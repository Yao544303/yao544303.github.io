<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0-rc2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":true,"nav":{"gitalk":{"order":-1}},"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="喵十八の小窝">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="喵十八の小窝">
<meta property="og:locale">
<meta property="article:author" content="喵十八">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>喵十八の小窝</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">喵十八の小窝</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-11-upload-requests/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-11-upload-requests/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（十一）upload 任务过程中产生的请求</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 13:41:40 / Modified: 13:42:32" itemprop="dateCreated datePublished" datetime="2023-08-20T13:41:40+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>upload 任务的http请求，可以分为两部分。<br>一部分是submit -&gt; job finish 这个流程中产生的。<br>另一部分是polling 的过程中，轮询产生的请求（只轮询后收集相关信息，不实际执行）</p>
<h1 id="执行细节"><a href="#执行细节" class="headerlink" title="执行细节"></a>执行细节</h1><p>以下的日志，是一个upload执行后，容器中完整的日志。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:31] &quot;POST /v1/party/202107260820309976351/local/0/create HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:31] &quot;POST /v1/data/upload?%7B%22file%22:%20%22/data/projects/fate/examples/data/breast_hetero_guest.csv%22,%20%22head%22:%201,%20%22partition%22:%201,%20%22work_mode%22:%201,%20%22table_name%22:%20%22hetero_guest%22,%20%22namespace%22:%20%22cl%22,%20%22config%22:%20%22/data/projects/fate/cl/upload_guest.json%22,%20%22function%22:%20%22upload%22%7D HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/local/0/resource/apply HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/local/0/start HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/status/running HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/start HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:33] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/report HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:34] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:36] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:38] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:40] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:41] &quot;POST /v1/party/202107260820309976351/local/0/update HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:42] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:43] &quot;POST /v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/output_data_info/save HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:43] &quot;POST /v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/metric_data/save HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:43] &quot;POST /v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/metric_meta/save HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:44] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/report HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:45] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:45] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/report HTTP/1.1&quot; 200 -</span><br><span class="line">static conf path: /data/projects/fate/eggroll/conf/eggroll.properties</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/status/success HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/stop/success HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/local/0/model HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/local/0/status/success HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/local/0/stop/success HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:48] &quot;POST /v1/party/202107260820309976351/local/0/clean HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:48] &quot;POST /v1/party/202107260820309976351/local/0/stop/success HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:48] &quot;POST /v1/party/202107260820309976351/local/0/clean HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure><br>其中endpoint为 collect 的是第二部分产生的日志，可以发现除最后一条记录外，时间间隔和轮询时间间隔是一致的。</p>
<p>其余则是第一部分的日志。</p>
<h1 id="提交任务http-请求"><a href="#提交任务http-请求" class="headerlink" title="提交任务http 请求"></a>提交任务http 请求</h1><p>按照不同的请求，依次说明其功能和函数调用链</p>
<ol>
<li>data/upload：<br>提交job<br>fate_flow_client.py -&gt; fate_flow_server.py -&gt; data_access_app_manager.py -&gt; DAGScheduler.submit </li>
</ol>
<ol>
<li>party/<job_id>/<role>/<party_id>/create：<br>创建job (接上文）<br>DAGScheduler.submit -&gt; FederatedScheduler.create_job -&gt; fate_flow_server.py -&gt; party_app.py -&gt; JobController.create_job</li>
</ol>
<ol>
<li>party/<job_id>/<role>/<party_id>/resource/apply：<br>为job申请资源<br>DAGScheduler.schedule_waiting_jobs -&gt; FederatedScheduler.resource_for_job -&gt; fate_flow_server.py -&gt; party_app.py -&gt; ResourceManager.apply_for_job_resource</li>
</ol>
<ol>
<li>party/<job_id>/<role>/<party_id>/start：<br>start job<br>DAGScheduler.schedule_waiting_jobs -&gt; DAGScheduler.start_job -&gt; FederatedScheduler.start_job(job=job) -&gt; fate_flow_server.py -&gt; party_app.py -&gt; JobController.start_job</li>
</ol>
<p><em>如下5-7 依次start task 并更新job状态</em></p>
<ol>
<li><p>party/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/status/running：<br>更新task状态<br>DAGScheduler.schedule_running_job -&gt; TaskScheduler.schedule -&gt; TaskScheduler.start_task -&gt; FederatedScheduler.sync_task_status -&gt; fate_flow_server.py -&gt; party_app.py -&gt; JobController.update_job_status</p>
</li>
<li><p>party/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/start：<br>紧跟上述 FederatedScheduler.sync_task_status 操作之后，start task。<br>DAGScheduler.schedule_running_job -&gt; TaskScheduler.schedule -&gt; TaskScheduler.start_task -&gt; FederatedScheduler.start_task -&gt; fate_flow_server.py -&gt; party_app.py -&gt; TaskController.start_task</p>
</li>
<li><p>party/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/report：<br>反馈状态<br>TaskExecutor.run_task -&gt; TaskExecutor.report_task_update_to_driver -&gt; ControllerClient.report_task -&gt; api_utils.local_api -&gt; fate_flow_server.py -&gt; party_app.py -&gt;  TaskController.update_task</p>
</li>
</ol>
<p><em>如下8 -11都是是在upload task执行过程中产生的请求</em></p>
<ol>
<li><p>party/<job_id>/<role>/<party_id>/update：<br>更新job状态<br>Upload.save_data_table -&gt; ControllerClient.update_job -&gt; api_utils.local_api -&gt; fate_flow_server.py -&gt; party_app.py -&gt;  JobController.update_job</p>
</li>
<li><p>tracker/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/output_data_info/save：<br>保存output_data_info<br>Upload.save_data_table -&gt; TrackerClient.log_output_data_info -&gt;  api_utils.local_api -&gt; fate_flow_server.py -&gt; tracker_app.py -&gt; Tracker.insert_output_data_info_into_db</p>
</li>
<li><p>tracker/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/metric_data/save：<br>保存指标<br>Upload.save_data_table -&gt; TrackerClient.log_metric_data -&gt; api_utils.local_api -&gt; fate_flow_server.py -&gt; tracker_app.py -&gt; Tracker.save_metric_data</p>
</li>
<li><p>tracker/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/metric_meta/save：<br>保存指标元数据<br>Upload.save_data_table -&gt; TrackerClient.log_metric_meta -&gt; api_utils.local_api -&gt; fate_flow_server.py -&gt; tracker_app.py -&gt; Tracker.save_metric_meta</p>
</li>
</ol>
<p><em>回到 task_executor，在finally 中执行 ，更新task状态</em></p>
<ol>
<li>party/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/report：<br>TaskExecutor.run_task -&gt; TaskExecutor.report_task_update_to_driver -&gt; ControllerClient.report_task -&gt; api_utils.local_api -&gt; fate_flow_server.py -&gt; party_app.py -&gt;  TaskController.update_task</li>
</ol>
<p><em>TaskExecutor.run_task() 执行完毕，执行TaskExecutor.report_task_update_to_driver()</em></p>
<ol>
<li>party/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id><br>report：TaskExecutor.report_task_update_to_driver -&gt; ControllerClient.report_task -&gt; api_utils.local_api -&gt; fate_flow_server.py -&gt; party_app.py -&gt;  TaskController.update_task</li>
</ol>
<p><em>Tips：这一次schedule_running_job之后，已经是success 了</em></p>
<ol>
<li>party/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/status/success：<br>DAGScheduler.schedule_running_job -&gt; TaskScheduler.schedule -&gt; FederatedScheduler.sync_task_status -&gt; fate_flow_server.py -&gt; party_app.py -&gt; TaskController.update_task_status</li>
</ol>
<p><em>Tips：因为已经success 进入下一环节</em></p>
<ol>
<li><p>party/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/stop/success：<br>DAGScheduler.schedule_running_job -&gt; TaskScheduler.schedule -&gt; FederatedScheduler.stop_task（接在上一步sync_task_status 之后） -&gt; fate_flow_server.py -&gt; party_app.py -&gt; TaskController.stop_task</p>
</li>
<li><p>party/<job_id>/<role>/<party_id>/model<br>DAGScheduler.schedule_running_job -&gt; FederatedScheduler.save_pipelined_model -&gt; fate_flow_server.py -&gt; party_app.py -&gt; JobController.save_pipelined_model</p>
</li>
<li><p>party/<job_id>/<role>/<party_id>/status/success<br>DAGScheduler.schedule_running_job -&gt; FederatedScheduler.sync_job_status -&gt; fate_flow_server.py -&gt; party_app.py -&gt; JobController.update_job_status</p>
</li>
<li><p>party/<job_id>/<role>/<party_id>/stop/success<br>DAGScheduler.schedule_running_job -&gt; DAGScheduler.finish -&gt; DAGScheduler.stop_job -&gt; FederatedScheduler.stop_job -&gt; fate_flow_server.py -&gt; party_app.py -&gt; JobController.stop_jobs</p>
</li>
<li><p>party/<job_id>/<role>/<party_id>/clean<br>DAGScheduler.schedule_running_job -&gt; DAGScheduler.finish -&gt;  FederatedScheduler.clean_job -&gt;  fate_flow_server.py -&gt; party_app.py -&gt; JobController.clean_job</p>
</li>
</ol>
<p><em>再run 一次 清理干净 参见<a href="https://blog.csdn.net/yao544303963/article/details/119878479">FATE学习：跟着日志读源码（九）upload任务job finsih阶段</a></em></p>
<ol>
<li><p>party/<job_id>/<role>/<party_id>/stop/success：DAGScheduler.schedule_running_job -&gt; DAGScheduler.finish -&gt; DAGScheduler.stop_job -&gt; FederatedScheduler.stop_job -&gt; fate_flow_server.py -&gt; party_app.py -&gt; JobController.stop_jobs</p>
</li>
<li><p>party/<job_id>/<role>/<party_id>/clean：DAGScheduler.schedule_running_job -&gt; DAGScheduler.finish -&gt;  FederatedScheduler.clean_job -&gt;  fate_flow_server.py -&gt; party_app.py -&gt; JobController.clean_job</p>
</li>
</ol>
<h1 id="对于轮询部分"><a href="#对于轮询部分" class="headerlink" title="对于轮询部分"></a>对于轮询部分</h1><p>party/<job_id>/<component_name>/<task_id>/<task_version>/<role>/<party_id>/collect：<br>DAGScheduler.schedule_running_job -&gt; TaskScheduler.schedule -&gt; TaskScheduler.collect_task_of_all_party -&gt; FederatedScheduler.collect_task -&gt; party_app.py -&gt; TaskController.collect_task</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-10-polling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-10-polling/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（十）polling</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:13:12 / Modified: 13:35:08" itemprop="dateCreated datePublished" datetime="2023-08-20T12:13:12+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>在<a href="">FATE学习：跟着日志读源码（二）fate_flow server 启动</a>介绍过，fate_flow_server.py中的DAGScheduler(interval=2 * 1000).start()，默认每隔2s，启动一次dag_scheduler，共五种调度。<br>其中：</p>
<ul>
<li>调度处于waiting 状态的job：job的状态从waiting -&gt; running，主要在<a href="">FATE学习：跟着日志读源码（五）upload任务job schedule阶段</a>介绍。</li>
<li>调度处于running 状态的job：涉及job和task的状态变化，<ul>
<li>task的状态从waiting -&gt; running 在<a href="">FATE学习：跟着日志读源码（六）upload任务task schedule</a>中介绍。</li>
<li>task的状态从running -&gt; success 在<a href="">FATE学习：跟着日志读源码（八）upload任务task finsih阶段</a> 中介绍</li>
<li>job的状态从running -&gt; success 在<a href="">FATE学习：跟着日志读源码（八）upload任务task finsih阶段</a> 中介绍</li>
<li>task的状态保持running不变，见后文</li>
</ul>
</li>
<li>调度ready状态的job：TODO</li>
<li>调度rerun任务的job：TODO</li>
<li>更新已经为endstatus的job的status：见后文</li>
</ul>
<h1 id="task的状态保持running不变"><a href="#task的状态保持running不变" class="headerlink" title="task的状态保持running不变"></a>task的状态保持running不变</h1><p>若task的执行时间比轮询间隔2s要长，那么在轮询期间，task的状态保持running不变，<br>对应的${job_log_dir}/fate_flow_schedule.log 日志为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:42,798] [1:140259369826048] - dag_scheduler.py[line:298]: scheduling job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:42,800] [1:140259369826048] - task_scheduler.py[line:28]: scheduling job 202107260820309976351 tasks</span><br><span class="line">[INFO] [2021-07-26 08:20:42,836] [1:140259369826048] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br><span class="line">[INFO] [2021-07-26 08:20:42,845] [1:140259369826048] - job_saver.py[line:76]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status update does not take effect: &#123;&#x27;elapsed&#x27;: None, &#x27;end_time&#x27;: None, &#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;party_status&#x27;: &#x27;running&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;start_time&#x27;: 1627287632259, &#x27;status&#x27;: &#x27;running&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: 0, &#x27;update_time&#x27;: 1627287631078&#125;</span><br><span class="line">[INFO] [2021-07-26 08:20:42,845] [1:140259369826048] - job_saver.py[line:81]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0</span><br><span class="line">[WARNING] [2021-07-26 08:20:42,860] [1:140259369826048] - job_saver.py[line:86]: job 202107260820309976351 task 202107260820309976351_upload_0 0 update does not take effect</span><br><span class="line">[INFO] [2021-07-26 08:20:42,867] [1:140259369826048] - task_scheduler.py[line:143]: job 202107260820309976351 task 202107260820309976351_upload_0 0 status is running, calculate by task party status list: [&#x27;running&#x27;]</span><br><span class="line">[INFO] [2021-07-26 08:20:42,867] [1:140259369826048] - task_scheduler.py[line:75]: finish scheduling job 202107260820309976351 tasks</span><br><span class="line">[INFO] [2021-07-26 08:20:42,868] [1:140259369826048] - dag_scheduler.py[line:310]: Job 202107260820309976351 status is running, calculate by task status list: [&#x27;running&#x27;]</span><br><span class="line">[INFO] [2021-07-26 08:20:42,868] [1:140259369826048] - dag_scheduler.py[line:325]: finish scheduling job 202107260820309976351</span><br></pre></td></tr></table></figure></p>
<h1 id="调度已经为endstatus的job"><a href="#调度已经为endstatus的job" class="headerlink" title="调度已经为endstatus的job"></a>调度已经为endstatus的job</h1><p>源码：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">schedule_logger().info(&quot;start schedule end status jobs to update status&quot;)</span><br><span class="line">jobs = JobSaver.query_job(is_initiator=True, status=set(EndStatus.status_list()), end_time=[current_timestamp() - END_STATUS_JOB_SCHEDULING_TIME_LIMIT, current_timestamp()])</span><br><span class="line">schedule_logger().info(f&quot;have &#123;len(jobs)&#125; end status jobs&quot;)</span><br><span class="line">for job in jobs:</span><br><span class="line">    schedule_logger().info(f&quot;schedule end status job &#123;job.f_job_id&#125;&quot;)</span><br><span class="line">    try:</span><br><span class="line">        update_status = self.end_scheduling_updates(job_id=job.f_job_id)</span><br><span class="line">        if not update_status:</span><br><span class="line">            schedule_logger(job.f_job_id).info(f&quot;the number of updates has been exceeded&quot;)</span><br><span class="line">            continue</span><br><span class="line">        self.schedule_running_job(job=job)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        schedule_logger(job.f_job_id).exception(e)</span><br><span class="line">        schedule_logger(job.f_job_id).error(f&quot;schedule job &#123;job.f_job_id&#125; failed&quot;)</span><br><span class="line">schedule_logger().info(&quot;schedule end status jobs finished&quot;)</span><br></pre></td></tr></table></figure><br>说明：结束之后的轮询dag_scheduler.py 中，schedule end status job 部分的功能。对于5分钟内（END_STATUS_JOB_SCHEDULING_TIME_LIMIT = 5 <em> 60 </em> 1000 # ms）已经finish 的job，都还会执行end_scheduling_updates。其中只有第一次能update成功（默认参数是一次 END_STATUS_JOB_SCHEDULING_UPDATES = 1），然后再schedule_running_job 该job。<br>此后，每次 dag_scheduler轮询（默认每2s），都会报出如下日志：<br>dag_scheduler.py[line:193]: the number of updates has been exceeded</p>
<p>fate_flow/fate_flow_schedule.log<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:48,027] [1:140259369826048] - dag_scheduler.py[line:185]: start schedule end status jobs to update status</span><br><span class="line">[INFO] [2021-07-26 08:20:48,036] [1:140259369826048] - dag_scheduler.py[line:187]: have 1 end status jobs</span><br><span class="line">[INFO] [2021-07-26 08:20:48,036] [1:140259369826048] - dag_scheduler.py[line:189]: schedule end status job 202107260820309976351</span><br></pre></td></tr></table></figure><br>再一次调度schedule_running_job </p>
<p>${job_log_dir}/fate_flow_schedule.log 日志为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:48,044] [1:140259369826048] - dag_scheduler.py[line:298]: scheduling job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:48,046] [1:140259369826048] - task_scheduler.py[line:28]: scheduling job 202107260820309976351 tasks</span><br><span class="line">[INFO] [2021-07-26 08:20:48,066] [1:140259369826048] - task_scheduler.py[line:143]: job 202107260820309976351 task 202107260820309976351_upload_0 0 status is success, calculate by task party status list: [&#x27;success&#x27;]</span><br><span class="line">[INFO] [2021-07-26 08:20:48,067] [1:140259369826048] - task_scheduler.py[line:75]: finish scheduling job 202107260820309976351 tasks</span><br><span class="line">[INFO] [2021-07-26 08:20:48,067] [1:140259369826048] - dag_scheduler.py[line:310]: Job 202107260820309976351 status is success, calculate by task status list: [&#x27;success&#x27;]</span><br><span class="line">[INFO] [2021-07-26 08:20:48,067] [1:140259369826048] - dag_scheduler.py[line:502]: Job 202107260820309976351 finished with success, do something...</span><br><span class="line">[INFO] [2021-07-26 08:20:48,067] [1:140259369826048] - dag_scheduler.py[line:436]: request stop job 202107260820309976351 with success</span><br><span class="line">[INFO] [2021-07-26 08:20:48,074] [1:140259369826048] - dag_scheduler.py[line:445]: request stop job 202107260820309976351 with success to all party</span><br><span class="line">[INFO] [2021-07-26 08:20:48,074] [1:140259369826048] - federated_scheduler.py[line:88]: try to stop job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:48,097] [1:140259119585024] - job_utils.py[line:396]: try to stop job 202107260820309976351 task 202107260820309976351_upload_0 local 0 with success party status process pid:90</span><br><span class="line">[INFO] [2021-07-26 08:20:48,097] [1:140259119585024] - job_utils.py[line:399]: can not found job 202107260820309976351 task 202107260820309976351_upload_0 local 0 with success party status process pid:90</span><br><span class="line">[INFO] [2021-07-26 08:20:48,100] [1:140259119585024] - job_utils.py[line:423]: start run subprocess to stop task session 202107260820309976351_upload_0_0_local_0</span><br><span class="line">[INFO] [2021-07-26 08:20:48,100] [1:140259119585024] - job_utils.py[line:310]: start process command: python3 /data/projects/fate/python/fate_flow/utils/session_utils.py -j 202107260820309976351_upload_0_0_local_0 --computing EGGROLL --federation EGGROLL --storage EGGROLL -c stop</span><br><span class="line">[INFO] [2021-07-26 08:20:48,111] [1:140259119585024] - job_utils.py[line:333]: start process command: python3 /data/projects/fate/python/fate_flow/utils/session_utils.py -j 202107260820309976351_upload_0_0_local_0 --computing EGGROLL --federation EGGROLL --storage EGGROLL -c stop successfully, pid is 159</span><br><span class="line">[INFO] [2021-07-26 08:20:48,111] [1:140259119585024] - task_controller.py[line:254]: job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0 process 90 kill success</span><br><span class="line">[INFO] [2021-07-26 08:20:48,112] [1:140259119585024] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br><span class="line">[INFO] [2021-07-26 08:20:48,119] [1:140259119585024] - job_saver.py[line:76]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status update does not take effect: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: 0, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;party_status&#x27;: &#x27;success&#x27;&#125;</span><br><span class="line">[INFO] [2021-07-26 08:20:48,144] [1:140259119585024] - job_saver.py[line:81]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0</span><br><span class="line">[WARNING] [2021-07-26 08:20:48,147] [1:140259119585024] - job_saver.py[line:86]: job 202107260820309976351 task 202107260820309976351_upload_0 0 update does not take effect</span><br><span class="line">[INFO] [2021-07-26 08:20:48,151] [1:140259119585024] - job_saver.py[line:45]: try to update job 202107260820309976351 status to success</span><br><span class="line">[INFO] [2021-07-26 08:20:48,156] [1:140259119585024] - job_saver.py[line:56]: update job 202107260820309976351 status does not take effect</span><br><span class="line">[INFO] [2021-07-26 08:20:48,158] [1:140259369826048] - federated_scheduler.py[line:92]: stop job 202107260820309976351 success</span><br><span class="line">[INFO] [2021-07-26 08:20:48,158] [1:140259369826048] - dag_scheduler.py[line:448]: stop job 202107260820309976351 with success successfully</span><br><span class="line">[INFO] [2021-07-26 08:20:48,158] [1:140259369826048] - federated_scheduler.py[line:107]: try to clean job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:48,162] [1:140259119585024] - job_controller.py[line:344]: Job 202107260820309976351 on local 0 start to clean</span><br><span class="line">[INFO] [2021-07-26 08:20:48,162] [1:140259119585024] - job_controller.py[line:346]: job 202107260820309976351 on local 0 clean done</span><br><span class="line">[INFO] [2021-07-26 08:20:48,164] [1:140259369826048] - federated_scheduler.py[line:110]: clean job 202107260820309976351 success</span><br><span class="line">[INFO] [2021-07-26 08:20:48,164] [1:140259369826048] - dag_scheduler.py[line:505]: Job 202107260820309976351 finished with success, done</span><br><span class="line">[INFO] [2021-07-26 08:20:48,164] [1:140259369826048] - dag_scheduler.py[line:325]: finish scheduling job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:48,596] [148:140090979002176] - session_utils.py[line:38]: start stop session 202107260820309976351_upload_0_0_local_0</span><br><span class="line">[INFO] [2021-07-26 08:20:48,762] [153:140325590579008] - session_utils.py[line:38]: start stop session 202107260820309976351_upload_0_0_local_0</span><br><span class="line">[INFO] [2021-07-26 08:20:48,941] [159:140675688425280] - session_utils.py[line:38]: start stop session 202107260820309976351_upload_0_0_local_0</span><br><span class="line">[INFO] [2021-07-26 08:20:50,205] [1:140259369826048] - dag_scheduler.py[line:193]: the number of updates has been exceeded</span><br><span class="line">[INFO] [2021-07-26 08:20:50,227] [153:140325590579008] - session_utils.py[line:47]: stop session 202107260820309976351_upload_0_0_local_0 success</span><br><span class="line">[INFO] [2021-07-26 08:20:50,233] [148:140090979002176] - session_utils.py[line:47]: stop session 202107260820309976351_upload_0_0_local_0 success</span><br><span class="line">[INFO] [2021-07-26 08:20:50,240] [159:140675688425280] - session_utils.py[line:47]: stop session 202107260820309976351_upload_0_0_local_0 success</span><br></pre></td></tr></table></figure>
<p>再次调度产生的日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:52,248] [1:140259369826048] - dag_scheduler.py[line:193]: the number of updates has been exceeded</span><br></pre></td></tr></table></figure></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-9-upload-job-finish/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-9-upload-job-finish/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（九）upload任务job finsih阶段</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:12:58 / Modified: 13:35:48" itemprop="dateCreated datePublished" datetime="2023-08-20T12:12:58+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>同task，job结束时，并不会返回job finish 的信息，也是在DagScheduler.schedule_running_job() 轮询时，通过calculate_job_status() 方法获取job的状态。<br>获取job已经finish的信息后，会返还资源和进行相关环境清理。</p>
<h1 id="执行步骤"><a href="#执行步骤" class="headerlink" title="执行步骤"></a>执行步骤</h1><p><img src="/image/fate/d55725da18b1408aac6c7ffccbaf1855.png" alt="在这里插入图片描述"></p>
<ol>
<li><p>dag_scheduler.py：当调度完task后，执行calculate_job_status，计算job当前的状态。执行calculate_job_progress，计算job当前的完成进度。<br>在${job_log_dir}/fate_flow_schedule.log 输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,782] [1:140259369826048] - dag_scheduler.py[line:310]: Job 202107260820309976351 status is success, calculate by task status list: [&#x27;success&#x27;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>dag_scheduler.py：根据job 状态和进度变化，同步信息，save model等<br>下面这段代码没执行，逻辑上有点问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if int(new_progress) - job.f_progress &gt; 0:</span><br><span class="line">    job.f_progress = new_progress</span><br><span class="line">    FederatedScheduler.sync_job(job=job, update_fields=[&quot;progress&quot;])</span><br><span class="line">    cls.update_job_on_initiator(initiator_job=job, update_fields=[&quot;progress&quot;])</span><br></pre></td></tr></table></figure>
<p><strong>存疑</strong><br>当task状态改变时TaskScheduler.schedule  返回的initiator_tasks_group 中的task状态未改变<br>结果导致 DAGScheduler.schedule_running_job 中    total, finished_count = cls.calculate_job_progress(tasks_status=tasks_status)<br>无改变，不会触发 后续流程，会多跑一遍。<br>建议在task schedule结束之后，再query一遍task的信息，更新状态。</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if new_job_status != job.f_status:</span><br><span class="line">    job.f_status = new_job_status</span><br><span class="line">    if EndStatus.contains(job.f_status):</span><br><span class="line">        FederatedScheduler.save_pipelined_model(job=job)</span><br><span class="line">    FederatedScheduler.sync_job_status(job=job)</span><br><span class="line">    cls.update_job_on_initiator(initiator_job=job, update_fields=[&quot;status&quot;])</span><br></pre></td></tr></table></figure>
<p>job 状态变换，且job 已经finish，调用FederatedScheduler.save_pipelined_model<br>调用链 FederatedScheduler.save_pipelined_model() -&gt; api_utils.federated_coordination_on_http() 这里endpoint 是model-&gt; fate_flow_server通过flask -&gt; party_app.save_pipelined_model() -&gt;   JobController.save_pipelined_model<br>在${job_log_dir}/fate_flow_schedule.log 输出日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,783] [1:140259369826048] - federated_scheduler.py[line:78]: try to save job 202107260820309976351 pipelined model</span><br><span class="line">[INFO] [2021-07-26 08:20:47,791] [1:140259119585024] - job_controller.py[line:300]: job 202107260820309976351 on local 0 start to save pipeline</span><br><span class="line">[INFO] [2021-07-26 08:20:47,800] [1:140259119585024] - job_controller.py[line:340]: job 202107260820309976351 on local 0 save pipeline successfully</span><br><span class="line">[INFO] [2021-07-26 08:20:47,804] [1:140259369826048] - federated_scheduler.py[line:81]: save job 202107260820309976351 pipelined model success</span><br></pre></td></tr></table></figure><br>注意：如果是predict，因为使用的是已经存在的model，这里不会再存储<br>模型存储的路径在<br>/data/projects/fate/model_local_cache/${role}#${party}#${component_name}#model/${jobid}<br>/data/projects/fate/model_local_cache/local#0#local-0#model/202107260820309976351</p>
<ol>
<li><p>dag_scheduler.py：save完成，同步信息执行FederatedScheduler.sync_job_status(job=job) 调用链FederatedScheduler.sync_job_status() -&gt;-api_utils.federated_coordination_on_http() 这里endpoint 是status -&gt; fate_flow_server通过flask -&gt; party_app.job_status -&gt;   JobController.update_job_status -&gt;  ResourceManager.return_job_resource<br>在update_job_status中，判断job处于finish 状态，回收资源。<br>对应在${job_log_dir}/fate_flow_schedule.log 输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,804] [1:140259369826048] - federated_scheduler.py[line:68]: job 202107260820309976351 is success, sync to all party</span><br><span class="line">[INFO] [2021-07-26 08:20:47,810] [1:140259119585024] - job_saver.py[line:45]: try to update job 202107260820309976351 status to success</span><br><span class="line">[INFO] [2021-07-26 08:20:47,830] [1:140259119585024] - job_saver.py[line:48]: update job 202107260820309976351 status successfully</span><br><span class="line">[INFO] [2021-07-26 08:20:47,869] [1:140259119585024] - resource_manager.py[line:175]: return job 202107260820309976351 resource(cores 4 memory 0) on local 0 successfully, remaining cores: 20 remaining memory: 0</span><br><span class="line">[INFO] [2021-07-26 08:20:47,874] [1:140259369826048] - federated_scheduler.py[line:71]: sync job 202107260820309976351 status success to all party success</span><br></pre></td></tr></table></figure>
</li>
<li><p>dag_scheduler.py：update_job_on_initiator() ，<br>调用链 update_job_on_initiator -&gt; JobSaver.update_job_status() -&gt; JobSaver.update_status -&gt; JobSaver.update_entity_table （由于是local，jobstatus 已经更新，前一步失败，这里不会执行）-&gt; JobSaver.update_job() -&gt; JobSaver.update_entity_table<br>对应在${job_log_dir}/fate_flow_schedule.log 输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,884] [1:140259369826048] - job_saver.py[line:45]: try to update job 202107260820309976351 status to success</span><br><span class="line">[INFO] [2021-07-26 08:20:47,894] [1:140259369826048] - job_saver.py[line:56]: update job 202107260820309976351 status does not take effect</span><br><span class="line">[INFO] [2021-07-26 08:20:47,894] [1:140259369826048] - job_saver.py[line:61]: try to update job 202107260820309976351</span><br><span class="line">[WARNING] [2021-07-26 08:20:47,904] [1:140259369826048] - job_saver.py[line:66]: job 202107260820309976351 update does not take effect: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;status&#x27;: &#x27;success&#x27;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>dag_scheduler.py：执行finish 执行stop_job<br>DagScheduler.stop_job() -&gt;   FederatedScheduler.stop_job -&gt; api_utils.federated_coordination_on_http() 这里endpoint 是stop -&gt; fate_flow_server通过flask -&gt; party_app.stop_job -&gt;    JobController.stop_jobs -&gt;  JobController.stop_job -&gt;TaskController.stop_task -&gt; JobController.update_job_status<br>注意，因为job是拆解成一个个task执行，故执行进程只有task的，没有job的进程。stop的job的操作是依次遍历job下的task，进行stop_task。在正常流程下，由于所有task都stop之后，才会触发stop_job。故而这里stop_task 都是can not found。<br>对应在${job_log_dir}/fate_flow_schedule.log 输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,904] [1:140259369826048] - dag_scheduler.py[line:502]: Job 202107260820309976351 finished with success, do something...</span><br><span class="line">[INFO] [2021-07-26 08:20:47,905] [1:140259369826048] - dag_scheduler.py[line:436]: request stop job 202107260820309976351 with success</span><br><span class="line">[INFO] [2021-07-26 08:20:47,913] [1:140259369826048] - dag_scheduler.py[line:445]: request stop job 202107260820309976351 with success to all party</span><br><span class="line">[INFO] [2021-07-26 08:20:47,913] [1:140259369826048] - federated_scheduler.py[line:88]: try to stop job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:47,937] [1:140259119585024] - job_utils.py[line:396]: try to stop job 202107260820309976351 task 202107260820309976351_upload_0 local 0 with success party status process pid:90</span><br><span class="line">[INFO] [2021-07-26 08:20:47,937] [1:140259119585024] - job_utils.py[line:399]: can not found job 202107260820309976351 task 202107260820309976351_upload_0 local 0 with success party status process pid:90</span><br><span class="line">[INFO] [2021-07-26 08:20:47,939] [1:140259119585024] - job_utils.py[line:423]: start run subprocess to stop task session 202107260820309976351_upload_0_0_local_0</span><br><span class="line">[INFO] [2021-07-26 08:20:47,939] [1:140259119585024] - job_utils.py[line:310]: start process command: python3 /data/projects/fate/python/fate_flow/utils/session_utils.py -j 202107260820309976351_upload_0_0_local_0 --computing EGGROLL --federation EGGROLL --storage EGGROLL -c stop</span><br><span class="line">[INFO] [2021-07-26 08:20:47,953] [1:140259119585024] - job_utils.py[line:333]: start process command: python3 /data/projects/fate/python/fate_flow/utils/session_utils.py -j 202107260820309976351_upload_0_0_local_0 --computing EGGROLL --federation EGGROLL --storage EGGROLL -c stop successfully, pid is 153</span><br><span class="line">[INFO] [2021-07-26 08:20:47,954] [1:140259119585024] - task_controller.py[line:254]: job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0 process 90 kill success</span><br></pre></td></tr></table></figure>
<p>然后调用 JobController.update_job_status 更新信息，不同于3中，这里执行失败，不会进行资源回收。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,984] [1:140259119585024] - job_saver.py[line:45]: try to update job 202107260820309976351 status to success</span><br><span class="line">[INFO] [2021-07-26 08:20:47,991] [1:140259119585024] - job_saver.py[line:56]: update job 202107260820309976351 status does not take effect</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>返回成功信息<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,997] [1:140259369826048] - federated_scheduler.py[line:92]: stop job 202107260820309976351 success</span><br><span class="line">[INFO] [2021-07-26 08:20:47,997] [1:140259369826048] - dag_scheduler.py[line:448]: stop job 202107260820309976351 with success successfully</span><br></pre></td></tr></table></figure></p>
<ol>
<li><p>dag_scheduler.py：执行finish 执行clean_job<br>FederatedScheduler.clean_job() -&gt; api_utils.federated_coordination_on_http() 这里endpoint 是clean -&gt; fate_flow_server通过flask -&gt; party_app.stop_job -&gt;    JobController.stop_jobs -&gt;  JobController.clean_job<br>然后clean_job，只打了日志，啥也没干</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def clean_job(cls, job_id, role, party_id, roles):</span><br><span class="line">    schedule_logger(job_id).info(&#x27;Job &#123;&#125; on &#123;&#125; &#123;&#125; start to clean&#x27;.format(job_id, role, party_id))</span><br><span class="line">    # todo</span><br><span class="line">    schedule_logger(job_id).info(&#x27;job &#123;&#125; on &#123;&#125; &#123;&#125; clean done&#x27;.format(job_id, role, party_id))</span><br></pre></td></tr></table></figure>
<p>对应在${job_log_dir}/fate_flow_schedule.log 输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,997] [1:140259369826048] - federated_scheduler.py[line:107]: try to clean job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:48,003] [1:140259119585024] - job_controller.py[line:344]: Job 202107260820309976351 on local 0 start to clean</span><br><span class="line">[INFO] [2021-07-26 08:20:48,003] [1:140259119585024] - job_controller.py[line:346]: job 202107260820309976351 on local 0 clean done</span><br><span class="line">[INFO] [2021-07-26 08:20:48,007] [1:140259369826048] - federated_scheduler.py[line:110]: clean job 202107260820309976351 success</span><br></pre></td></tr></table></figure>
</li>
<li><p>dag_scheduler.py： finish执行结束，输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:48,007] [1:140259369826048] - dag_scheduler.py[line:505]: Job 202107260820309976351 finished with success, done</span><br></pre></td></tr></table></figure>
<p>至此，job finish 结束，当然，调度器本轮调度也结束了，打出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:48,007] [1:140259369826048] - dag_scheduler.py[line:325]: finish scheduling job 202107260820309976351</span><br></pre></td></tr></table></figure>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-8-upload-task-finish/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-8-upload-task-finish/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（八）upload任务task finsih阶段</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:12:51 / Modified: 13:35:59" itemprop="dateCreated datePublished" datetime="2023-08-20T12:12:51+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>task结束时，是通过TaskExecutor.report_task_update_to_driver更新本地的DB中task的状态信息的。但由于是异步请求，对于发起者而言，并不会收到task 结束的信息，只有在轮询中，去查询db，获取task的状态。<br>获取task已经finish的信息后，会返还资源和进行相关环境清理。</p>
<h1 id="执行细节"><a href="#执行细节" class="headerlink" title="执行细节"></a>执行细节</h1><p><img src="/image/fate/4581c0b4600f440797dba9b06e11612b.png" alt="在这里插入图片描述"></p>
<ol>
<li><p>dag_scheduler.py：schedule_running_job 调度轮询，和前文类似，这里不多赘述调用链为<br>DagScheduler.schedule_running_job() -&gt;TaskScheduler.schedule-&gt;JobSaver.get_tasks_asc -&gt; JobSaver.collect_task_of_all_party -&gt; JobSaver.federated_task_status<br>对应的${job_log_dir}/fate_flow_schedule.log 日志为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:44,944] [1:140259369826048] - dag_scheduler.py[line:298]: scheduling job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:44,945] [1:140259369826048] - task_scheduler.py[line:28]: scheduling job 202107260820309976351 tasks</span><br><span class="line">[INFO] [2021-07-26 08:20:45,010] [1:140259369826048] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br><span class="line">[INFO] [2021-07-26 08:20:45,022] [1:140259369826048] - job_saver.py[line:76]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status update does not take effect: &#123;&#x27;elapsed&#x27;: 11447, &#x27;end_time&#x27;: 1627287644838, &#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;party_status&#x27;: &#x27;success&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;start_time&#x27;: 1627287632259, &#x27;status&#x27;: &#x27;running&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: 0, &#x27;update_time&#x27;: 1627287631078&#125;</span><br><span class="line">[INFO] [2021-07-26 08:20:45,022] [1:140259369826048] - job_saver.py[line:81]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0</span><br><span class="line">[WARNING] [2021-07-26 08:20:45,036] [1:140259369826048] - job_saver.py[line:86]: job 202107260820309976351 task 202107260820309976351_upload_0 0 update does not take effect</span><br><span class="line">[INFO] [2021-07-26 08:20:45,041] [1:140259369826048] - task_scheduler.py[line:143]: job 202107260820309976351 task 202107260820309976351_upload_0 0 status is success, calculate by task party status list: [&#x27;success&#x27;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>task_scheduler.py：同步状态，同上文相同，调用FederatedScheduler.sync_task_status<br>产生的调用链为<br>FederatedScheduler.sync_task_status() -&gt; api_utils.federated_coordination_on_http() -&gt; fate_flow_server通过flask -&gt; party_app.task_status() -&gt;   TaskController.update_task_status </p>
</li>
</ol>
<p>对应的${job_log_dir}/fate_flow_schedule.log 日志为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:45,041] [1:140259369826048] - federated_scheduler.py[line:192]: job 202107260820309976351 task 202107260820309976351_upload_0 0 is success, sync to all party</span><br><span class="line">[INFO] [2021-07-26 08:20:45,053] [1:140259119585024] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br><span class="line">[INFO] [2021-07-26 08:20:45,063] [1:140259119585024] - job_saver.py[line:74]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status successfully: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: &#x27;0&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;status&#x27;: &#x27;success&#x27;&#125;</span><br></pre></td></tr></table></figure></p>
<ol>
<li>resource_manager.py：归还资源，执行return_task_resource 这一部分会更新resource 相关的DB，增加剩余资源数。<br>对应的${job_log_dir}/fate_flow_schedule.log 日志为</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:45,070] [1:140259119585024] - resource_manager.py[line:285]: task 202107260820309976351_upload_0 0 return resource successfully</span><br></pre></td></tr></table></figure>
<ol>
<li><p>task_controller.py：执行clean_task，调用 job_tracker.clean_task() job_tracker.clean_task 清理tracker 表中的相关内容<br>对应的${job_log_dir}/fate_flow_schedule.log 日志为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:45,075] [1:140259119585024] - job_tracker.py[line:424]: clean task 202107260820309976351_upload_0 0 on local 0</span><br><span class="line">[INFO] [2021-07-26 08:20:46,706] [1:140259119585024] - job_tracker.py[line:440]: clean table by namespace 202107260820309976351_upload_0_0_local_0 on local 0 done</span><br><span class="line">[INFO] [2021-07-26 08:20:46,725] [1:140259119585024] - job_tracker.py[line:446]: clean table by namespace 202107260820309976351_upload_0_0 on local 0 done</span><br></pre></td></tr></table></figure>
</li>
<li><p>federated_scheduler.py： 返回执行结果，对应2<br>对应的${job_log_dir}/fate_flow_schedule.log 日志为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,714] [1:140259369826048] - federated_scheduler.py[line:195]: sync job 202107260820309976351 task 202107260820309976351_upload_0 0 status success to all party success</span><br></pre></td></tr></table></figure></li>
<li>task_scheduler.py：因task 的状态已经属于EndStatus，执行FederatedScheduler.stop_task 根据pid 进行kill。<br>调用链为FederatedScheduler.stop_task()-&gt; api_utils.federated_coordination_on_http() -&gt; fate_flow_server通过flask -&gt; party_app.stop_task() -&gt;   TaskController.stop_task() -&gt;  TaskController.kill_task() -&gt;job_utils.kill_task_executor_process<br>P1: kill pid<br>P2: stop session </li>
</ol>
<p>对应的${job_log_dir}/fate_flow_schedule.log 日志为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,714] [1:140259369826048] - federated_scheduler.py[line:202]: try to stop job 202107260820309976351 task 202107260820309976351_upload_0 0</span><br><span class="line">[INFO] [2021-07-26 08:20:47,739] [1:140259119585024] - job_utils.py[line:396]: try to stop job 202107260820309976351 task 202107260820309976351_upload_0 local 0 with success party status process pid:90</span><br><span class="line">[INFO] [2021-07-26 08:20:47,740] [1:140259119585024] - job_utils.py[line:399]: can not found job 202107260820309976351 task 202107260820309976351_upload_0 local 0 with success party status process pid:90</span><br><span class="line">[INFO] [2021-07-26 08:20:47,742] [1:140259119585024] - job_utils.py[line:423]: start run subprocess to stop task session 202107260820309976351_upload_0_0_local_0</span><br><span class="line">[INFO] [2021-07-26 08:20:47,743] [1:140259119585024] - job_utils.py[line:310]: start process command: python3 /data/projects/fate/python/fate_flow/utils/session_utils.py -j 202107260820309976351_upload_0_0_local_0 --computing EGGROLL --federation EGGROLL --storage EGGROLL -c stop</span><br><span class="line">[INFO] [2021-07-26 08:20:47,755] [1:140259119585024] - job_utils.py[line:333]: start process command: python3 /data/projects/fate/python/fate_flow/utils/session_utils.py -j 202107260820309976351_upload_0_0_local_0 --computing EGGROLL --federation EGGROLL --storage EGGROLL -c stop successfully, pid is 148</span><br><span class="line">[INFO] [2021-07-26 08:20:47,756] [1:140259119585024] - task_controller.py[line:254]: job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0 process 90 kill success</span><br></pre></td></tr></table></figure></p>
<ol>
<li><p>task_controller.py：更新信息<br>  cls.update_task_status(task_info=task_info)</p>
<pre><code>cls.update_task(task_info=task_info)
</code></pre><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,756] [1:140259119585024] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br><span class="line">[INFO] [2021-07-26 08:20:47,762] [1:140259119585024] - job_saver.py[line:76]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status update does not take effect: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: 0, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;party_status&#x27;: &#x27;success&#x27;&#125;</span><br><span class="line">[INFO] [2021-07-26 08:20:47,767] [1:140259119585024] - job_saver.py[line:81]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0</span><br><span class="line">[WARNING] [2021-07-26 08:20:47,771] [1:140259119585024] - job_saver.py[line:86]: job 202107260820309976351 task 202107260820309976351_upload_0 0 update does not take effect</span><br></pre></td></tr></table></figure>
</li>
<li><p>federated_scheduler.py： 对应6</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,782] [1:140259369826048] - federated_scheduler.py[line:206]: stop job 202107260820309976351 task 202107260820309976351_upload_0 0 success</span><br></pre></td></tr></table></figure>
</li>
<li><p>task_scheduler.py：对应1</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:47,782] [1:140259369826048] - task_scheduler.py[line:75]: finish scheduling job 202107260820309976351 tasks</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>task finish 结束</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-7-upload-task-execute/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-7-upload-task-execute/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（七）upload任务task excute阶段</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:12:47 / Modified: 13:36:55" itemprop="dateCreated datePublished" datetime="2023-08-20T12:12:47+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>前文对upload task 进行schedule 之后，最终调用 task_executor 进行执行，进入具体的执行部分。<br>每个task的具体日志会打在${job_log_dir}/ $ {role}/ ${party} 中（为便于记录，这里简记为 ${task_log_dir}<br>这里就按照 ${task_log_dir}/DEBUG.log看 会比较清晰一点</p>
<h1 id="执行细节"><a href="#执行细节" class="headerlink" title="执行细节"></a>执行细节</h1><p><img src="/image/fate/c1ec280a31b64fc6bc0c81c8bece859e.png" alt="在这里插入图片描述"></p>
<ol>
<li>执行命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/app-root/bin/python /data/projects/fate/python/fate_flow/operation/task_executor.py -j 202107260820309976351 -n upload_0 -t 202107260820309976351_upload_0 -v 0 -r local -p 0 -c /data/projects/fate/jobs/202107260820309976351/local/0/upload_0/202107260820309976351_upload_0/0/task_parameters.json --run_ip 10.200.96.235 --job_server 10.200.96.235:9380</span><br></pre></td></tr></table></figure></li>
<li><p>task_executor.py：执行run_task<br>先解析各参数。<br>在${job_log_dir}/fate_flow_schedule.log 输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:33,391] [90:139687957583680] - task_executor.py[line:56]: enter task process</span><br><span class="line">[INFO] [2021-07-26 08:20:33,391] [90:139687957583680] - task_executor.py[line:57]: Namespace(component_name=&#x27;upload_0&#x27;, config=&#x27;/data/projects/fate/jobs/202107260820309976351/local/0/upload_0/202107260820309976351_upload_0/0/task_parameters.json&#x27;, job_id=&#x27;202107260820309976351&#x27;, job_server=&#x27;10.200.96.235:9380&#x27;, party_id=0, role=&#x27;local&#x27;, run_ip=&#x27;10.200.96.235&#x27;, task_id=&#x27;202107260820309976351_upload_0&#x27;, task_version=0)</span><br></pre></td></tr></table></figure>
<p>根据参数解析的结果，调用 schedule_utils.get_job_dsl_parser() 生成dsl_parser，并配置各项参数。<br>设置job_log_dir 和 task_log_dir。<br><strong>注：设置完目录后，task产生的所有日志，都是输出到task_log_dir 下了，和外层的fate_flow_schedule.log 分离了</strong></p>
</li>
<li><p>task_executor.py：初始化Tracker 和 TrackerClient，获取run_class_paths、run_class_package、run_class_name，调用 report_task_update_to_driver(task_info=task_info)</p>
</li>
<li><p>task_executor.py：执行report_task_update_to_driver()<br>先在 ${task_log_dir}/fate_flow_schedule.log 输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:33,395] [90:139687957583680] - task_executor.py[line:318]: report task 202107260820309976351_upload_0 0 local 0 to driver</span><br></pre></td></tr></table></figure>
<p>然后调用ControllerClient.report_task</p>
</li>
<li>control_client.py：执行report_task<br>先在${job_log_dir}/${role}/${party}/DEBUG.log 中打日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:33,396] [90:139687957583680] - control_client.py[line:42]: request update job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0</span><br></pre></td></tr></table></figure>
然后发起http请求，endpoint是report。<br>流转流程同前文，调用链为 ControllerClient.report_task -&gt; fate_flow_server 通过flask -&gt; party_app.report_task() -&gt;   TaskController.update_task(task_info=task_info) -&gt; TaskController.update_task_status(task_info=task_info)</li>
</ol>
<p>在${job_log_dir}/fate_flow_audit.log 中的日志为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:33,396] [90:139687957583680] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/report</span><br><span class="line">[INFO] [2021-07-26 08:20:33,452] [90:139687957583680] - api_utils.py[line:129]: &#123;&quot;retcode&quot;:103,&quot;retmsg&quot;:&quot;update task status failed&quot;&#125;</span><br><span class="line"></span><br><span class="line">[INFO] [2021-07-26 08:20:33,452] [90:139687957583680] - api_utils.py[line:131]: remote http api response: /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/report &#123;&#x27;retcode&#x27;: 103, &#x27;retmsg&#x27;: &#x27;update task status failed&#x27;&#125;</span><br></pre></td></tr></table></figure><br>因为status一致，无法update，故failed.(同五中所述)</p>
<p>在${job_log_dir}/fate_flow_schedule.log 中输出日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:33,404] [1:140259119585024] - job_saver.py[line:81]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0</span><br><span class="line">[INFO] [2021-07-26 08:20:33,422] [1:140259119585024] - job_saver.py[line:84]: job 202107260820309976351 task 202107260820309976351_upload_0 0 update successfully</span><br><span class="line">[INFO] [2021-07-26 08:20:33,429] [1:140259119585024] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br><span class="line">[INFO] [2021-07-26 08:20:33,438] [1:140259119585024] - job_saver.py[line:76]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status update does not take effect: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;component_name&#x27;: &#x27;upload_0&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: &#x27;0&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;run_ip&#x27;: &#x27;10.200.96.235&#x27;, &#x27;run_pid&#x27;: 90, &#x27;party_status&#x27;: &#x27;running&#x27;&#125;</span><br></pre></td></tr></table></figure></p>
<p>在${job_log_dir}/peewee.log中输出日志为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:33,409] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE (((((`t1`.`f_job_id` = %s) AND (`t1`.`f_task_id` = %s)) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:33,416] [1:140259119585024] - peewee.py[line:2863]: (&#x27;UPDATE `t_task` SET `f_component_name` = %s, `f_run_ip` = %s, `f_run_pid` = %s WHERE (((((`t_task`.`f_job_id` = %s) AND (`t_task`.`f_task_id` = %s)) AND (`t_task`.`f_task_version` = %s)) AND (`t_task`.`f_role` = %s)) AND (`t_task`.`f_party_id` = %s))&#x27;, [&#x27;upload_0&#x27;, &#x27;10.200.96.235&#x27;, 90, &#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br><span class="line"></span><br><span class="line">[DEBUG] [2021-07-26 08:20:33,425] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE ((((`t1`.`f_task_id` = %s) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br><span class="line"></span><br><span class="line">[DEBUG] [2021-07-26 08:20:33,433] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE (((((`t1`.`f_job_id` = %s) AND (`t1`.`f_task_id` = %s)) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br><span class="line"></span><br><span class="line">[DEBUG] [2021-07-26 08:20:33,441] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE ((((`t1`.`f_task_id` = %s) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure></p>
<ol>
<li><p>task<em>executor.py：初始化环境变量，设置session<br>sess.init<em>federation 会调用federation/eggroll/_federation.py 的 __init</em></em>，调用如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:39,837] [90:139687957583680] - _federation.py[line:35]: [federation.eggroll]init federation: rp_session_id=202107260820309976351_upload_0_0_local_0, rs_session_id=202107260820309976351_upload_0_0, party=Party(role=local, party_id=0), proxy_endpoint=rollsite:9370</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,837] [90:139687957583680] - _federation.py[line:45]: [federation.eggroll]init federation context done</span><br></pre></td></tr></table></figure>
</li>
<li><p>task_executor.py：开始run task<br>先在${job_log_dir}/${role}/${party}/DEBUG.log 打出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:39,837] [90:139687957583680] - task_executor.py[line:156]: Run 202107260820309976351 upload_0 202107260820309976351_upload_0 local 0 task</span><br><span class="line">[INFO] [2021-07-26 08:20:39,838] [90:139687957583680] - task_executor.py[line:157]: Component parameters on party &#123;&#x27;UploadParam&#x27;: &#123;&#x27;file&#x27;: &#x27;/data/projects/fate/jobs/202107260820309976351/fate_upload_tmp/breast_hetero_guest.csv&#x27;, &#x27;head&#x27;: 1, &#x27;id_delimiter&#x27;: &#x27;,&#x27;, &#x27;partition&#x27;: 1, &#x27;namespace&#x27;: &#x27;cl&#x27;, &#x27;name&#x27;: &#x27;hetero_guest&#x27;, &#x27;storage_engine&#x27;: &#x27;&#x27;, &#x27;storage_address&#x27;: None, &#x27;destroy&#x27;: False&#125;, &#x27;initiator&#x27;: &#123;&#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: 0&#125;, &#x27;job_parameters&#x27;: &#123;&#x27;job_type&#x27;: &#x27;train&#x27;, &#x27;work_mode&#x27;: 1, &#x27;backend&#x27;: 0, &#x27;computing_engine&#x27;: &#x27;EGGROLL&#x27;, &#x27;federation_engine&#x27;: &#x27;EGGROLL&#x27;, &#x27;storage_engine&#x27;: &#x27;EGGROLL&#x27;, &#x27;engines_address&#x27;: &#123;&#x27;computing&#x27;: &#123;&#x27;cores_per_node&#x27;: 20, &#x27;nodes&#x27;: 1&#125;, &#x27;federation&#x27;: &#123;&#x27;host&#x27;: &#x27;rollsite&#x27;, &#x27;port&#x27;: 9370&#125;, &#x27;storage&#x27;: &#123;&#x27;cores_per_node&#x27;: 20, &#x27;nodes&#x27;: 1&#125;&#125;, &#x27;federated_mode&#x27;: &#x27;MULTIPLE&#x27;, &#x27;task_parallelism&#x27;: 1, &#x27;computing_partitions&#x27;: 4, &#x27;federated_status_collect_type&#x27;: &#x27;PULL&#x27;, &#x27;model_id&#x27;: &#x27;local-0#model&#x27;, &#x27;model_version&#x27;: &#x27;202107260820309976351&#x27;, &#x27;eggroll_run&#x27;: &#123;&#x27;eggroll.session.processors.per.node&#x27;: 4&#125;, &#x27;spark_run&#x27;: &#123;&#125;, &#x27;rabbitmq_run&#x27;: &#123;&#125;, &#x27;adaptation_parameters&#x27;: &#123;&#x27;task_nodes&#x27;: 1, &#x27;task_cores_per_node&#x27;: 4, &#x27;task_memory_per_node&#x27;: 0, &#x27;request_task_cores&#x27;: 4, &#x27;if_initiator_baseline&#x27;: False&#125;&#125;, &#x27;role&#x27;: &#123;&#x27;local&#x27;: [0]&#125;, &#x27;component_parameters&#x27;: &#123;&#x27;role&#x27;: &#123;&#x27;local&#x27;: &#123;&#x27;0&#x27;: &#123;&#x27;upload_0&#x27;: &#123;&#x27;name&#x27;: &#x27;hetero_guest&#x27;, &#x27;head&#x27;: 1, &#x27;file&#x27;: &#x27;/data/projects/fate/jobs/202107260820309976351/fate_upload_tmp/breast_hetero_guest.csv&#x27;, &#x27;partition&#x27;: 1, &#x27;namespace&#x27;: &#x27;cl&#x27;, &#x27;destroy&#x27;: False&#125;&#125;&#125;&#125;&#125;, &#x27;dsl_version&#x27;: 2, &#x27;local&#x27;: &#123;&#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: 0&#125;, &#x27;CodePath&#x27;: &#x27;fate_flow/components/upload.py/Upload&#x27;, &#x27;module&#x27;: &#x27;Upload&#x27;, &#x27;output_data_name&#x27;: None&#125;</span><br><span class="line">[INFO] [2021-07-26 08:20:39,838] [90:139687957583680] - task_executor.py[line:158]: Task input dsl &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>然后获取 task_run_args，配置run_object，后执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">profile.profile_start()</span><br><span class="line">run_object.run(component_parameters_on_party, task_run_args)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这里的run_object 是 Upload，run_object.run 即调用Upload.run()</p>
<ol>
<li>upload.py：执行run<br>根据 component_parameters 获取参数。<br>在${job_log_dir}/${role}/${party}/DEBUG.log 打出日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:39,883] [90:139687957583680] - upload.py[line:41]: &#123;&#x27;file&#x27;: &#x27;/data/projects/fate/jobs/202107260820309976351/fate_upload_tmp/breast_hetero_guest.csv&#x27;, &#x27;head&#x27;: 1, &#x27;id_delimiter&#x27;: &#x27;,&#x27;, &#x27;partition&#x27;: 1, &#x27;namespace&#x27;: &#x27;cl&#x27;, &#x27;name&#x27;: &#x27;hetero_guest&#x27;, &#x27;storage_engine&#x27;: &#x27;&#x27;, &#x27;storage_address&#x27;: None, &#x27;destroy&#x27;: False&#125;</span><br><span class="line">[INFO] [2021-07-26 08:20:39,883] [90:139687957583680] - upload.py[line:42]: &#123;&#x27;job_parameters&#x27;: &lt;fate_flow.entity.types.RunParameters object at 0x7f0b81a98b38&gt;&#125;</span><br></pre></td></tr></table></figure>
根据参数，设置各变量。</li>
</ol>
<p>build session<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:39,883] [90:139687957583680] - pool.py[line:129]: No connection available in pool.</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,889] [90:139687957583680] - pool.py[line:158]: Created new connection 139687331472832.</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,891] [90:139687957583680] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_date`, `t1`.`f_update_date`, `t1`.`f_name`, `t1`.`f_namespace`, `t1`.`f_address`, `t1`.`f_engine`, `t1`.`f_type`, `t1`.`f_options`, `t1`.`f_partitions`, `t1`.`f_id_delimiter`, `t1`.`f_in_serialized`, `t1`.`f_have_head`, `t1`.`f_schema`, `t1`.`f_count`, `t1`.`f_part_of_data`, `t1`.`f_description`, `t1`.`f_create_time`, `t1`.`f_update_time` FROM `t_storage_table_meta` AS `t1` WHERE ((`t1`.`f_name` = %s) AND (`t1`.`f_namespace` = %s))&#x27;, [&#x27;hetero_guest&#x27;, &#x27;cl&#x27;])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,894] [90:139687957583680] - pool.py[line:185]: Returning 139687331472832 to pool.</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,966] [90:139687957583680] - peewee.py[line:2863]: (&#x27;INSERT INTO `t_session_record` (`f_session_id`, `f_create_date`, `f_update_time`, `f_update_date`, `f_engine_name`, `f_engine_type`, `f_engine_address`, `f_create_time`) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)&#x27;, [&#x27;202107260820309976351_upload_0_0_local_0_storage_5cbb3a88edea11ebbccccaf5cc2d708a&#x27;, datetime.datetime(2021, 7, 26, 8, 20, 39), 1627287639962, datetime.datetime(2021, 7, 26, 8, 20, 39), &#x27;STANDALONE&#x27;, &#x27;storage&#x27;, &#x27;&#123;&#125;&#x27;, 1627287639962])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,973] [90:139687957583680] - _session.py[line:144]: save session 202107260820309976351_upload_0_0_local_0_storage_5cbb3a88edea11ebbccccaf5cc2d708a record</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,974] [90:139687957583680] - pool.py[line:185]: Returning 139687331472832 to pool.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:39,975] [90:139687957583680] - peewee.py[line:2863]: (&#x27;DELETE FROM `t_session_record` WHERE (`t_session_record`.`f_session_id` = %s)&#x27;, [&#x27;202107260820309976351_upload_0_0_local_0_storage_5cbb3a88edea11ebbccccaf5cc2d708a&#x27;])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,981] [90:139687957583680] - _session.py[line:153]: delete session 202107260820309976351_upload_0_0_local_0_storage_5cbb3a88edea11ebbccccaf5cc2d708a record</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,981] [90:139687957583680] - pool.py[line:185]: Returning 139687331472832 to pool.</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,985] [90:139687957583680] - peewee.py[line:2863]: (&#x27;INSERT INTO `t_session_record` (`f_session_id`, `f_create_date`, `f_update_time`, `f_update_date`, `f_engine_name`, `f_engine_type`, `f_engine_address`, `f_create_time`) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)&#x27;, [&#x27;202107260820309976351_upload_0_0_local_0_storage_5cca2ef8edea11ebbccccaf5cc2d708a&#x27;, datetime.datetime(2021, 7, 26, 8, 20, 39), 1627287639985, datetime.datetime(2021, 7, 26, 8, 20, 39), &#x27;EGGROLL&#x27;, &#x27;storage&#x27;, &#x27;&#123;&#125;&#x27;, 1627287639985])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,989] [90:139687957583680] - _session.py[line:144]: save session 202107260820309976351_upload_0_0_local_0_storage_5cca2ef8edea11ebbccccaf5cc2d708a record</span><br><span class="line">[DEBUG] [2021-07-26 08:20:39,989] [90:139687957583680] - pool.py[line:185]: Returning 139687331472832 to pool.</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if table:</span><br><span class="line">    LOGGER.info(f&quot;destroy table name: &#123;name&#125; namespace: &#123;namespace&#125; engine: &#123;table.get_engine()&#125;&quot;)</span><br><span class="line">    table.destroy()</span><br><span class="line">else:</span><br><span class="line">    LOGGER.info(f&quot;can not found table name: &#123;name&#125; namespace: &#123;namespace&#125;, pass destroy&quot;)</span><br></pre></td></tr></table></figure>
<p><strong>注：如果有destroy 参数，会调用table.destroy</strong><br>更新upload的address,在${job_log_dir}/${role}/${party}/DEBUG.log 打出日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:41,836] [90:139687957583680] - upload.py[line:95]: upload to EGGROLL storage, address: &#123;&#x27;cores_per_node&#x27;: 20, &#x27;nodes&#x27;: 1, &#x27;name&#x27;: &#x27;hetero_guest&#x27;, &#x27;namespace&#x27;: &#x27;cl&#x27;, &#x27;storage_type&#x27;: &#x27;LMDB&#x27;&#125;</span><br></pre></td></tr></table></figure><br>这个address 就是LMDB 的存储位置<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">address = storage.StorageTableMeta.create_address(storage_engine=storage_engine, address_dict=address_dict)</span><br><span class="line">self.parameters[&quot;partitions&quot;] = partitions</span><br><span class="line">self.parameters[&quot;name&quot;] = name</span><br><span class="line">self.table = storage_session.create_table(address=address, **self.parameters)</span><br><span class="line">data_table_count = self.save_data_table(job_id, name, namespace, head)</span><br><span class="line">self.table.get_meta().update_metas(in_serialized=True)</span><br></pre></td></tr></table></figure><br>如果是使用local 模式调试，在项目目录下会生成data目录。<br><img src="/image/fate/02d76fd6588e43c39d28b9b6bd8484e2.png" alt="在这里插入图片描述"></p>
<p>如果是kubeFATE 部署，该数据位于 nodemanager 的 /data/projects/fate/eggroll/data/LMDB 目录下<br><img src="/image/fate/15bb01d3c0854489a5f209ec5736ac4b.png" alt="在这里插入图片描述"></p>
<p>依次为创建元数据，建表，保存数据，更新元数据</p>
<ol>
<li>upload.py：执行save_data_table ，<br>获取文件schma。<br>按最大文件块读取（    lines = fin.readlines(self.MAX_BYTES)），保存至LMDB<br>进度计算如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save_progress = lines_count/input_feature_count*100//1</span><br></pre></td></tr></table></figure>
故而这里的进度和MAX_BYTES 有关。</li>
</ol>
<ol>
<li>upload.py： 调用ControllerClient.update_job(job_info=job_info) 更新task 状态（主要是进度），control_client.update_job<br>流转流程同前文，调用链为 ControllerClient.update_job -&gt; fate_flow_server 通过flask -&gt; party_app.update_task() -&gt;   TaskController.update_task(task_info=task_info) </li>
</ol>
<p>输出日志</p>
<p>${job_log_dir}/${role}/${party}/DEBUG.log<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:41,942] [90:139687957583680] - control_client.py[line:26]: request update job 202107260820309976351 on local 0</span><br></pre></td></tr></table></figure></p>
<p>在${job_log_dir}/fate_flow_audit.log 中的日志为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:41,942] [90:139687957583680] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/party/202107260820309976351/local/0/update</span><br><span class="line">[INFO] [2021-07-26 08:20:41,966] [90:139687957583680] - api_utils.py[line:129]: &#123;&quot;retcode&quot;:0,&quot;retmsg&quot;:&quot;success&quot;&#125;</span><br><span class="line"></span><br><span class="line">[INFO] [2021-07-26 08:20:41,966] [90:139687957583680] - api_utils.py[line:131]: remote http api response: /v1/party/202107260820309976351/local/0/update &#123;&#x27;retcode&#x27;: 0, &#x27;retmsg&#x27;: &#x27;success&#x27;&#125;</span><br></pre></td></tr></table></figure></p>
<p>在${job_log_dir}/fate_flow_schedule.log 中输出日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:41,950] [1:140259119585024] - job_saver.py[line:61]: try to update job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:41,963] [1:140259119585024] - job_saver.py[line:64]: job 202107260820309976351 update successfully: &#123;&#x27;progress&#x27;: 100.0, &#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;&#125;</span><br></pre></td></tr></table></figure></p>
<p>在${job_log_dir}/peewee.log中输出日志为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:41,954] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_user_id`, `t1`.`f_job_id`, `t1`.`f_name`, `t1`.`f_description`, `t1`.`f_tag`, `t1`.`f_dsl`, `t1`.`f_runtime_conf`, `t1`.`f_runtime_conf_on_party`, `t1`.`f_train_runtime_conf`, `t1`.`f_roles`, `t1`.`f_work_mode`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_is_initiator`, `t1`.`f_progress`, `t1`.`f_ready_signal`, `t1`.`f_ready_time`, `t1`.`f_cancel_signal`, `t1`.`f_cancel_time`, `t1`.`f_rerun_signal`, `t1`.`f_end_scheduling_updates`, `t1`.`f_engine_name`, `t1`.`f_engine_type`, `t1`.`f_cores`, `t1`.`f_memory`, `t1`.`f_remaining_cores`, `t1`.`f_remaining_memory`, `t1`.`f_resource_in_use`, `t1`.`f_apply_resource_time`, `t1`.`f_return_resource_time`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_job` AS `t1` WHERE (((`t1`.`f_job_id` = %s) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:41,960] [1:140259119585024] - peewee.py[line:2863]: (&#x27;UPDATE `t_job` SET `f_progress` = %s WHERE ((((`t_job`.`f_job_id` = %s) AND (`t_job`.`f_role` = %s)) AND (`t_job`.`f_party_id` = %s)) AND (`t_job`.`f_progress` &lt;= %s))&#x27;, [100, &#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;, 100])</span><br></pre></td></tr></table></figure></p>
<ol>
<li>upload.py： 回到9，继续保存文件，将data存入LMDB。当所有文件都存入完毕，更新metadata，更新tracker<br>在task_executor.py 中是<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run_object.set_tracker(tracker=tracker_client)</span><br></pre></td></tr></table></figure>
故而这里self.tracker 调用的是TrackerClient<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">self.tracker.log_output_data_info(data_name=&#x27;upload&#x27;,</span><br><span class="line">                                  table_namespace=dst_table_namespace,</span><br><span class="line">                                  table_name=dst_table_name)</span><br><span class="line"></span><br><span class="line">self.tracker.log_metric_data(metric_namespace=&quot;upload&quot;,</span><br><span class="line">                             metric_name=&quot;data_access&quot;,</span><br><span class="line">                             metrics=[Metric(&quot;count&quot;, table_count)])</span><br><span class="line">self.tracker.set_metric_meta(metric_namespace=&quot;upload&quot;,</span><br><span class="line">                             metric_name=&quot;data_access&quot;,</span><br><span class="line">                             metric_meta=MetricMeta(name=&#x27;upload&#x27;, metric_type=&#x27;UPLOAD&#x27;))</span><br></pre></td></tr></table></figure>
对应的分别是log_output_data_DEBUG.log_metric_data，set_metric_meta三个方法<br>输出日志${job_log_dir}/${role}/${party}/DEBUG.log <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:42,704] [90:139687957583680] - tracker_client.py[line:127]: Request save job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0 data upload info</span><br><span class="line">[INFO] [2021-07-26 08:20:43,044] [1:140259119585024] - job_tracker.py[line:97]: save job 202107260820309976351 component upload_0 on local 0 upload data_access metric meta</span><br><span class="line">[INFO] [2021-07-26 08:20:44,838] [90:139687957583680] - job_tracker.py[line:159]: task id 202107260820309976351_upload_0 output data table is none</span><br><span class="line"></span><br></pre></td></tr></table></figure>
发起http请求，对应的${job_log_dir}/fate_flow_audit.log 中的日志为<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:42,704] [90:139687957583680] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/output_data_info/save</span><br><span class="line">[INFO] [2021-07-26 08:20:43,009] [90:139687957583680] - api_utils.py[line:129]: &#123;&quot;retcode&quot;:0,&quot;retmsg&quot;:&quot;success&quot;&#125;</span><br><span class="line"></span><br><span class="line">[INFO] [2021-07-26 08:20:43,010] [90:139687957583680] - api_utils.py[line:131]: remote http api response: /v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/output_data_info/save &#123;&#x27;retcode&#x27;: 0, &#x27;retmsg&#x27;: &#x27;success&#x27;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[INFO] [2021-07-26 08:20:43,011] [90:139687957583680] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/metric_data/save</span><br><span class="line">[INFO] [2021-07-26 08:20:43,036] [90:139687957583680] - api_utils.py[line:129]: &#123;&quot;retcode&quot;:0,&quot;retmsg&quot;:&quot;success&quot;&#125;</span><br><span class="line"></span><br><span class="line">[INFO] [2021-07-26 08:20:43,036] [90:139687957583680] - api_utils.py[line:131]: remote http api response: /v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/metric_data/save &#123;&#x27;retcode&#x27;: 0, &#x27;retmsg&#x27;: &#x27;success&#x27;&#125;</span><br><span class="line"></span><br><span class="line">[INFO] [2021-07-26 08:20:43,037] [90:139687957583680] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/metric_meta/save</span><br><span class="line">[INFO] [2021-07-26 08:20:43,056] [90:139687957583680] - api_utils.py[line:129]: &#123;&quot;retcode&quot;:0,&quot;retmsg&quot;:&quot;success&quot;&#125;</span><br><span class="line"></span><br><span class="line">[INFO] [2021-07-26 08:20:43,056] [90:139687957583680] - api_utils.py[line:131]: remote http api response: /v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/metric_meta/save &#123;&#x27;retcode&#x27;: 0, &#x27;retmsg&#x27;: &#x27;success&#x27;&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>对应的调用链是 TrackerClient.log_output_data_info() -&gt; fate_flow_server -&gt; tracker_app -&gt; job_tracker<br>在${job_log_dir}/fate_flow_schedule.log 中输出日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:43,018] [1:140259119585024] - job_tracker.py[line:74]: save job 202107260820309976351 component upload_0 on local 0 upload data_access metric data</span><br><span class="line">[INFO] [2021-07-26 08:20:43,044] [1:140259119585024] - job_tracker.py[line:97]: save job 202107260820309976351 component upload_0 on local 0 upload data_access metric meta</span><br><span class="line">[INFO] [2021-07-26 08:20:44,838] [90:139687957583680] - job_tracker.py[line:159]: task id 202107260820309976351_upload_0 output data table is none</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>save完毕，返回table_count。</p>
<ol>
<li>upload.py： 打印完成日志，并清理临时文件，输出统计信息<br>${job_log_dir}/${role}/${party}/DEBUG.log <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:44,822] [90:139687957583680] - upload.py[line:102]: ------------load data finish!-----------------</span><br><span class="line">[INFO] [2021-07-26 08:20:44,822] [90:139687957583680] - upload.py[line:106]: remove tmp upload file</span><br><span class="line">[INFO] [2021-07-26 08:20:44,823] [90:139687957583680] - upload.py[line:107]: /data/projects/fate/jobs/202107260820309976351/fate_upload_tmp</span><br><span class="line">[INFO] [2021-07-26 08:20:44,823] [90:139687957583680] - upload.py[line:111]: file: /data/projects/fate/jobs/202107260820309976351/fate_upload_tmp/breast_hetero_guest.csv</span><br><span class="line">[INFO] [2021-07-26 08:20:44,824] [90:139687957583680] - upload.py[line:112]: total data_count: 569</span><br><span class="line">[INFO] [2021-07-26 08:20:44,824] [90:139687957583680] - upload.py[line:113]: table name: hetero_guest, table namespace: cl</span><br></pre></td></tr></table></figure></li>
<li><p>upload.py：回到8 ，执行profile.profile_ends()<br>profile.profile_ends() 会打出${task_log_dir}/PROFILING.log中的日志（分别收集到INFO，DEBUG中）<br>${job_log_dir}/${role}/${party}/DEBUG.log </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:44,837] [90:139687957583680] - profile.py[line:249]: </span><br><span class="line">Computing:</span><br><span class="line">+----------+------------------------------------------+</span><br><span class="line">| function |                                          |</span><br><span class="line">+----------+------------------------------------------+</span><br><span class="line">|  total   | n=0, sum=0.0000, mean=0.0000, max=0.0000 |</span><br><span class="line">+----------+------------------------------------------+</span><br><span class="line"></span><br><span class="line">Federation:</span><br><span class="line">+--------+------------------------------------------+</span><br><span class="line">|  get   |                                         |</span><br><span class="line">+--------+------------------------------------------+</span><br><span class="line">| remote |                                          |</span><br><span class="line">+--------+------------------------------------------+</span><br><span class="line">| total  | n=0, sum=0.0000, mean=0.0000, max=0.0000 |</span><br><span class="line">+--------+------------------------------------------+</span><br><span class="line"></span><br><span class="line">[DEBUG] [2021-07-26 08:20:44,838] [90:139687957583680] - profile.py[line:250]: </span><br><span class="line">Detailed Computing:</span><br><span class="line">+-------+------------------------------------------+</span><br><span class="line">| stack |                                          |</span><br><span class="line">+-------+------------------------------------------+</span><br><span class="line">| total | n=0, sum=0.0000, mean=0.0000, max=0.0000 |</span><br><span class="line">+-------+------------------------------------------+</span><br></pre></td></tr></table></figure>
</li>
<li><p>task_executor.py：执行完毕之后，再save_data ，save_out_model，然后调用report_task_update_to_driver。同4、5。再输出统计信息<br>${job_log_dir}/${role}/${party}/DEBUG.log </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:44,838] [90:139687957583680] - task_executor.py[line:318]: report task 202107260820309976351_upload_0 0 local 0 to driver</span><br><span class="line">[INFO] [2021-07-26 08:20:44,838] [90:139687957583680] - control_client.py[line:42]: request update job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0</span><br><span class="line">[INFO] [2021-07-26 08:20:44,938] [90:139687957583680] - task_executor.py[line:207]: task 202107260820309976351_upload_0 local 0 start time: 2021-07-26 08:20:33</span><br><span class="line">[INFO] [2021-07-26 08:20:44,939] [90:139687957583680] - task_executor.py[line:209]: task 202107260820309976351_upload_0 local 0 end time: 2021-07-26 08:20:44</span><br><span class="line">[INFO] [2021-07-26 08:20:44,939] [90:139687957583680] - task_executor.py[line:211]: task 202107260820309976351_upload_0 local 0 takes 11.447s</span><br><span class="line">[INFO] [2021-07-26 08:20:44,939] [90:139687957583680] - task_executor.py[line:214]: Finish 202107260820309976351 upload_0 202107260820309976351_upload_0 0 local 0 task success</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>对应${job_log_dir}/fate_flow_schedule.log 中输出日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:44,844] [1:140259119585024] - job_saver.py[line:81]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0</span><br><span class="line">[INFO] [2021-07-26 08:20:44,864] [1:140259119585024] - job_saver.py[line:84]: job 202107260820309976351 task 202107260820309976351_upload_0 0 update successfully</span><br><span class="line">[INFO] [2021-07-26 08:20:44,873] [1:140259119585024] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br><span class="line">[INFO] [2021-07-26 08:20:44,908] [1:140259119585024] - job_saver.py[line:74]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status successfully: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;component_name&#x27;: &#x27;upload_0&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: &#x27;0&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;run_ip&#x27;: &#x27;10.200.96.235&#x27;, &#x27;run_pid&#x27;: 90, &#x27;party_status&#x27;: &#x27;success&#x27;, &#x27;end_time&#x27;: 1627287644838, &#x27;elapsed&#x27;: 11447&#125;</span><br></pre></td></tr></table></figure></p>
<ol>
<li>task_executor.py：TaskExecutor.run_task()执行完毕，执行 TaskExecutor.report_task_update_to_driver(task_info=task_info)<br>${job_log_dir}/${role}/${party}/DEBUG.log <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:44,940] [90:139687957583680] - task_executor.py[line:318]: report task 202107260820309976351_upload_0 0 local 0 to driver</span><br><span class="line">[INFO] [2021-07-26 08:20:44,940] [90:139687957583680] - control_client.py[line:42]: request update job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>对应${job_log_dir}/fate_flow_schedule.log 中输出日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:44,947] [1:140259119585024] - job_saver.py[line:81]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0</span><br><span class="line">[WARNING] [2021-07-26 08:20:44,972] [1:140259119585024] - job_saver.py[line:86]: job 202107260820309976351 task 202107260820309976351_upload_0 0 update does not take effect</span><br><span class="line">[INFO] [2021-07-26 08:20:44,996] [1:140259119585024] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br><span class="line">[INFO] [2021-07-26 08:20:45,015] [1:140259119585024] - job_saver.py[line:76]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status update does not take effect: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;component_name&#x27;: &#x27;upload_0&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: &#x27;0&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;run_ip&#x27;: &#x27;10.200.96.235&#x27;, &#x27;run_pid&#x27;: 90, &#x27;party_status&#x27;: &#x27;success&#x27;, &#x27;end_time&#x27;: 1627287644838, &#x27;elapsed&#x27;: 11447&#125;</span><br></pre></td></tr></table></figure><br>注：这里的日志会和dag_scheduler 轮询的日志混在一起。区别就是 这个部分有run_pid。</p>
<ol>
<li>返回执行结果，对应1<br>至此，整个task 执行完毕。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-6-upload-job-schedule/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-6-upload-job-schedule/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（六）upload任务task schedule阶段</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:11:47 / Modified: 13:36:39" itemprop="dateCreated datePublished" datetime="2023-08-20T12:11:47+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>在前文的基础上，因为job已经处于running状态，会按照task的依赖关系，依次调度该job下的task。</p>
<p> 调度之后的操作有2部分： </p>
<ul>
<li>Part1. 申请资源  </li>
<li>Part2. start job：将job的状态从waiting -&gt; running 状态<br>涉及的主要方法：   dag_scheduler.schedule_running_jobs()</li>
</ul>
<h1 id="执行步骤"><a href="#执行步骤" class="headerlink" title="执行步骤"></a>执行步骤</h1><p><img src="/image/fate/8ea2c9e7fee841dc82c8448a00efbf5d.png" alt="在这里插入图片描述"></p>
<ol>
<li>dag_scheduler.py：rundo轮询，发现处于running状态的job（这一部分见fate flow server 启动部分）<br>对应fate_flow/fate_flow_schedule.log依次为<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,117] [1:140259369826048] - dag_scheduler.py[line:148]: start schedule running jobs</span><br><span class="line">[INFO] [2021-07-26 08:20:32,127] [1:140259369826048] - dag_scheduler.py[line:150]: have 1 running jobs</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>对应查询running状态的fate_flow/peewee.log为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:34,354] [1:140259369826048] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_user_id`, `t1`.`f_job_id`, `t1`.`f_name`, `t1`.`f_description`, `t1`.`f_tag`, `t1`.`f_dsl`, `t1`.`f_runtime_conf`, `t1`.`f_runtime_conf_on_party`, `t1`.`f_train_runtime_conf`, `t1`.`f_roles`, `t1`.`f_work_mode`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_is_initiator`, `t1`.`f_progress`, `t1`.`f_ready_signal`, `t1`.`f_ready_time`, `t1`.`f_cancel_signal`, `t1`.`f_cancel_time`, `t1`.`f_rerun_signal`, `t1`.`f_end_scheduling_updates`, `t1`.`f_engine_name`, `t1`.`f_engine_type`, `t1`.`f_cores`, `t1`.`f_memory`, `t1`.`f_remaining_cores`, `t1`.`f_remaining_memory`, `t1`.`f_resource_in_use`, `t1`.`f_apply_resource_time`, `t1`.`f_return_resource_time`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_job` AS `t1` WHERE ((`t1`.`f_is_initiator` = %s) AND (`t1`.`f_status` = %s)) ORDER BY `t1`.`f_create_time` ASC&#x27;, [True, &#x27;running&#x27;])</span><br></pre></td></tr></table></figure></p>
<ol>
<li>dag_scheduler.py：执行schedule_running_jobs 调度处于running 状态的job。<br>先在${job_log_dir}/fate_flow_schedule.log 输出<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,128] [1:140259369826048] - dag_scheduler.py[line:152]: schedule running job 202107260820309976351</span><br></pre></td></tr></table></figure></li>
<li>dag_scheduler.py：调用schedule_utils.get_job_dsl_parser 解析参数</li>
<li>schedule_utils.py：返回解析完毕的 dsl_parser</li>
<li>dag_scheduler.py：调用TaskScheduler.schedule(job=job, dsl_parser=dsl_parser, canceled=job.f_cancel_signal)调度task，注意这里的f_cancel_signal，这个是在detector 轮询时，更新的状态。</li>
<li>task_scheduler.py：执行task调度。<br>先在${job_log_dir}/fate_flow_schedule.log 输出<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,130] [1:140259369826048] - task_scheduler.py[line:28]: scheduling job 202107260820309976351 tasks</span><br></pre></td></tr></table></figure>
调用JobSaver.get_tasks_asc 获取相关信息。</li>
<li>job_saver.py： 执行如下源码，获取该job对应的task<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tasks = Task.select().where(Task.f_job_id == job_id, Task.f_role == role, Task.f_party_id == party_id).order_by(Task.f_create_time.asc())</span><br><span class="line">tasks_group = cls.get_latest_tasks(tasks=tasks)</span><br></pre></td></tr></table></figure>
按照create_time，升序获取当前job中涉及的task。从前文可知，create job 的时候，会根据job涉及的component， 依次create 不同的task ，所以在这里按照create_time顺序获取，也就是task的执行顺序（？如果db出问题，create_time 乱了，咋玩？）<br>操作数据库的日志在fate_flow/peewee.log 中</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,133] [1:140259369826048] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE (((`t1`.`f_job_id` = %s) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s)) ORDER BY `t1`.`f_create_time` ASC&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
<p>get_latest_tasks 的作用是，获取new version 的task。<br>最后，将需要执行的tasks 返回给task_scheduler</p>
<ol>
<li>task_scheduler.py：遍历待执行的task，针对每个task执行如下操作：<br>判断federated_status_collect_type，如是PULL 需要执行collect_task_of_all_party()通过调用JobSaver.query_task()获取各个party 上task的信息。（步骤9 -10）<br>调用federated_task_status 并计算当前task状态（11-13）<br>更新task状态 14<br>加入waiting task 队列 15<br><strong>注：PULL需要主动拉取多方计算下，其余party上，对应task的信息</strong></li>
<li>job_saver.py：执行query_task，返回结果，对应的fate_flow/peewee.log日志如下<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,139] [1:140259369826048] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE ((`t1`.`f_task_id` = %s) AND (`t1`.`f_task_version` = %s))&#x27;, [&#x27;202107260820309976351_upload_0&#x27;, 0])</span><br></pre></td></tr></table></figure></li>
<li><p>task_scheduler.py：紧接着8，对9的查询结果进行判断。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if not len(tasks_status_on_all) &gt; 1 and not TaskStatus.RUNNING in tasks_status_on_all:</span><br><span class="line">    return</span><br></pre></td></tr></table></figure>
<p>当前是upload任务，不涉及多方计算，故len(tasks_status_on_all) = 1，且此时task处于waiting，故直接返回，后面task 变为runing，便会执行下文的collect。</p>
</li>
<li><p>task_scheduler.py：执行federated_task_status 获取当前task状态。先调用JobSaver.query_job()进行查询</p>
</li>
<li>job_saver.py：执行query_task，返回结果，对应的fate_flow/peewee.log日志如下<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,144] [1:140259369826048] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE ((`t1`.`f_task_id` = %s) AND (`t1`.`f_task_version` = %s))&#x27;, [&#x27;202107260820309976351_upload_0&#x27;, 0])</span><br></pre></td></tr></table></figure></li>
<li><p>task_scheduler.py：判断除non-idmapping role之外，所有的party上，该task的状态（？non-idmapping 这段逻辑没看懂），如存在非SUCCESS状态的，则收集所有状态，调用calculate_multi_party_task_status() 计算当前状态。并输出日志到${job_log_dir}/fate_flow_schedule.log </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,148] [1:140259369826048] - task_scheduler.py[line:143]: job 202107260820309976351 task 202107260820309976351_upload_0 0 status is waiting, calculate by task party status list: [&#x27;waiting&#x27;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>task_scheduler.py：判断13计算得到的状态和原状态是否一致，如不一致，则更新原状态，并调用FederatedScheduler.sync_task_status 更新各个party该task的状态。（这里都为waiting，状态一致无需更新）</p>
</li>
<li><p>task_scheduler.py：判断状态，如为waiting则加入waiting_tasks队列，如为EndStatus，则调用FederatedScheduler.stop_task</p>
</li>
<li><p>task_scheduler.py：判断是否canceled，如未cancel 则遍历waiting_tasks执行17-48。（疑问：为啥不是先判断？）</p>
</li>
<li><p>task_scheduler.py：针对每个task，调用dsl_parser.get_upstream_dependent_components() 获取其依赖的components，如果前置components中存在未success的，break跳出遍历。<br>（？？ 存疑 这里的else缩进）</p>
</li>
<li><p>task_scheduler.py：调用start_task，启动task。<br>执行第一步，先输出日志到${job_log_dir}/fate_flow_schedule.log </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,148] [1:140259369826048] - task_scheduler.py[line:80]: try to start job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0</span><br></pre></td></tr></table></figure>
</li>
<li><p>task_scheduler.py：调用ResourceManager.apply_for_task_resource 申请资源</p>
</li>
<li><p>resource_manager.py：执行resource_for_task，先调用calculate_task_resource计算该task所需的资源。<br>这里需要注意的是，调用的代码是</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cores_per_task, memory_per_task = cls.calculate_task_resource(task_info=task_info)</span><br></pre></td></tr></table></figure>
<p>而calculate_task_resource的定义是</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def calculate_task_resource(cls, task_parameters: RunParameters = None, task_info: dict = None):</span><br><span class="line">    if not task_parameters:</span><br><span class="line">        job_parameters = job_utils.get_job_parameters(job_id=task_info[&quot;job_id&quot;],</span><br><span class="line">                                                      role=task_info[&quot;role&quot;],</span><br><span class="line">                                                      party_id=task_info[&quot;party_id&quot;])</span><br><span class="line">        task_parameters = RunParameters(**job_parameters)</span><br><span class="line">    if task_info[&quot;role&quot;] in IGNORE_RESOURCE_ROLES and task_parameters.computing_engine in SUPPORT_IGNORE_RESOURCE_ENGINES:</span><br><span class="line">        cores_per_task = 0</span><br><span class="line">        memory_per_task = 0</span><br><span class="line">    else:</span><br><span class="line">        cores_per_task = task_parameters.adaptation_parameters[&quot;task_cores_per_node&quot;] * \</span><br><span class="line">                         task_parameters.adaptation_parameters[&quot;task_nodes&quot;]</span><br><span class="line">        memory_per_task = task_parameters.adaptation_parameters[&quot;task_memory_per_node&quot;] * \</span><br><span class="line">                          task_parameters.adaptation_parameters[&quot;task_nodes&quot;]</span><br><span class="line">    return cores_per_task, memory_per_task</span><br></pre></td></tr></table></figure>
<p>task_parameters 为空，故而会调用job_utils.get_job_parameters 对应的fate_flow/peewee.log日志为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,149] [1:140259369826048] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_runtime_conf_on_party` FROM `t_job` AS `t1` WHERE (((`t1`.`f_job_id` = %s) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>如申请到的cores_per_task 和 memory_per_task 有非0值，则执行update_resource_sql 生成filters 和updates 操作，再更新resource表。<br>执行sql对应的fate_flow/peewee.log日志为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,152] [1:140259369826048] - peewee.py[line:2863]: (&#x27;UPDATE `t_job` SET `f_remaining_cores` = (`t_job`.`f_remaining_cores` - %s), `f_remaining_memory` = (`t_job`.`f_remaining_memory` - %s) WHERE ((((((`t_job`.`f_remaining_cores` &gt;= %s) AND (`t_job`.`f_remaining_memory` &gt;= %s)) AND (`t_job`.`f_job_id` = %s)) AND (`t_job`.`f_role` = %s)) AND (`t_job`.`f_party_id` = %s)) AND (`t_job`.`f_resource_in_use` = %s))&#x27;, [4, 0, 4, 0, &#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;, True])</span><br></pre></td></tr></table></figure><br>执行成功，会在${job_log_dir}/fate_flow_schedule.log 输出日志，并将成功状态返回<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,158] [1:140259369826048] - resource_manager.py[line:285]: task 202107260820309976351_upload_0 0 apply resource successfully</span><br></pre></td></tr></table></figure></p>
<ol>
<li><p>task_scheduler.py：若未申请资源成功，返回无资源。否则将task 状态置为running，并调用jobsaver.update_task_status 更新状态。</p>
</li>
<li><p>job_saver.py：执行update_task_status()<br>先在${job_log_dir}/fate_flow_schedule.log 输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,159] [1:140259369826048] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br></pre></td></tr></table></figure>
<p>执行update_status，先通过select，获取task基本信息，fate_flow/peewee.log日志为</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,160] [1:140259369826048] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE (((((`t1`.`f_job_id` = %s) AND (`t1`.`f_task_id` = %s)) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
<p>修改之后再update，fate_flow/peewee.log日志<br><strong>注：这里update 会是调用update_status() 方法，会先判断能否从oldStatus 转换成newStatus，如不能，不会执行update语句，直接返回false</strong><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,165] [1:140259369826048] - peewee.py[line:2863]: (&#x27;UPDATE `t_task` SET `f_status` = %s WHERE ((((((`t_task`.`f_job_id` = %s) AND (`t_task`.`f_task_id` = %s)) AND (`t_task`.`f_task_version` = %s)) AND (`t_task`.`f_role` = %s)) AND (`t_task`.`f_party_id` = %s)) AND (`t_task`.`f_status` = %s))&#x27;, [&#x27;running&#x27;, &#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;, &#x27;waiting&#x27;])</span><br></pre></td></tr></table></figure><br>如执行成功，则在${job_log_dir}/fate_flow_schedule.log 输出日志，并返回执行状态（如失败，打出失败日志update does not take effect）<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,172] [1:140259369826048] - job_saver.py[line:74]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status successfully: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: 0, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;status&#x27;: &#x27;running&#x27;&#125;</span><br></pre></td></tr></table></figure></p>
<ol>
<li>task_scheduler.py：如状态未更新成功，打出失败日志${job_log_dir}/fate_flow_schedule.log ，并回收资源。否则输出成功日志，对应18<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,173] [1:140259369826048] - task_scheduler.py[line:93]: start job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0</span><br></pre></td></tr></table></figure></li>
<li>task_scheduler.py：调用FederatedScheduler.sync_task_status() 同步状态至所有party</li>
<li><p>federated_scheduler.py： 执行sync_task_status()<br>先打印日志到${job_log_dir}/fate_flow_schedule.log </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,173] [1:140259369826048] - federated_scheduler.py[line:192]: job 202107260820309976351 task 202107260820309976351_upload_0 0 is running, sync to all party</span><br></pre></td></tr></table></figure>
<p>再调用 task_command() 通过 federated_coordination_on_http 发起http 请求</p>
</li>
<li><p>api_utils.py：发起请求，日志见 ${job_log_dir}/fate_flow_audit.log </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,175] [1:140259369826048] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/status/running</span><br></pre></td></tr></table></figure>
</li>
<li><p>fate_flow_server.py：接受请求，通过flask，转移到party_app</p>
</li>
<li><p>party_app.py： 执行task_status，调用TaskController.update_task_status(task_info=task_info)，更新task信息。实际操作是调用JobSaver.update_task_status</p>
</li>
<li><p>job_saver.py：执行update_task_status()<br>先输出日志到${job_log_dir}/fate_flow_schedule.log </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,183] [1:140259119585024] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br></pre></td></tr></table></figure>
<p>再执行update_status，先通过select，获取task基本信息，fate_flow/peewee.log日志为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,187] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE (((((`t1`.`f_job_id` = %s) AND (`t1`.`f_task_id` = %s)) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
<p>这里和22 的操作一样，但是时间戳不同。接下去update部分，则因为running状态不能转变为running 状态，不会执行update，所以就返回了false。<br>输出失败的日志到${job_log_dir}/fate_flow_schedule.log </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,192] [1:140259119585024] - job_saver.py[line:76]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status update does not take effect: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: &#x27;0&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;status&#x27;: &#x27;running&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>返回false 信息。<br>执行report_task_to_initiator(), 查询task信息，如task.f_federated_status_collect_typePUSH 架构下，调用FederatedScheduler.report_task_to_initiator() 主动推送信息。<br>对应的fate_flow/peewee.log日志为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,196] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE ((((`t1`.`f_task_id` = %s) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
<p>前文所述，这里是PULL，故不会执行。直接返回状态给app_party.py 对应28</p>
</li>
<li><p>party_app.py：返回执行失败信息，对应27</p>
</li>
<li>fate_flow_server.py：返回失败信息给api_utils.py 对应26</li>
<li>api_utils.py：接受失败信息，在${job_log_dir}/fate_flow_audit.log  输出如下日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,203] [1:140259369826048] - api_utils.py[line:129]: &#123;&quot;retcode&quot;:103,&quot;retmsg&quot;:&quot;update task status failed&quot;&#125;</span><br><span class="line"></span><br><span class="line">[INFO] [2021-07-26 08:20:32,203] [1:140259369826048] - api_utils.py[line:131]: remote http api response: /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/status/running &#123;&#x27;retcode&#x27;: 103, &#x27;retmsg&#x27;: &#x27;update task status failed&#x27;&#125;</span><br></pre></td></tr></table></figure>
对应的容器日志为<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/status/running HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure>
并返回结果给federated_scheduler.py 对应25</li>
<li><p>federated_scheduler.py：在${job_log_dir}/fate_flow_schedule.log 输出日志，并返回信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[WARNING] [2021-07-26 08:20:32,203] [1:140259369826048] - federated_scheduler.py[line:260]: an error occurred while status/running the task to role local party 0: </span><br><span class="line">update task status failed</span><br><span class="line">[INFO] [2021-07-26 08:20:32,203] [1:140259369826048] - federated_scheduler.py[line:197]: sync job 202107260820309976351 task 202107260820309976351_upload_0 0 status running to all party failed: </span><br><span class="line">&#123;&#x27;local&#x27;: &#123;0: &#123;&#x27;retcode&#x27;: 103, &#x27;retmsg&#x27;: &#x27;update task status failed&#x27;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>task_scheduler.py：调用FederatedScheduler.start_task() 启动多方任务</p>
</li>
<li><p>federated_scheduler.py：执行start_task()<br>发起http请求 ${job_log_dir}/fate_flow_audit.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,205] [1:140259369826048] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/start</span><br></pre></td></tr></table></figure>
</li>
<li><p>fate_flow_server.py：接受请求，通过flask，转移到party_app</p>
</li>
<li><p>party_app.py： 执行task_status，调用TaskController.start_task<br>这里不论调用结果，返回的都是success。</p>
</li>
<li><p>task_controller.py：执行start_task。<br>先调用job_utils.get_job_dsl() 获取job的dsl。这里需要查询DB，产生fate_flow/peewee.log日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,212] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_dsl` FROM `t_job` AS `t1` WHERE (((`t1`.`f_job_id` = %s) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
<p>鉴权，（接上文，本job无鉴权，故不会执行）。<br>输出日志到${job_log_dir}/fate_flow_schedule.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,214] [1:140259119585024] - task_controller.py[line:71]: try to start job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0 executor subprocess</span><br></pre></td></tr></table></figure>
<p>生成task等目录，并创建。将task_parameters_path 写入对应文件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">task_dir = os.path.join(job_utils.get_job_directory(job_id=job_id), role, party_id, component_name, task_id, task_version)</span><br><span class="line">/data/projects/fate/jobs/202107260820309976351/local/0/upload_0/202107260820309976351_upload_0/0/</span><br><span class="line"></span><br><span class="line">task_parameters_path = os.path.join(task_dir, &#x27;task_parameters.json&#x27;)</span><br><span class="line">run_parameters_dict = job_utils.get_job_parameters(job_id, role, party_id)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>获取run_parameters，对应fate_flow/peewee.log日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,216] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_runtime_conf_on_party` FROM `t_job` AS `t1` WHERE (((`t1`.`f_job_id` = %s) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure></p>
<p>输出日志：${job_log_dir}/fate_flow_schedule.log<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,218] [1:140259119585024] - task_controller.py[line:90]: use computing engine EGGROLL</span><br></pre></td></tr></table></figure></p>
<p>根据computing engine，生成process_cmd。这里可以看下源码，比较有意思<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">if run_parameters.computing_engine in &#123;ComputingEngine.EGGROLL, ComputingEngine.STANDALONE&#125;:</span><br><span class="line">    process_cmd = [</span><br><span class="line">        sys.executable,</span><br><span class="line">        sys.modules[TaskExecutor.__module__].__file__,</span><br><span class="line">        &#x27;-j&#x27;, job_id,</span><br><span class="line">        &#x27;-n&#x27;, component_name,</span><br><span class="line">        &#x27;-t&#x27;, task_id,</span><br><span class="line">        &#x27;-v&#x27;, task_version,</span><br><span class="line">        &#x27;-r&#x27;, role,</span><br><span class="line">        &#x27;-p&#x27;, party_id,</span><br><span class="line">        &#x27;-c&#x27;, task_parameters_path,</span><br><span class="line">        &#x27;--run_ip&#x27;, RuntimeConfig.JOB_SERVER_HOST,</span><br><span class="line">        &#x27;--job_server&#x27;, &#x27;&#123;&#125;:&#123;&#125;&#x27;.format(RuntimeConfig.JOB_SERVER_HOST, RuntimeConfig.HTTP_PORT),</span><br><span class="line">    ]</span><br><span class="line">elif run_parameters.computing_engine == ComputingEngine.SPARK:</span><br><span class="line">    if &quot;SPARK_HOME&quot; not in os.environ:</span><br><span class="line">        raise EnvironmentError(&quot;SPARK_HOME not found&quot;)</span><br><span class="line">    spark_home = os.environ[&quot;SPARK_HOME&quot;]</span><br><span class="line"></span><br><span class="line">    # additional configs</span><br><span class="line">    spark_submit_config = run_parameters.spark_run</span><br><span class="line"></span><br><span class="line">    deploy_mode = spark_submit_config.get(&quot;deploy-mode&quot;, &quot;client&quot;)</span><br><span class="line">    if deploy_mode not in [&quot;client&quot;]:</span><br><span class="line">        raise ValueError(f&quot;deploy mode &#123;deploy_mode&#125; not supported&quot;)</span><br><span class="line"></span><br><span class="line">    spark_submit_cmd = os.path.join(spark_home, &quot;bin/spark-submit&quot;)</span><br><span class="line">    process_cmd = [spark_submit_cmd, f&#x27;--name=&#123;task_id&#125;#&#123;role&#125;&#x27;]</span><br><span class="line">    for k, v in spark_submit_config.items():</span><br><span class="line">        if k != &quot;conf&quot;:</span><br><span class="line">            process_cmd.append(f&#x27;--&#123;k&#125;=&#123;v&#125;&#x27;)</span><br><span class="line">    if &quot;conf&quot; in spark_submit_config:</span><br><span class="line">        for ck, cv in spark_submit_config[&quot;conf&quot;].items():</span><br><span class="line">            process_cmd.append(f&#x27;--conf&#x27;)</span><br><span class="line">            process_cmd.append(f&#x27;&#123;ck&#125;=&#123;cv&#125;&#x27;)</span><br><span class="line">    process_cmd.extend([</span><br><span class="line">        sys.modules[TaskExecutor.__module__].__file__,</span><br><span class="line">        &#x27;-j&#x27;, job_id,</span><br><span class="line">        &#x27;-n&#x27;, component_name,</span><br><span class="line">        &#x27;-t&#x27;, task_id,</span><br><span class="line">        &#x27;-v&#x27;, task_version,</span><br><span class="line">        &#x27;-r&#x27;, role,</span><br><span class="line">        &#x27;-p&#x27;, party_id,</span><br><span class="line">        &#x27;-c&#x27;, task_parameters_path,</span><br><span class="line">        &#x27;--run_ip&#x27;, RuntimeConfig.JOB_SERVER_HOST,</span><br><span class="line">        &#x27;--job_server&#x27;, &#x27;&#123;&#125;:&#123;&#125;&#x27;.format(RuntimeConfig.JOB_SERVER_HOST, RuntimeConfig.HTTP_PORT),</span><br><span class="line">    ])</span><br><span class="line">else:</span><br><span class="line">    raise ValueError(f&quot;$&#123;run_parameters.computing_engine&#125; is not supported&quot;)</span><br></pre></td></tr></table></figure></p>
<p><strong>注：spark 只支持client模式</strong><br><strong>注：spark 的submint 是 $sparkhome/bin/spark-submit</strong><br>建立task的日志目录<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">task_log_dir = os.path.join(job_utils.get_job_log_directory(job_id=job_id), role, party_id, component_name)</span><br><span class="line">对应</span><br><span class="line">local/0/upload_0/</span><br></pre></td></tr></table></figure><br>输出日志：${job_log_dir}/fate_flow_schedule.log<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,218] [1:140259119585024] - task_controller.py[line:144]: job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0 executor subprocess is ready</span><br></pre></td></tr></table></figure><br>调用job_utils.run_subprocess() 真正执行的部分来了</p>
<ol>
<li>job_utils.py：执行run_subprocess<br>先输出日志：${job_log_dir}/fate_flow_schedule.log<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,218] [1:140259119585024] - job_utils.py[line:310]: start process command: /opt/app-root/bin/python /data/projects/fate/python/fate_flow/operation/task_executor.py -j 202107260820309976351 -n upload_0 -t 202107260820309976351_upload_0 -v 0 -r local -p 0 -c /data/projects/fate/jobs/202107260820309976351/local/0/upload_0/202107260820309976351_upload_0/0/task_parameters.json --run_ip 10.200.96.235 --job_server 10.200.96.235:9380</span><br></pre></td></tr></table></figure>
这里会把真实执行的命令打出。<br><strong>注：小技巧，本地debug 可以直接执行这条命令，这也是真正的入口，可以参考文档<a href="https://github.com/FederatedAI/DOC-CHN/blob/master/%E6%9C%89%E5%A5%96%E5%BE%81%E9%9B%86%E6%B4%BB%E5%8A%A8/%E6%95%99%E7%A8%8B%E7%B1%BB/Mac%E4%B8%8B%E4%BD%BF%E7%94%A8Pycharm/MAC%E4%B8%8B%E4%BD%BF%E7%94%A8PyCharm%E8%BF%9B%E8%A1%8C%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95fate.md">Mac下使用Pycharm</a></strong></li>
</ol>
<p>获取相关目录<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">os.makedirs(config_dir, exist_ok=True)</span><br><span class="line">if log_dir:</span><br><span class="line">    os.makedirs(log_dir, exist_ok=True)</span><br><span class="line">std_log = open(os.path.join(log_dir if log_dir else config_dir, &#x27;std.log&#x27;), &#x27;w&#x27;)</span><br><span class="line">pid_path = os.path.join(config_dir, &#x27;pid&#x27;)</span><br></pre></td></tr></table></figure><br>判断操作系统。<br>执行cmd<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p = subprocess.Popen(process_cmd,</span><br><span class="line">                         stdout=std_log,</span><br><span class="line">                         stderr=std_log,</span><br><span class="line">                         startupinfo=startupinfo</span><br><span class="line">                         )</span><br></pre></td></tr></table></figure><br>并将pid 写入对应目录。<br>打出日志${job_log_dir}/fate_flow_schedule.log<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,258] [1:140259119585024] - job_utils.py[line:333]: start process command: /opt/app-root/bin/python /data/projects/fate/python/fate_flow/operation/task_executor.py -j 202107260820309976351 -n upload_0 -t 202107260820309976351_upload_0 -v 0 -r local -p 0 -c /data/projects/fate/jobs/202107260820309976351/local/0/upload_0/202107260820309976351_upload_0/0/task_parameters.json --run_ip 10.200.96.235 --job_server 10.200.96.235:9380 successfully, pid is 90</span><br></pre></td></tr></table></figure><br>至此 schedule 结束，并返回进程给task_controller.py 对应38</p>
<ol>
<li><p>task_controller.py：接收38返回值，更新task变量状态。在finally部分，调用update_task，update_task_status更新DB中task状态。两个方法均会调用job_saver.py 的对应方法。</p>
</li>
<li><p>task_controller.py：update_task调用执行job_saver.update_task()<br>先打印日志${job_log_dir}/fate_flow_schedule.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,259] [1:140259119585024] - job_saver.py[line:81]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0</span><br></pre></td></tr></table></figure>
<p><strong>注：这里和update_task_status 相比，少了一个status（参考步骤20）</strong><br>执行update_entity_table()，先查询，再执行update，对应fate_flow/peewee.log日志为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,263] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE (((((`t1`.`f_job_id` = %s) AND (`t1`.`f_task_id` = %s)) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:32,270] [1:140259119585024] - peewee.py[line:2863]: (&#x27;UPDATE `t_task` SET `f_start_time` = %s, `f_start_date` = %s WHERE (((((`t_task`.`f_job_id` = %s) AND (`t_task`.`f_task_id` = %s)) AND (`t_task`.`f_task_version` = %s)) AND (`t_task`.`f_role` = %s)) AND (`t_task`.`f_party_id` = %s))&#x27;, [1627287632259, datetime.datetime(2021, 7, 26, 8, 20, 32), &#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
<p>update成功，输出日志${job_log_dir}/fate_flow_schedule.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,275] [1:140259119585024] - job_saver.py[line:84]: job 202107260820309976351 task 202107260820309976351_upload_0 0 update successfully</span><br></pre></td></tr></table></figure>
<p>执行 report_task_to_initiator，同29中，只执行了query，不发起请求。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,277] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE ((((`t1`.`f_task_id` = %s) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
<p>返回update_status</p>
</li>
<li><p>task_controller.py：update_task_status调用job_saver.update_task_status()<br>过程参照22，对应fate_flow/peewee.log日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,283] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE (((((`t1`.`f_job_id` = %s) AND (`t1`.`f_task_id` = %s)) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:32,289] [1:140259119585024] - peewee.py[line:2863]: (&#x27;UPDATE `t_task` SET `f_party_status` = %s WHERE ((((((`t_task`.`f_job_id` = %s) AND (`t_task`.`f_task_id` = %s)) AND (`t_task`.`f_task_version` = %s)) AND (`t_task`.`f_role` = %s)) AND (`t_task`.`f_party_id` = %s)) AND (`t_task`.`f_party_status` = %s))&#x27;, [&#x27;running&#x27;, &#x27;202107260820309976351&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;, &#x27;waiting&#x27;])</span><br></pre></td></tr></table></figure>
<p>对应${job_log_dir}/fate_flow_schedule.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,281] [1:140259119585024] - job_saver.py[line:71]: try to update job 202107260820309976351 task 202107260820309976351_upload_0 0 status</span><br><span class="line">[INFO] [2021-07-26 08:20:32,295] [1:140259119585024] - job_saver.py[line:74]: update job 202107260820309976351 task 202107260820309976351_upload_0 0 status successfully: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;task_id&#x27;: &#x27;202107260820309976351_upload_0&#x27;, &#x27;task_version&#x27;: &#x27;0&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: &#x27;0&#x27;, &#x27;party_status&#x27;: &#x27;running&#x27;, &#x27;start_time&#x27;: 1627287632259&#125;</span><br></pre></td></tr></table></figure>
<p><strong>注：29失败，这里成功,因为字段不同，29是f_status，这里是f_party_status</strong><br>执行 report_task_to_initiator，同29中，只执行了query，不发起请求。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,300] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_job_id`, `t1`.`f_component_name`, `t1`.`f_task_id`, `t1`.`f_task_version`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_federated_mode`, `t1`.`f_federated_status_collect_type`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_run_on_this_party`, `t1`.`f_run_ip`, `t1`.`f_run_pid`, `t1`.`f_party_status`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_task` AS `t1` WHERE ((((`t1`.`f_task_id` = %s) AND (`t1`.`f_task_version` = %s)) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>注：对比22 和 29 可以发现，job_saver 不发起report ,task_control 中的方法有report</strong></p>
<ol>
<li><p>task_controller.py：执行完毕，无异常，在${job_log_dir}/fate_flow_schedule.log输出日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,304] [1:140259119585024] - task_controller.py[line:163]: job 202107260820309976351 task 202107260820309976351_upload_0 0 on local 0 executor subprocess start success</span><br></pre></td></tr></table></figure>
</li>
<li><p>party_app.py： 对应37，返回结果。这里不论上文的执行情况，返回的都是success。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TaskController.create_task(role, party_id, True, request.json)</span><br><span class="line">return get_json_result(retcode=0, retmsg=&#x27;success&#x27;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>fate_flow_server.py：返回结果给api_utils.py 对应36</p>
</li>
<li><p>api_utils.py：接受信息，在${job_log_dir}/fate_flow_audit.log  输出如下日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,310] [1:140259369826048] - api_utils.py[line:129]: &#123;&quot;retcode&quot;:0,&quot;retmsg&quot;:&quot;success&quot;&#125;</span><br><span class="line"></span><br><span class="line">[INFO] [2021-07-26 08:20:32,311] [1:140259369826048] - api_utils.py[line:131]: remote http api response: /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/start &#123;&#x27;retcode&#x27;: 0, &#x27;retmsg&#x27;: &#x27;success&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>对应的容器日志为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/start HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure>
<p>并返回结果给federated_scheduler.py 对应35</p>
</li>
<li><p>federated_scheduler.py：返回结果给task_scheduler.py，对应34</p>
</li>
<li>task_scheduler.py：status_code 为SUCCESS，返回SchedulingStatusCode.SUCCESS，对应16。</li>
<li>task_scheduler.py：对应16，依次遍历，完成本轮该job下task的调度，并在${job_log_dir}/fate_flow_schedule.log输出日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,311] [1:140259369826048] - task_scheduler.py[line:75]: finish scheduling job 202107260820309976351 tasks</span><br></pre></td></tr></table></figure>
<strong>注：这里不是一次性调度该job下的所有task，当task的前置依赖task不满足时，会跳出循环，等下一次轮询</strong></li>
<li>task_scheduler.py：返回各task的当前状态给dag_scheduler.py 对应5</li>
<li>dag_scheduler.py：调用calculate_job_status() 计算当前job状态，如果收到cancel信号，且job处于waiting，将状态置为canceled。<br>计算当前的进度。完成的task/总task（吐槽，无视了各个task的耗时）<br>${job_log_dir}/fate_flow_schedule.log输出日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,312] [1:140259369826048] - dag_scheduler.py[line:310]: Job 202107260820309976351 status is running, calculate by task status list: [&#x27;running&#x27;]</span><br></pre></td></tr></table></figure></li>
<li>dag_scheduler.py：根据job状态和进度变化情况，向多方同步相关信息。</li>
<li>dag_scheduler.py：整个schedule_running_job结束。${job_log_dir}/fate_flow_schedule.log输出日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,312] [1:140259369826048] - dag_scheduler.py[line:325]: finish scheduling job 202107260820309976351</span><br></pre></td></tr></table></figure>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-5-upload-task-schedule/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-5-upload-task-schedule/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（五）upload任务job schedule阶段</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:11:32 / Modified: 13:31:04" itemprop="dateCreated datePublished" datetime="2023-08-20T12:11:32+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>由于是异步提交的，job启动是由server 进行轮询，对于处于waiting的 job 按照FIFO进行调度。<br>调度之后的操作有2部分：</p>
<ul>
<li>Part1. 申请资源 </li>
<li>Part2. start job：将job的状态从waiting -&gt; running 状态</li>
</ul>
<p>涉及的主要方法： dag_scheduler.schedule_waiting_jobs()</p>
<h1 id="执行细节"><a href="#执行细节" class="headerlink" title="执行细节"></a>执行细节</h1><p><img src="/image/fate/84129cf514ec4762a73cc32d06f34b74.png" alt="在这里插入图片描述"></p>
<ol>
<li>dag_scheduler.py：轮询，发现处于waiting状态的job（这一部分见fate flow server 启动部分），调用schedule_waiting_jobs 调度处于waiting 状态的job。<br>轮询日志输出在 fate_flow/fate_flow_schedule.log 中<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:31,994] [1:140259369826048] - dag_scheduler.py[line:134]: start schedule waiting jobs</span><br><span class="line">[INFO] [2021-07-26 08:20:32,007] [1:140259369826048] - dag_scheduler.py[line:136]: have 1 waiting jobs</span><br><span class="line">[INFO] [2021-07-26 08:20:32,008] [1:140259369826048] - dag_scheduler.py[line:140]: schedule waiting job 202107260820309976351</span><br><span class="line">[INFO] [2021-07-26 08:20:32,117] [1:140259369826048] - dag_scheduler.py[line:146]: schedule waiting jobs finished</span><br></pre></td></tr></table></figure>
对应查询waiting状态的fate_flow/peewee.log为<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,001] [1:140259369826048] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_user_id`, `t1`.`f_job_id`, `t1`.`f_name`, `t1`.`f_description`, `t1`.`f_tag`, `t1`.`f_dsl`, `t1`.`f_runtime_conf`, `t1`.`f_runtime_conf_on_party`, `t1`.`f_train_runtime_conf`, `t1`.`f_roles`, `t1`.`f_work_mode`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_is_initiator`, `t1`.`f_progress`, `t1`.`f_ready_signal`, `t1`.`f_ready_time`, `t1`.`f_cancel_signal`, `t1`.`f_cancel_time`, `t1`.`f_rerun_signal`, `t1`.`f_end_scheduling_updates`, `t1`.`f_engine_name`, `t1`.`f_engine_type`, `t1`.`f_cores`, `t1`.`f_memory`, `t1`.`f_remaining_cores`, `t1`.`f_remaining_memory`, `t1`.`f_resource_in_use`, `t1`.`f_apply_resource_time`, `t1`.`f_return_resource_time`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_job` AS `t1` WHERE ((`t1`.`f_is_initiator` = %s) AND (`t1`.`f_status` = %s)) ORDER BY `t1`.`f_create_time` ASC&#x27;, [True, &#x27;waiting&#x27;])</span><br></pre></td></tr></table></figure></li>
<li>dag_scheduler.py： 将job ready_signal 置为true后，调用FederatedScheduler.resource_for_job() 申请资源<br>ready_signal 部分的代码为<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if not cls.ready_signal(job_id=job_id, set_or_reset=True):</span><br></pre></td></tr></table></figure>
会在fate_flow/peewee.log 中输出<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,009] [1:140259369826048] - peewee.py[line:2863]: (&#x27;UPDATE `t_job` SET `f_ready_signal` = %s, `f_ready_time` = %s WHERE ((`t_job`.`f_job_id` = %s) AND (`t_job`.`f_ready_signal` = %s))&#x27;, [True, 1627287632009, &#x27;202107260820309976351&#x27;, False])</span><br></pre></td></tr></table></figure></li>
<li>federated_scheduler.py：开始申请资源，这里会在${job_log_dir}/fate_flow_schedule.log 打出日志，<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,022] [1:140259369826048] - federated_scheduler.py[line:39]: try to apply job 202107260820309976351 resource</span><br></pre></td></tr></table></figure>
然后根据入参，调用job_command发起请求，申请资源。</li>
<li><p>api_utils.py：如前文所述，本地的是http请求，故而调用的是ederated_coordination_on_http。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">url = &quot;http://&#123;&#125;:&#123;&#125;&#123;&#125;&quot;.format(host, port, endpoint)</span><br><span class="line">audit_logger(job_id).info(&#x27;remote http api request: &#123;&#125;&#x27;.format(url))</span><br><span class="line">action = getattr(requests, method.lower(), None)</span><br><span class="line">headers = HEADERS.copy()</span><br><span class="line">headers[&quot;dest-party-id&quot;] = str(dest_party_id)</span><br><span class="line">headers[&quot;src-party-id&quot;] = str(src_party_id)</span><br><span class="line">headers[&quot;src-role&quot;] = str(src_role)</span><br><span class="line">http_response = action(url=url, data=json_dumps(json_body), headers=headers)</span><br><span class="line">audit_logger(job_id).info(http_response.text)</span><br><span class="line">response = http_response.json()</span><br><span class="line">audit_logger(job_id).info(&#x27;remote http api response: &#123;&#125; &#123;&#125;&#x27;.format(endpoint, response))</span><br><span class="line">return response</span><br></pre></td></tr></table></figure>
<p>先生成请求的url。并在${job_log_dir}/fate_flow_audit.log 中打印出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,023] [1:140259369826048] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/party/202107260820309976351/local/0/resource/apply</span><br></pre></td></tr></table></figure>
</li>
<li><p>fate_flow_server.py：接收请求，因为endpoint 是party/<em>**</em>，通过flask机制，跳转至party_app</p>
</li>
<li>party_app.py：调用 ResourceManager.apply_for_job_resource() 申请资源</li>
<li>resource_manager.py：在resource_for_job()给job分配资源。主要操作为<br>-&gt;调用calculate_job_resource，查询表t_job，得到f_runtime_conf_on_party进一步计算得到engine_name，cores，memory<br>这里会在fate_flow/peewee.log<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,031] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_runtime_conf_on_party` FROM `t_job` AS `t1` WHERE (((`t1`.`f_job_id` = %s) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
-&gt;获取相关信息后，更新t_job表<br>fate_flow/peewee.log 中有<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,037] [1:140259119585024] - peewee.py[line:2863]: (&#x27;UPDATE `t_job` SET `f_engine_name` = %s, `f_engine_type` = %s, `f_cores` = %s, `f_memory` = %s, `f_remaining_cores` = %s, `f_remaining_memory` = %s, `f_resource_in_use` = %s, `f_apply_resource_time` = %s WHERE ((((`t_job`.`f_job_id` = %s) AND (`t_job`.`f_role` = %s)) AND (`t_job`.`f_party_id` = %s)) AND (`t_job`.`f_resource_in_use` = %s))&#x27;, [&#x27;EGGROLL&#x27;, &#x27;computing&#x27;, 4, 0, 4, 0, True, 1627287632035, &#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;, False])</span><br></pre></td></tr></table></figure>
-&gt; t_job表更新成功后，再更新t_engine_registry表<br>代码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">operate = EngineRegistry.update(updates).where(*filters)</span><br><span class="line">apply_status = operate.execute() &gt; 0</span><br></pre></td></tr></table></figure>
fate_flow/peewee.log<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,040] [1:140259119585024] - peewee.py[line:2863]: (&#x27;UPDATE `t_engine_registry` SET `f_remaining_cores` = (`t_engine_registry`.`f_remaining_cores` - %s), `f_remaining_memory` = (`t_engine_registry`.`f_remaining_memory` - %s) WHERE ((((`t_engine_registry`.`f_remaining_cores` &gt;= %s) AND (`t_engine_registry`.`f_remaining_memory` &gt;= %s)) AND (`t_engine_registry`.`f_engine_type` = %s)) AND (`t_engine_registry`.`f_engine_name` = %s))&#x27;, [4, 0, 4, 0, &#x27;computing&#x27;, &#x27;EGGROLL&#x27;])</span><br></pre></td></tr></table></figure>
获取当前剩余的资源<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">remaining_cores, remaining_memory = cls.get_remaining_resource(EngineRegistry,</span><br><span class="line">                                                               [</span><br><span class="line">                                                                   EngineRegistry.f_engine_type == EngineType.COMPUTING,</span><br><span class="line">                                                                   EngineRegistry.f_engine_name == engine_name])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
对应fate_flow/peewee.log<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,046] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_remaining_cores`, `t1`.`f_remaining_memory` FROM `t_engine_registry` AS `t1` WHERE ((`t1`.`f_engine_type` = %s) AND (`t1`.`f_engine_name` = %s))&#x27;, [&#x27;computing&#x27;, &#x27;EGGROLL&#x27;])</span><br></pre></td></tr></table></figure>
若查到数据且一切正常，在${job_log_dir}/fate_flow_schedule.log中打出如下日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,049] [1:140259119585024] - resource_manager.py[line:175]: apply job 202107260820309976351 resource(cores 4 memory 0) on local 0 successfully, remaining cores: 16 remaining memory: 0</span><br></pre></td></tr></table></figure></li>
<li>resource_manager.py：返回资源申请结果</li>
<li>party_app.py： 返回response给fate_flow_server.py，对应5</li>
<li>fate_flow_server.py：返回response给api_utils.py，对应4<br>参考 4中的代码，这里会在fate_flow/fate_flow_audit.log中输出如下日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,052] [1:140259369826048] - api_utils.py[line:129]: &#123;&quot;retcode&quot;:0,&quot;retmsg&quot;:&quot;success&quot;&#125;</span><br><span class="line">[INFO] [2021-07-26 08:20:32,052] [1:140259369826048] - api_utils.py[line:131]: remote http api response: /v1/party/202107260820309976351/local/0/resource/apply &#123;&#x27;retcode&#x27;: 0, &#x27;retmsg&#x27;: &#x27;success&#x27;&#125;</span><br></pre></td></tr></table></figure></li>
<li>api_utils.py：返回response 给federated_scheduler.py，对应3</li>
<li>federated_scheduler.py： 根据response 结果输出日志到 ${job_log_dir}/fate_flow_schedule.log 中<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,053] [1:140259369826048] - federated_scheduler.py[line:42]: apply job 202107260820309976351 resource successfully</span><br></pre></td></tr></table></figure>
并返回资源分配结果给dag_scheduler.py，对应2</li>
<li>dag_scheduler.py：如资源申请成功，调用start_job启动job，<br>在${job_log_dir}/fate_flow_schedule.log 中输出日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,053] [1:140259369826048] - dag_scheduler.py[line:279]: try to start job 202107260820309976351 on initiator local 0</span><br></pre></td></tr></table></figure>
然后配置job_info 各项参数将status置为Runing，将tag置为end_waiting<br>在容器日志中也有<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/local/0/resource/apply HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure></li>
<li>dag_scheduler.py： 调用JobSaver.query_job查询db,确认该job在数据库中，就继续执行(骚操作，删db)<br>对应fate_flow/peewee.log 日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,058] [1:140259369826048] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_user_id`, `t1`.`f_job_id`, `t1`.`f_name`, `t1`.`f_description`, `t1`.`f_tag`, `t1`.`f_dsl`, `t1`.`f_runtime_conf`, `t1`.`f_runtime_conf_on_party`, `t1`.`f_train_runtime_conf`, `t1`.`f_roles`, `t1`.`f_work_mode`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_is_initiator`, `t1`.`f_progress`, `t1`.`f_ready_signal`, `t1`.`f_ready_time`, `t1`.`f_cancel_signal`, `t1`.`f_cancel_time`, `t1`.`f_rerun_signal`, `t1`.`f_end_scheduling_updates`, `t1`.`f_engine_name`, `t1`.`f_engine_type`, `t1`.`f_cores`, `t1`.`f_memory`, `t1`.`f_remaining_cores`, `t1`.`f_remaining_memory`, `t1`.`f_resource_in_use`, `t1`.`f_apply_resource_time`, `t1`.`f_return_resource_time`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_job` AS `t1` WHERE (((`t1`.`f_job_id` = %s) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
这里对应的是submit阶段的insert语句。</li>
<li>dag_scheduler.py：调用FederatedScheduler.start_job() 启动任务</li>
<li>federated_scheduler.py：调用job_command  start job</li>
<li>federated_scheduler.py：由于是本地，向server发起http请求<br>类似第4步，在${job_log_dir}/fate_flow_audit.log中输出日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,063] [1:140259369826048] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/party/202107260820309976351/local/0/start</span><br></pre></td></tr></table></figure></li>
<li>fate_flow_server.py：接收请求，因为endpoint 是party/<em>**</em>，通过flask机制，跳转至party_app通过Flask 机制，跳转至party_app</li>
<li>party_app.py： 调用JobController.start_job() 启动job</li>
<li>job_controller.py：打印日志<br>${job_log_dir}/fate_flow_schedule.log<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,053] [1:140259369826048] - dag_scheduler.py[line:279]: try to start job 202107260820309976351 on initiator local 0</span><br></pre></td></tr></table></figure>
并设置job_info，主要是将status 置为running,调用update_job_status 更新DB</li>
<li>job_controller.py：调用JobSaver.update_job_status</li>
<li>job_saver.py：执行update_job_status()<br>首先输出日志到${job_log_dir}/fate_flow_schedule.log<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,070] [1:140259119585024] - job_saver.py[line:45]: try to update job 202107260820309976351 status to running</span><br></pre></td></tr></table></figure>
调用update_status()，在update_status()内部，先查询db<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,074] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_user_id`, `t1`.`f_job_id`, `t1`.`f_name`, `t1`.`f_description`, `t1`.`f_tag`, `t1`.`f_dsl`, `t1`.`f_runtime_conf`, `t1`.`f_runtime_conf_on_party`, `t1`.`f_train_runtime_conf`, `t1`.`f_roles`, `t1`.`f_work_mode`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_is_initiator`, `t1`.`f_progress`, `t1`.`f_ready_signal`, `t1`.`f_ready_time`, `t1`.`f_cancel_signal`, `t1`.`f_cancel_time`, `t1`.`f_rerun_signal`, `t1`.`f_end_scheduling_updates`, `t1`.`f_engine_name`, `t1`.`f_engine_type`, `t1`.`f_cores`, `t1`.`f_memory`, `t1`.`f_remaining_cores`, `t1`.`f_remaining_memory`, `t1`.`f_resource_in_use`, `t1`.`f_apply_resource_time`, `t1`.`f_return_resource_time`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_job` AS `t1` WHERE (((`t1`.`f_job_id` = %s) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
根据获取信息，更新相关信息，然后调用execute_update()，执行sql更新DB<br>注意，在execute_update()这个方法里，会输出日志到${job_log_dir}/fate_flow_sql.log<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,081] [1:140259119585024] - job_saver.py[line:185]: UPDATE `t_job` SET `f_status` = &#x27;running&#x27; WHERE ((((`t_job`.`f_job_id` = &#x27;202107260820309976351&#x27;) AND (`t_job`.`f_role` = &#x27;local&#x27;)) AND (`t_job`.`f_party_id` = &#x27;0&#x27;)) AND (`t_job`.`f_status` = &#x27;waiting&#x27;))</span><br></pre></td></tr></table></figure>
对应的fate_flow/peewee.log 日志为<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,083] [1:140259119585024] - peewee.py[line:2863]: (&#x27;UPDATE `t_job` SET `f_status` = %s WHERE ((((`t_job`.`f_job_id` = %s) AND (`t_job`.`f_role` = %s)) AND (`t_job`.`f_party_id` = %s)) AND (`t_job`.`f_status` = %s))&#x27;, [&#x27;running&#x27;, &#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;, &#x27;waiting&#x27;])</span><br></pre></td></tr></table></figure>
可以看到，就是将状态从waiting 更新为running。从时间戳上也能看出，先打sql.log，再底层调用peewee执行<br>update_status() 执行完毕，DB更新成功，会在${job_log_dir}/fate_flow_schedule.log中输出日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,088] [1:140259119585024] - job_saver.py[line:48]: update job 202107260820309976351 status successfully</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>注：若job的status属于EndStatus，会调用update_entity_table()</p>
<ol>
<li>job_saver.py：返回update_status()的执行状态给job_controllle.py 对应21</li>
<li><p>job_controlller.py：返回update_job_status()执行状态<br>注：若状态为true，会根据job status 判断是否回收资源，这个在start 阶段不用，但是后续finish 阶段会用</p>
</li>
<li><p>job_controlller.py： 调用update_job</p>
</li>
<li>job_controlller.py：调用JobSaver.update_job </li>
<li><p>job_saver.py：执行update_job()<br>输出日志到${job_log_dir}/fate_flow_schedule.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,089] [1:140259119585024] - job_saver.py[line:61]: try to update job 202107260820309976351</span><br></pre></td></tr></table></figure>
<p>调用update_entity_table，同22部分，先根据jobid 查现有更新，然后执行update</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,092] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_user_id`, `t1`.`f_job_id`, `t1`.`f_name`, `t1`.`f_description`, `t1`.`f_tag`, `t1`.`f_dsl`, `t1`.`f_runtime_conf`, `t1`.`f_runtime_conf_on_party`, `t1`.`f_train_runtime_conf`, `t1`.`f_roles`, `t1`.`f_work_mode`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_is_initiator`, `t1`.`f_progress`, `t1`.`f_ready_signal`, `t1`.`f_ready_time`, `t1`.`f_cancel_signal`, `t1`.`f_cancel_time`, `t1`.`f_rerun_signal`, `t1`.`f_end_scheduling_updates`, `t1`.`f_engine_name`, `t1`.`f_engine_type`, `t1`.`f_cores`, `t1`.`f_memory`, `t1`.`f_remaining_cores`, `t1`.`f_remaining_memory`, `t1`.`f_resource_in_use`, `t1`.`f_apply_resource_time`, `t1`.`f_return_resource_time`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_job` AS `t1` WHERE (((`t1`.`f_job_id` = %s) AND (`t1`.`f_role` = %s)) AND (`t1`.`f_party_id` = %s))&#x27;, [&#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:32,099] [1:140259119585024] - peewee.py[line:2863]: (&#x27;UPDATE `t_job` SET `f_start_time` = %s, `f_start_date` = %s WHERE (((`t_job`.`f_job_id` = %s) AND (`t_job`.`f_role` = %s)) AND (`t_job`.`f_party_id` = %s))&#x27;, [1627287632070, datetime.datetime(2021, 7, 26, 8, 20, 32), &#x27;202107260820309976351&#x27;, &#x27;local&#x27;, &#x27;0&#x27;])</span><br></pre></td></tr></table></figure>
<p>对应的${job_log_dir}/fate_flow_sql.log日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,097] [1:140259119585024] - job_saver.py[line:185]: UPDATE `t_job` SET `f_start_time` = 1627287632070, `f_start_date` = &#x27;2021-07-26 08:20:32&#x27; WHERE (((`t_job`.`f_job_id` = &#x27;202107260820309976351&#x27;) AND (`t_job`.`f_role` = &#x27;local&#x27;)) AND (`t_job`.`f_party_id` = &#x27;0&#x27;))</span><br></pre></td></tr></table></figure>
</li>
<li><p>job_saver.py：输出日志到${job_log_dir}/fate_flow_schedule.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,106] [1:140259119585024] - job_saver.py[line:64]: job 202107260820309976351 update successfully: &#123;&#x27;job_id&#x27;: &#x27;202107260820309976351&#x27;, &#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: 0, &#x27;status&#x27;: &#x27;running&#x27;, &#x27;start_time&#x27;: 1627287632070&#125;</span><br></pre></td></tr></table></figure>
<p>并返回update_status()的执行状态给job_controllle.py 对应26</p>
</li>
<li><p>job_controlller.py：start 结束， 输出 successfully 到${job_log_dir}/fate_flow_schedule.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,106] [1:140259119585024] - job_controller.py[line:250]: start job 202107260820309976351 on local 0 successfully</span><br></pre></td></tr></table></figure>
</li>
<li><p>dag_scheduler.py：若上述都无异常，在${job_log_dir}/fate_flow_schedule.log输出如下日志（对应13）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,110] [1:140259369826048] - dag_scheduler.py[line:292]: start job 202107260820309976351 on initiator local 0</span><br></pre></td></tr></table></figure>
</li>
<li><p>dag_scheduler.py：调用ready_singal，执行Job.updates，将ready_signal置为false<br>对应的fate_flow/peewee.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:32,111] [1:140259369826048] - peewee.py[line:2863]: (&#x27;UPDATE `t_job` SET `f_ready_signal` = %s, `f_ready_time` = %s WHERE ((`t_job`.`f_job_id` = %s) AND (`t_job`.`f_ready_signal` = %s))&#x27;, [False, None, &#x27;202107260820309976351&#x27;, True])</span><br></pre></td></tr></table></figure></li>
<li>dag_scheduler.py：在${job_log_dir}/fate_flow_schedule.log中打印31的执行结果<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:32,117] [1:140259369826048] - dag_scheduler.py[line:247]: reset job 202107260820309976351 ready signal True</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>至此，执行完毕，主要操作为更新DB中job的状态和resource的状态</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-4-upload-submit/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-4-upload-submit/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（四）upload任务submit&create阶段</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:11:20 / Modified: 13:37:05" itemprop="dateCreated datePublished" datetime="2023-08-20T12:11:20+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>本篇以upload任务的sumbit 和 create 阶段为例，结合产生的日志，说明该生命阶段代码的运行情况。</p>
<h1 id="执行步骤"><a href="#执行步骤" class="headerlink" title="执行步骤"></a>执行步骤</h1><p><img src="/image/fate/e3a8da03871b4ca5a7d5d35d09b2f1d2.png" alt="在这里插入图片描述"></p>
<p>为便于说明，画了下uml 时序图，结合图说下各步操作</p>
<ol>
<li>在CLI 用户执行命令 python fate_flow_client.py -f upload -c upload_guest.json</li>
<li><p>fate_flow_client.py:调用 call_fun()函数，向本地server 发起post请求</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.post(&quot;/&quot;.join([server_url, &quot;data&quot;, func.replace(&#x27;_&#x27;, &#x27;/&#x27;)]), data=data,params=json.dumps(config_data),headers=&#123;&#x27;Content-Type&#x27;: data.content_type&#125;)</span><br></pre></td></tr></table></figure>
<p>这里会在容器日志中体现post请求日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10.200.96.235 - - [26/Jul/2021 08:20:31] &quot;POST /v1/data/upload?%7B%22file%22:%20%22/data/projects/fate/examples/data/breast_hetero_guest.csv%22,%20%22head%22:%201,%20%22partition%22:%201,%20%22work_mode%22:%201,%20%22table_name%22:%20%22hetero_guest%22,%20%22namespace%22:%20%22cl%22,%20%22config%22:%20%22/data/projects/fate/cl/upload_guest.json%22,%20%22function%22:%20%22upload%22%7D HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure>
</li>
<li><p>fate_flow_server.py: 接受请求，Flask的调度，跳转至data_access_app.py</p>
</li>
<li>data_access_app.py: 执行download_upload() 函数，判断job_id 是否为空，若为空则调用job_utils.generate_job_id()</li>
<li>job_utils.py: 执行generate_job_id() 并返回ID</li>
<li>data_access_app.py: 根据request 中的相关参数，生成job_config</li>
<li>data_access_app.py: 调用detect_utils.check_config() 校验参数</li>
<li>detect_utils.py: 执行check_config() 如有异常抛出</li>
<li>data_access_app.py: 根据job_config，生成各项兼容性参数，如table_name,backnd 等</li>
<li>data_access_app.py: 初始化 StroageTableMeta并给data_table_meta赋值</li>
<li><em>table.py: 调用build 返回Meta，这里打出fate<em>flow/peewee.log 的第3行日志<br>这里在初始化 StorageTableMeta 的时候，会调用__new</em></em>() -&gt; query_table_meta() 从而在peewee 留下日志。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:31,008] [1:140259119585024] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_date`, `t1`.`f_update_date`, `t1`.`f_name`, `t1`.`f_namespace`, `t1`.`f_address`, `t1`.`f_engine`, `t1`.`f_type`, `t1`.`f_options`, `t1`.`f_partitions`, `t1`.`f_id_delimiter`, `t1`.`f_in_serialized`, `t1`.`f_have_head`, `t1`.`f_schema`, `t1`.`f_count`, `t1`.`f_part_of_data`, `t1`.`f_description`, `t1`.`f_create_time`, `t1`.`f_update_time` FROM `t_storage_table_meta` AS `t1` WHERE ((`t1`.`f_name` = %s) AND (`t1`.`f_namespace` = %s))&#x27;, [&#x27;hetero_guest&#x27;, &#x27;cl&#x27;])</span><br></pre></td></tr></table></figure></li>
<li>data_access_app.py: 校验tabel 不存在，或存在且drop 参数为1，调用gen_data_access_job_conf(job_config,access_module) 生成 job_dsl 和 job_runtime_conf</li>
<li>data_access_app.py: 调用DAGScheduler.submit({‘job_dsl’: job_dsl, job_runtime_conf’: job_runtime_conf}, job_id) 提交任务</li>
<li>dag_scheduler.py: 判断jobid 是否为空，空则重新生成</li>
<li><p>dag_scheduler.py: 打印出${job_log_dir}/fate_flow_schedule.log的第一行日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:31,014] [1:140259119585024] - dag_scheduler.py[line:40]: submit job, job_id 202107260820309976351, body &#123;&#x27;job_dsl&#x27;: &#123;&#x27;components&#x27;: &#123;&#x27;upload_0&#x27;: &#123;&#x27;module&#x27;: &#x27;Upload&#x27;&#125;&#125;&#125;, &#x27;job_runtime_conf&#x27;: &#123;&#x27;initiator&#x27;: &#123;&#x27;role&#x27;: &#x27;local&#x27;, &#x27;party_id&#x27;: 0&#125;, &#x27;job_parameters&#x27;: &#123;&#x27;common&#x27;: &#123;&#x27;backend&#x27;: 0, &#x27;work_mode&#x27;: 1&#125;&#125;, &#x27;role&#x27;: &#123;&#x27;local&#x27;: [0]&#125;, &#x27;component_parameters&#x27;: &#123;&#x27;role&#x27;: &#123;&#x27;local&#x27;: &#123;&#x27;0&#x27;: &#123;&#x27;upload_0&#x27;: &#123;&#x27;name&#x27;: &#x27;hetero_guest&#x27;, &#x27;head&#x27;: 1, &#x27;file&#x27;: &#x27;/data/projects/fate/jobs/202107260820309976351/fate_upload_tmp/breast_hetero_guest.csv&#x27;, &#x27;partition&#x27;: 1, &#x27;namespace&#x27;: &#x27;cl&#x27;, &#x27;destroy&#x27;: False&#125;&#125;&#125;&#125;&#125;, &#x27;dsl_version&#x27;: 2&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>其中json部分是入参job_data，可以看到，整个body，包含两部分job_dsl 和 job_runtime_conf。job_dsl 定义了所使用的components,这里只有一个upload。<br>job_runtime_conf定义了整个job的相关参数，包括：     </p>
<ul>
<li>initiator: 调度者（或联邦任务的发起者）</li>
<li>job_parameters:job参数，主要是work_mode：是否为集群模式和 backend 计算引擎</li>
<li>role: 本次任务的参与角色</li>
<li>component_parameters: 位于各个role上的component 的参数，这里就是upload_0 的各项参数</li>
</ul>
</li>
<li><p>dag_scheduler.py: 从job_data中获取job_dsl 和 job_runtime_conf</p>
</li>
<li>dag_scheduler.py: 调用job_utils.check_job_config() 进行参数校验</li>
<li>job_utils.py: 确认各项必要参数都具备，且将party_id都强制转为int。如有异常，则raise。</li>
<li>dag_scheduler.py: 调用 authentication_utils.check_constraint() 校验约束</li>
<li>authentication_utils.py: 调用 check_component_constraint()，校验约束:不允许仅有arbiter 和guest，同在一个party_id, 除非host 也在该party_id</li>
<li>dag_scheduler.py: 配置initiator 和 conf_adapter</li>
<li>dag_scheduler.py: 根据job类型，配置train_runtime_conf</li>
<li>dag_scheduler.py: 新建job对象，并给对应参数赋值</li>
<li>dag_scheduler.py: 调用job_utils.save_job_conf() 生成job_dsl, job_runtime_conf,job_runtime_conf_on_party,train_runtime_conf,pipeline_dsl 各项的保存目录，并将相关参数以json格式落盘。</li>
<li>job_utils.py: 返回24中各项的目录</li>
<li>dag_scheduler.py: 校验initiator 在job_runtime_conf 列表里</li>
<li>dag_scheduler.py: 调用JobController.backend_compatibility() 设置计算引擎和是否集群模式</li>
<li>dag_scheduler.py: 调用JobController.adapt_job_parameters() 适配common_job_parameters</li>
<li>dag_scheduler.py: 使用28中的common_job_parameters 更新job.f_runtime_conf(job 为23 新建对象)</li>
<li>dag_scheduler.py: 调用schedule_utils.get_job_dsl_parser 解析参数</li>
<li>scheduler_utils.py: 根据配置选择dsl 版本（v1 或v2)</li>
<li>scheduler_utils.py: 调用dsl_parser.run() 解析参数</li>
<li>dsl_parser.py: 解析完毕</li>
<li>scheduler_utils.py: 返回dsl_parser 对象</li>
<li>dag_scheduler.py: 若为cluster  模式，且role 和 partyid 不为initiator（if role == job.f_initiator_role and party_id == job.f_initiator_party_id: continue），调用 JobController.initialize_tasks，故而后面36-41都不会执行</li>
<li>job_controller.py: 基于common_job_parameters, dsl_parser ,调用TaskController.create_task()，生成除initiator 外各个role &amp; party_id 上的task</li>
<li>task_controller.py: 设置task_info 的各项信息</li>
<li>task_controller.py:  调用job_utils.generate_task_id()</li>
<li>job_utils.py: 返回task_id</li>
<li>task_controller.py: 调用JobSaver.create_task()</li>
<li>job_saver.py: 调用create_job_family_entity将相关task信息入DB</li>
<li>dag_scheduler.py: 调用FederatedScheduler.create_job()</li>
<li>federated_scheduler.py: 调用job_command() </li>
<li>federated_scheduler.py: 调用api_utils.federated_api() 发起post请求。</li>
<li>api_utils.py: 由于upload 是在本地执行的，调用依次调用local_api()-&gt;federated_coordination_on_http(),${job_log_dir}/fate_flow_audit.log 的第一条日志从这里产生<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:31,028] [1:140259119585024] - api_utils.py[line:122]: remote http api request: http://10.200.96.235:9380/v1/party/202107260820309976351/local/0/create</span><br></pre></td></tr></table></figure></li>
<li>fate_flow_server.py: sever 端接受到如上请求，通过Flask，跳转至party_app.py</li>
<li>party_app.py: 调用create_job() </li>
<li>party_app.py: 调用JobController.create_job()</li>
<li>job_controller.py: 调用schedule_utils.get_job_dsl_parser 解析参数</li>
<li>scheduler_utils.py: 根据配置选择dsl 版本（v1 或v2)</li>
<li>scheduler_utils.py: 调用dsl_parser.run() 解析参数</li>
<li>dsl_parser.py: 解析完毕</li>
<li>job_controller.py: 打印出${job_log_dir}/fate_flow_schedule.log的第二行日志<br>schedule_logger(job_id).info(‘job parameters:{}’.format(job_parameters))<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 08:20:31,043] [1:140259111192320] - job_controller.py[line:51]: job parameters:&#123;&#x27;job_type&#x27;: &#x27;train&#x27;, &#x27;work_mode&#x27;: 1, &#x27;backend&#x27;: 0, &#x27;computing_engine&#x27;: &#x27;EGGROLL&#x27;, &#x27;federation_engine&#x27;: &#x27;EGGROLL&#x27;, &#x27;storage_engine&#x27;: &#x27;EGGROLL&#x27;, &#x27;engines_address&#x27;: &#123;&#125;, &#x27;federated_mode&#x27;: &#x27;MULTIPLE&#x27;, &#x27;task_parallelism&#x27;: 1, &#x27;computing_partitions&#x27;: 4, &#x27;federated_status_collect_type&#x27;: &#x27;PULL&#x27;, &#x27;model_id&#x27;: &#x27;local-0#model&#x27;, &#x27;model_version&#x27;: &#x27;202107260820309976351&#x27;, &#x27;eggroll_run&#x27;: &#123;&#125;, &#x27;spark_run&#x27;: &#123;&#125;, &#x27;rabbitmq_run&#x27;: &#123;&#125;, &#x27;adaptation_parameters&#x27;: &#123;&#x27;task_nodes&#x27;: 1, &#x27;task_cores_per_node&#x27;: 4, &#x27;task_memory_per_node&#x27;: 0, &#x27;request_task_cores&#x27;: 4, &#x27;if_initiator_baseline&#x27;: True&#125;&#125;</span><br></pre></td></tr></table></figure></li>
<li>job_controller.py: 更新job 参数信息，并进行参数校验</li>
<li>job_controller.py: 调用job_utils.save_job_conf() 生成job_dsl, job_runtime_conf,<br>job_runtime_conf_on_party,train_runtime_conf,pipeline_dsl 各项的保存目录，<br>并将相关参数以json格式落盘。这里和24 的操作一致，会入两次盘。</li>
<li>job_controller.py: 调用initialize_task, 初始化task。</li>
<li>job_controller.py: 基于common_job_parameters, dsl_parser ,调用TaskController.create_task()生成各个role &amp; party_id 上的task</li>
<li>task_controller.py: 设置task_info 的各项信息</li>
<li>task_controller.py: 调用JobSaver.create_task()</li>
<li><p>job_saver.py: 调用create_job_family_entity将相关task信息入DB<br>这里在fate_flow/peewee.log 中打出了日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:31,079] [1:140259111192320] - peewee.py[line:2863]: (&#x27;INSERT INTO `t_task` (`f_create_time`, `f_create_date`, `f_update_time`, `f_update_date`, `f_job_id`, `f_component_name`, `f_task_id`, `f_task_version`, `f_initiator_role`, `f_initiator_party_id`, `f_federated_mode`, `f_federated_status_collect_type`, `f_status`, `f_role`, `f_party_id`, `f_run_on_this_party`, `f_party_status`) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)&#x27;, [1627287631077, datetime.datetime(2021, 7, 26, 8, 20, 31), 1627287631078, datetime.datetime(2021, 7, 26, 8, 20, 31), &#x27;202107260820309976351&#x27;, &#x27;upload_0&#x27;, &#x27;202107260820309976351_upload_0&#x27;, 0, &#x27;local&#x27;, &#x27;0&#x27;, &#x27;MULTIPLE&#x27;, &#x27;PULL&#x27;, &#x27;waiting&#x27;, &#x27;local&#x27;, &#x27;0&#x27;, True, &#x27;waiting&#x27;])</span><br></pre></td></tr></table></figure>
</li>
<li><p>job_controller.py: 调用initialize_job_tracker，初始化tracker。</p>
</li>
<li>job_controller.py: 初始化 tracker,并调用tracker.log_job_view </li>
<li>job_tracker.py: 调用log_job_view 将相关信息写db，并在peewee.log 打日志<br>调用源码位于 python/fate_flow/operation/job_tracker.py 312行<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@DB.connection_context()</span><br><span class="line">def bulk_insert_into_db(self, model, data_source):</span><br><span class="line">    try:</span><br><span class="line">        try:</span><br><span class="line">            DB.create_tables([model])</span><br><span class="line">        except Exception as e:</span><br><span class="line">            schedule_logger(self.job_id).exception(e)</span><br><span class="line">        batch_size = 50 if RuntimeConfig.USE_LOCAL_DATABASE else 1000</span><br><span class="line">        for i in range(0, len(data_source), batch_size):</span><br><span class="line">            with DB.atomic():</span><br><span class="line">                model.insert_many(data_source[i:i+batch_size]).execute()</span><br><span class="line">        return len(data_source)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        schedule_logger(self.job_id).exception(e)</span><br><span class="line">        return 0</span><br></pre></td></tr></table></figure>
这里在fate_flow/peewee.log 中打出了日志如下：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:31,122] [1:140259111192320] - peewee.py[line:2863]: (&#x27;SELECT table_name FROM information_schema.tables WHERE table_schema = DATABASE() AND table_type != %s ORDER BY table_name&#x27;, (&#x27;VIEW&#x27;,))</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,132] [1:140259111192320] - peewee.py[line:2863]: (&#x27;CREATE TABLE IF NOT EXISTS `t_tracking_metric_20210726` (`f_id` BIGINT AUTO_INCREMENT NOT NULL PRIMARY KEY, `f_create_time` BIGINT, `f_create_date` DATETIME, `f_update_time` BIGINT, `f_update_date` DATETIME, `f_job_id` VARCHAR(25) NOT NULL, `f_component_name` TEXT NOT NULL, `f_task_id` VARCHAR(100), `f_task_version` BIGINT, `f_role` VARCHAR(50) NOT NULL, `f_party_id` VARCHAR(10) NOT NULL, `f_metric_namespace` VARCHAR(180) NOT NULL, `f_metric_name` VARCHAR(180) NOT NULL, `f_key` VARCHAR(200) NOT NULL, `f_value` LONGTEXT NOT NULL, `f_type` INTEGER NOT NULL)&#x27;, [])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,163] [1:140259111192320] - peewee.py[line:2863]: (&#x27;CREATE INDEX `trackingmetric_20210726_f_job_id` ON `t_tracking_metric_20210726` (`f_job_id`)&#x27;, [])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,184] [1:140259111192320] - peewee.py[line:2863]: (&#x27;CREATE INDEX `trackingmetric_20210726_f_task_id` ON `t_tracking_metric_20210726` (`f_task_id`)&#x27;, [])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,220] [1:140259111192320] - peewee.py[line:2863]: (&#x27;CREATE INDEX `trackingmetric_20210726_f_task_version` ON `t_tracking_metric_20210726` (`f_task_version`)&#x27;, [])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,250] [1:140259111192320] - peewee.py[line:2863]: (&#x27;CREATE INDEX `trackingmetric_20210726_f_role` ON `t_tracking_metric_20210726` (`f_role`)&#x27;, [])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,265] [1:140259111192320] - peewee.py[line:2863]: (&#x27;CREATE INDEX `trackingmetric_20210726_f_party_id` ON `t_tracking_metric_20210726` (`f_party_id`)&#x27;, [])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,283] [1:140259111192320] - peewee.py[line:2863]: (&#x27;CREATE INDEX `trackingmetric_20210726_f_metric_namespace` ON `t_tracking_metric_20210726` (`f_metric_namespace`)&#x27;, [])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,310] [1:140259111192320] - peewee.py[line:2863]: (&#x27;CREATE INDEX `trackingmetric_20210726_f_metric_name` ON `t_tracking_metric_20210726` (`f_metric_name`)&#x27;, [])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,333] [1:140259111192320] - peewee.py[line:2863]: (&#x27;CREATE INDEX `trackingmetric_20210726_f_type` ON `t_tracking_metric_20210726` (`f_type`)&#x27;, [])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,377] [1:140259111192320] - peewee.py[line:2863]: (&#x27;INSERT INTO `t_tracking_metric_20210726` (`f_create_time`, `f_job_id`, `f_component_name`, `f_task_id`, `f_task_version`, `f_role`, `f_party_id`, `f_metric_namespace`, `f_metric_name`, `f_key`, `f_value`, `f_type`) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s), (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s), (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)&#x27;, [1627287631122, &#x27;202107260820309976351&#x27;, &#x27;pipeline&#x27;, None, None, &#x27;local&#x27;, &#x27;0&#x27;, &#x27;job&#x27;, &#x27;job_view&#x27;, &#x27;gANYBwAAAHBhcnRuZXJxAC4=&#x27;, &#x27;gAN9cQAu&#x27;, 2, 1627287631122, &#x27;202107260820309976351&#x27;, &#x27;pipeline&#x27;, None, None, &#x27;local&#x27;, &#x27;0&#x27;, &#x27;job&#x27;, &#x27;job_view&#x27;, &#x27;gANYBwAAAGRhdGFzZXRxAC4=&#x27;, &#x27;gAN9cQBYBQAAAGxvY2FscQF9cQJLAH1xA3NzLg==&#x27;, 2, 1627287631122, &#x27;202107260820309976351&#x27;, &#x27;pipeline&#x27;, None, None, &#x27;local&#x27;, &#x27;0&#x27;, &#x27;job&#x27;, &#x27;job_view&#x27;, &#x27;gANYBQAAAHJvbGVzcQAu&#x27;, &#x27;gAN9cQBYBQAAAGxvY2FscQFdcQJLAGFzLg==&#x27;, 2])</span><br><span class="line">[DEBUG] [2021-07-26 08:20:31,381] [1:140259111192320] - pool.py[line:185]: Returning 140259386365264 to pool.</span><br></pre></td></tr></table></figure>
<ol>
<li>job_controller.py: 调用JobSaver.create_job() </li>
<li><p>job_saver.py: 调用create_job_family_entity将相关job信息 写db  fate_flow/peewee.log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 08:20:31,385] [1:140259111192320] - peewee.py[line:2863]: (&#x27;INSERT INTO `t_job` (`f_create_time`, `f_create_date`, `f_update_time`, `f_update_date`, `f_job_id`, `f_name`, `f_description`, `f_tag`, `f_dsl`, `f_runtime_conf`, `f_runtime_conf_on_party`, `f_train_runtime_conf`, `f_roles`, `f_work_mode`, `f_initiator_role`, `f_initiator_party_id`, `f_status`, `f_role`, `f_party_id`, `f_is_initiator`, `f_progress`, `f_ready_signal`, `f_cancel_signal`, `f_rerun_signal`, `f_end_scheduling_updates`, `f_cores`, `f_memory`, `f_remaining_cores`, `f_remaining_memory`, `f_resource_in_use`) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)&#x27;, [1627287631382, datetime.datetime(2021, 7, 26, 8, 20, 31), 1627287631382, datetime.datetime(2021, 7, 26, 8, 20, 31), &#x27;202107260820309976351&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#123;&quot;components&quot;: &#123;&quot;upload_0&quot;: &#123;&quot;module&quot;: &quot;Upload&quot;&#125;&#125;&#125;&#x27;, &#x27;&#123;&quot;initiator&quot;: &#123;&quot;role&quot;: &quot;local&quot;, &quot;party_id&quot;: 0&#125;, &quot;job_parameters&quot;: &#123;&quot;common&quot;: &#123;&quot;job_type&quot;: &quot;train&quot;, &quot;work_mode&quot;: 1, &quot;backend&quot;: 0, &quot;computing_engine&quot;: &quot;EGGROLL&quot;, &quot;federation_engine&quot;: &quot;EGGROLL&quot;, &quot;storage_engine&quot;: &quot;EGGROLL&quot;, &quot;engines_address&quot;: &#123;&#125;, &quot;federated_mode&quot;: &quot;MULTIPLE&quot;, &quot;task_parallelism&quot;: 1, &quot;computing_partitions&quot;: 4, &quot;federated_status_collect_type&quot;: &quot;PULL&quot;, &quot;model_id&quot;: &quot;local-0#model&quot;, &quot;model_version&quot;: &quot;202107260820309976351&quot;, &quot;eggroll_run&quot;: &#123;&#125;, &quot;spark_run&quot;: &#123;&#125;, &quot;rabbitmq_run&quot;: &#123;&#125;, &quot;adaptation_parameters&quot;: &#123;&quot;task_nodes&quot;: 1, &quot;task_cores_per_node&quot;: 4, &quot;task_memory_per_node&quot;: 0, &quot;request_task_cores&quot;: 4, &quot;if_initiator_baseline&quot;: true&#125;&#125;&#125;, &quot;role&quot;: &#123;&quot;local&quot;: [0]&#125;, &quot;component_parameters&quot;: &#123;&quot;role&quot;: &#123;&quot;local&quot;: &#123;&quot;0&quot;: &#123;&quot;upload_0&quot;: &#123;&quot;name&quot;: &quot;hetero_guest&quot;, &quot;head&quot;: 1, &quot;file&quot;: &quot;/data/projects/fate/jobs/202107260820309976351/fate_upload_tmp/breast_hetero_guest.csv&quot;, &quot;partition&quot;: 1, &quot;namespace&quot;: &quot;cl&quot;, &quot;destroy&quot;: false&#125;&#125;&#125;&#125;&#125;, &quot;dsl_version&quot;: 2&#125;&#x27;, &#x27;&#123;&quot;initiator&quot;: &#123;&quot;role&quot;: &quot;local&quot;, &quot;party_id&quot;: 0&#125;, &quot;job_parameters&quot;: &#123;&quot;job_type&quot;: &quot;train&quot;, &quot;work_mode&quot;: 1, &quot;backend&quot;: 0, &quot;computing_engine&quot;: &quot;EGGROLL&quot;, &quot;federation_engine&quot;: &quot;EGGROLL&quot;, &quot;storage_engine&quot;: &quot;EGGROLL&quot;, &quot;engines_address&quot;: &#123;&quot;computing&quot;: &#123;&quot;cores_per_node&quot;: 20, &quot;nodes&quot;: 1&#125;, &quot;federation&quot;: &#123;&quot;host&quot;: &quot;rollsite&quot;, &quot;port&quot;: 9370&#125;, &quot;storage&quot;: &#123;&quot;cores_per_node&quot;: 20, &quot;nodes&quot;: 1&#125;&#125;, &quot;federated_mode&quot;: &quot;MULTIPLE&quot;, &quot;task_parallelism&quot;: 1, &quot;computing_partitions&quot;: 4, &quot;federated_status_collect_type&quot;: &quot;PULL&quot;, &quot;model_id&quot;: &quot;local-0#model&quot;, &quot;model_version&quot;: &quot;202107260820309976351&quot;, &quot;eggroll_run&quot;: &#123;&quot;eggroll.session.processors.per.node&quot;: 4&#125;, &quot;spark_run&quot;: &#123;&#125;, &quot;rabbitmq_run&quot;: &#123;&#125;, &quot;adaptation_parameters&quot;: &#123;&quot;task_nodes&quot;: 1, &quot;task_cores_per_node&quot;: 4, &quot;task_memory_per_node&quot;: 0, &quot;request_task_cores&quot;: 4, &quot;if_initiator_baseline&quot;: false&#125;&#125;, &quot;role&quot;: &#123;&quot;local&quot;: [0]&#125;, &quot;component_parameters&quot;: &#123;&quot;role&quot;: &#123;&quot;local&quot;: &#123;&quot;0&quot;: &#123;&quot;upload_0&quot;: &#123;&quot;name&quot;: &quot;hetero_guest&quot;, &quot;head&quot;: 1, &quot;file&quot;: &quot;/data/projects/fate/jobs/202107260820309976351/fate_upload_tmp/breast_hetero_guest.csv&quot;, &quot;partition&quot;: 1, &quot;namespace&quot;: &quot;cl&quot;, &quot;destroy&quot;: false&#125;&#125;&#125;&#125;&#125;, &quot;dsl_version&quot;: 2&#125;&#x27;, &#x27;&#123;&#125;&#x27;, &#x27;&#123;&quot;local&quot;: [0]&#125;&#x27;, 1, &#x27;local&#x27;, &#x27;0&#x27;, &#x27;waiting&#x27;, &#x27;local&#x27;, &#x27;0&#x27;, True, 0, False, False, False, 0, 0, 0, 0, 0, False])</span><br></pre></td></tr></table></figure>
</li>
<li><p>party_app.py: 对应48，若以上步骤都未 raise 异常，则调用get_json_result, 生成返回信息 success 给。 否则抛出异常</p>
</li>
<li>party_app.py: 返回信息给server端，对应46</li>
<li>fate_flow_server.py: 返回response 给api_utils.py，对应45</li>
<li>api_utils.py: 返回response 给 federated_scheduler.py，对应44</li>
<li>federated_scheduler.py: 根据response生成federated_response </li>
<li>federated_scheduler.py: 返回federated_response  给dag_scheduler.py，对应42</li>
<li>dag_scheduler.py: 返回federated_response  给data_access_app.py，对应13</li>
<li>data_access_app.py: 返回federated_response 给fate_flow_server.py，对应3</li>
<li>fate_flow_server.py: 返回federated_response 给 fate_flow_client.py 对应2</li>
<li>fate_flow_client.py: 调用prettify 在console 打印日志</li>
</ol>
<p>至此，任务提交成功</p>
<h1 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h1><p><a href="">raise</a><br><a href="">peewee</a><br><a href="http://c.biancheng.net/view/5484.html">Python <strong>new</strong>()方法详解</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-3-lifecycle/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-3-lifecycle/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（三）一般任务生命周期</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:10:55 / Modified: 13:30:33" itemprop="dateCreated datePublished" datetime="2023-08-20T12:10:55+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>从联邦建模的角度去理解整个job的生命周期，就是一系列功能模块组成的DAG，可以参照fate官方的文档，<img src="/image/fate/3cd642864c473c272b55c0efde5026e8.png" alt="image"><br>其中，各个功能模块就具体实现而言，就是fate中的各个算法或数据组件。</p>
<p>不过结合源码，从日志的角度来看，可以将整个job的生命周期，按照不同阶段所做的操作，进行划分。具体如下图：<br><img src="/image/fate/084bab7a7de64bce9decdcf09c29e14d.png" alt="job life cycle"></p>
<ol>
<li>submit：提交 job </li>
<li>create：创建job 和该job下对应的 tasks（相当于元数据） ，这里创建好之后，所有状态都是waiting</li>
<li>job schedule：对于job，按照FIFO的顺序，轮询到waiting状态的job，为其申请资源并将状态置为running。</li>
<li>task scheduler：轮询到running状态的job，对其涉及的tasks，按照依赖关系依次调度</li>
<li>execute： 执行4中置为running状态的task</li>
<li>task finish：task 运行完毕，进行资源回收和环境清理</li>
<li>job finish：job 运行完毕，进行资源回收和环境清理</li>
<li>cancel：中止正在执行的job，cancel并不算一般的生命周期中的操作，可以发生在create之后的任何阶段，接受到cancel后，在polling下一次轮询时生效</li>
</ol>
<p>此外还有非生命周期中阶段polling： 是fate_flow_server上的轮询机制，探测到各种状态的job和task分别予以相对应的操作，严格而言，并不算是job的生命周期，只是一个轮询的角色。</p>
<h1 id="样例"><a href="#样例" class="headerlink" title="样例"></a>样例</h1><p>先从最简单的upload 开始，因为upload只是一个单方的job，在job schedule 至 job finish 阶段，不涉及多方的协作，日志都在单机上，分析较为简单。参照文档，在CLI 提交如下命令<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python fate_flow_client.py -f upload -c upload_guest.json</span><br></pre></td></tr></table></figure></p>
<h1 id="日志位置"><a href="#日志位置" class="headerlink" title="日志位置"></a>日志位置</h1><p>任务提交成功后，主要产生三部分日志：</p>
<h2 id="Console-日志"><a href="#Console-日志" class="headerlink" title="Console 日志"></a>Console 日志</h2><p>提交任务完成之后，打印在屏幕上的日志<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;data&quot;: &#123;</span><br><span class="line">        &quot;board_url&quot;: &quot;http://fateboard:8080/index.html#/dashboard?job_id=202107260820309976351&amp;role=local&amp;party_id=0&quot;,</span><br><span class="line">        &quot;job_dsl_path&quot;: &quot;/data/projects/fate/jobs/202107260820309976351/job_dsl.json&quot;,</span><br><span class="line">        &quot;job_id&quot;: &quot;202107260820309976351&quot;,</span><br><span class="line">        &quot;job_runtime_conf_on_party_path&quot;: &quot;/data/projects/fate/jobs/202107260820309976351/local/job_runtime_on_party_conf.json&quot;,</span><br><span class="line">        &quot;job_runtime_conf_path&quot;: &quot;/data/projects/fate/jobs/202107260820309976351/job_runtime_conf.json&quot;,</span><br><span class="line">        &quot;logs_directory&quot;: &quot;/data/projects/fate/logs/202107260820309976351&quot;,</span><br><span class="line">        &quot;model_info&quot;: &#123;</span><br><span class="line">            &quot;model_id&quot;: &quot;local-0#model&quot;,</span><br><span class="line">            &quot;model_version&quot;: &quot;202107260820309976351&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;namespace&quot;: &quot;cl&quot;,</span><br><span class="line">        &quot;pipeline_dsl_path&quot;: &quot;/data/projects/fate/jobs/202107260820309976351/pipeline_dsl.json&quot;,</span><br><span class="line">        &quot;table_name&quot;: &quot;hetero_guest&quot;,</span><br><span class="line">        &quot;train_runtime_conf_path&quot;: &quot;/data/projects/fate/jobs/202107260820309976351/train_runtime_conf.json&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;jobId&quot;: &quot;202107260820309976351&quot;,</span><br><span class="line">    &quot;retcode&quot;: 0,</span><br><span class="line">    &quot;retmsg&quot;: &quot;success&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="容器日志"><a href="#容器日志" class="headerlink" title="容器日志"></a>容器日志</h2><p>KubeFATE部署的话，查看名为python 的容器的日志，主要是POST请求和结果的日志。<br>其中和submit job 相关部分截取如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">1. 10.200.96.235 - - [26/Jul/2021 08:20:31] &quot;POST /v1/party/202107260820309976351/local/0/create HTTP/1.1&quot; 200 -</span><br><span class="line">2. 10.200.96.235 - - [26/Jul/2021 08:20:31] &quot;POST /v1/data/upload?%7B%22file%22:%20%22/data/projects/fate/examples/data/breast_hetero_guest.csv%22,%20%22head%22:%201,%20%22partition%22:%201,%20%22work_mode%22:%201,%20%22table_name%22:%20%22hetero_guest%22,%20%22namespace%22:%20%22cl%22,%20%22config%22:%20%22/data/projects/fate/cl/upload_guest.json%22,%20%22function%22:%20%22upload%22%7D HTTP/1.1&quot; 200 -</span><br><span class="line">3. 10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/local/0/resource/apply HTTP/1.1&quot; 200 -</span><br><span class="line">4. 10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/local/0/start HTTP/1.1&quot; 200 -</span><br><span class="line">5. 10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/status/running HTTP/1.1&quot; 200 -</span><br><span class="line">6. 10.200.96.235 - - [26/Jul/2021 08:20:32] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/start HTTP/1.1&quot; 200 -</span><br><span class="line">7. 10.200.96.235 - - [26/Jul/2021 08:20:33] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/report HTTP/1.1&quot; 200 -</span><br><span class="line">8. 10.200.96.235 - - [26/Jul/2021 08:20:34] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">9. 10.200.96.235 - - [26/Jul/2021 08:20:36] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">10. 10.200.96.235 - - [26/Jul/2021 08:20:38] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">11. 10.200.96.235 - - [26/Jul/2021 08:20:40] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">12. 10.200.96.235 - - [26/Jul/2021 08:20:41] &quot;POST /v1/party/202107260820309976351/local/0/update HTTP/1.1&quot; 200 -</span><br><span class="line">13. 10.200.96.235 - - [26/Jul/2021 08:20:42] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">14. 10.200.96.235 - - [26/Jul/2021 08:20:43] &quot;POST /v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/output_data_info/save HTTP/1.1&quot; 200 -</span><br><span class="line">15. 10.200.96.235 - - [26/Jul/2021 08:20:43] &quot;POST /v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/metric_data/save HTTP/1.1&quot; 200 -</span><br><span class="line">16. 10.200.96.235 - - [26/Jul/2021 08:20:43] &quot;POST /v1/tracker/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/metric_meta/save HTTP/1.1&quot; 200 -</span><br><span class="line">17. 10.200.96.235 - - [26/Jul/2021 08:20:44] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/report HTTP/1.1&quot; 200 -</span><br><span class="line">18. 10.200.96.235 - - [26/Jul/2021 08:20:45] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/collect HTTP/1.1&quot; 200 -</span><br><span class="line">19. 10.200.96.235 - - [26/Jul/2021 08:20:45] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/report HTTP/1.1&quot; 200 -</span><br><span class="line">static conf path: /data/projects/fate/eggroll/conf/eggroll.properties</span><br><span class="line">20. 10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/status/success HTTP/1.1&quot; 200 -</span><br><span class="line">21. 10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/upload_0/202107260820309976351_upload_0/0/local/0/stop/success HTTP/1.1&quot; 200 -</span><br><span class="line">22. 10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/local/0/model HTTP/1.1&quot; 200 -</span><br><span class="line">23. 10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/local/0/status/success HTTP/1.1&quot; 200 -</span><br><span class="line">24. 10.200.96.235 - - [26/Jul/2021 08:20:47] &quot;POST /v1/party/202107260820309976351/local/0/stop/success HTTP/1.1&quot; 200 -</span><br><span class="line">25. 10.200.96.235 - - [26/Jul/2021 08:20:48] &quot;POST /v1/party/202107260820309976351/local/0/clean HTTP/1.1&quot; 200 -</span><br><span class="line">26. 10.200.96.235 - - [26/Jul/2021 08:20:48] &quot;POST /v1/party/202107260820309976351/local/0/stop/success HTTP/1.1&quot; 200 -</span><br><span class="line">27. 10.200.96.235 - - [26/Jul/2021 08:20:48] &quot;POST /v1/party/202107260820309976351/local/0/clean HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure><br>该生命周期中，各个阶段的情况，在这里都有体现。</p>
<h2 id="FATE-Flow-日志"><a href="#FATE-Flow-日志" class="headerlink" title="FATE Flow 日志"></a>FATE Flow 日志</h2><p>日志会生成在fate_flow 和 jobid 两个目录下，为了便于区分，分别会用fate_flow/xxx.log 和 $ {job_log_dir}/xxx.log 进行区分。<br>此外${job_log_dir}下还可进一步细分为如下几个目录：</p>
<ul>
<li>${job_log_dir}</li>
<li>$ {job_log_dir}/$ {role}/${party}</li>
<li>$ {job_log_dir}/$ {role}/$ {party}/${taskid} = ${task_log_dir}<h3 id="fate-flow-server-日志，位于-data-projects-fate-logs-fate-flow-目录下，说明见前文："><a href="#fate-flow-server-日志，位于-data-projects-fate-logs-fate-flow-目录下，说明见前文：" class="headerlink" title="fate_flow_server 日志，位于/data/projects/fate/logs/fate_flow 目录下，说明见前文："></a>fate_flow_server 日志，位于/data/projects/fate/logs/fate_flow 目录下，说明见前文：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- fate_flow_audit.log</span><br><span class="line">- fate_flow_detect.log</span><br><span class="line">- fate_flow_stat.log</span><br><span class="line">- fate_flow_schedule.log</span><br><span class="line">- peewee.log</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="job日志"><a href="#job日志" class="headerlink" title="job日志"></a>job日志</h3><p>位于/data/projects/fate/logs/${jobid} 下（此目录后文称之为job_log_dir），量级过大，这里只列下目录，每个日志的说明，见前文。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">- fate_flow_audit.log：</span><br><span class="line">- fate_flow_schedule.log  </span><br><span class="line">- fate_flow_sql.log  </span><br><span class="line">+ $&#123;role&#125;</span><br><span class="line">    + $&#123;party&#125;</span><br><span class="line">        - DEBUG.log  </span><br><span class="line">        - INFO.log  </span><br><span class="line">        + $&#123;taskid&#125;</span><br><span class="line">            - DEBUG.log  </span><br><span class="line">            - fate_flow_schedule.log  </span><br><span class="line">            - INFO.log  </span><br><span class="line">            - peewee.log  </span><br><span class="line">            - PROFILING.log  </span><br><span class="line">            - stat.log  </span><br><span class="line">            - std.log</span><br></pre></td></tr></table></figure></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-2-start-fateflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-2-start-fateflow/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（二）fate_flow server 启动</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:10:46 / Modified: 12:24:01" itemprop="dateCreated datePublished" datetime="2023-08-20T12:10:46+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><ul>
<li>代码：python/fate_flow/fate_flow_server.py</li>
<li>web框架：Flask</li>
</ul>
<p>流程为：</p>
<ol>
<li>执行 python fate_flow_server.py ，这部分会在容器中打出相应日志。</li>
<li><p>fate_flow_server 执行启动过程。这里可以看下logs目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(app-root) bash-4.2# pwd</span><br><span class="line">/data/projects/fate/logs</span><br><span class="line">(app-root) bash-4.2# ls</span><br><span class="line">fate_flow</span><br><span class="line">(app-root) bash-4.2# ls fate_flow/</span><br><span class="line">DEBUG.log  fate_flow_detect.log  fate_flow_schedule.log  fate_flow_stat.log  INFO.log  peewee.log</span><br></pre></td></tr></table></figure>
<p>可以看到，由于没有提交任何任务，当前只有一个fate_flow的目录，这里记录的是fate_flow_server启动的日志。具体而言</p>
<ul>
<li>peewee.log：fate中操作db，使用了peewee，这里记录所有通过peewee操作数据库的日志</li>
<li>fate_flow_detect.log：探测器日志</li>
<li>fate_flow_schedule.log：调度器日志</li>
<li>fate_flow_stat.log：除以上3部分外的其余状态日志</li>
<li>DEBUG.log、INFO.log、WARNING.log、ERROR.log：各级别日志，会将以上各部分（除了fate_flow_detect.log，这个后续单独说明逻辑）中对应级别的日志收集。<br>因fate_flow_server 启动的日志，均输出在fate_flow 目录中，故本文所述的日志，均为fate_flow目录中的对应日志。</li>
</ul>
</li>
</ol>
<h1 id="执行-fate-flow-server-py"><a href="#执行-fate-flow-server-py" class="headerlink" title="执行 fate_flow_server.py"></a>执行 fate_flow_server.py</h1><p>由于是KubeFATE 部署，直接查看容器日志即可。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+ mkdir -p /data/projects/fate/conf/</span><br><span class="line">+ cp /data/projects/fate/conf1/transfer_conf.yaml /data/projects/fate/conf/transfer_conf.yaml</span><br><span class="line">+ cp /data/projects/fate/conf1/service_conf.yaml /data/projects/fate/conf/service_conf.yaml</span><br><span class="line">+ cp /data/projects/fate/conf1/pipeline_conf.yaml /data/projects/fate/conf/pipeline_conf.yaml</span><br><span class="line">+ sed -i &#x27;s/host: fateflow/host: 10.200.96.237/g&#x27; /data/projects/fate/conf/service_conf.yaml</span><br><span class="line">+ sed -i &#x27;s/ip: fateflow/ip: 10.200.96.237/g&#x27; /data/projects/fate/conf/pipeline_conf.yaml</span><br><span class="line">+ cp -r /data/projects/fate/examples /data/projects/fate/examples-shared-for-client</span><br><span class="line">+ sleep 5</span><br><span class="line">+ python ./fate_flow/fate_flow_server.py</span><br><span class="line"> * Running on http://10.200.96.237:9380/ (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure></p>
<p>从上述命令可以看出，涉及操作是创建目录-&gt;复制配置文件-&gt;启动 fate_flow_server.py。</p>
<h1 id="fate-flow-server-启动细节"><a href="#fate-flow-server-启动细节" class="headerlink" title="fate_flow_server 启动细节"></a>fate_flow_server 启动细节</h1><p><img src="/image/fate/a87d7d3622cc4f37a72b64b57de9577b.png" alt="fate_flow server 启动uml图"></p>
<ol>
<li><p>fate_flow_server.py：定义app变量，定义server能提供的服务，这一部分源码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">app = DispatcherMiddleware(</span><br><span class="line">    manager,</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;/&#123;&#125;/data&#x27;.format(API_VERSION): data_access_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/model&#x27;.format(API_VERSION): model_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/job&#x27;.format(API_VERSION): job_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/table&#x27;.format(API_VERSION): table_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/tracking&#x27;.format(API_VERSION): tracking_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/pipeline&#x27;.format(API_VERSION): pipeline_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/permission&#x27;.format(API_VERSION): permission_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/version&#x27;.format(API_VERSION): version_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/party&#x27;.format(API_VERSION): party_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/initiator&#x27;.format(API_VERSION): initiator_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/tracker&#x27;.format(API_VERSION): tracker_app_manager,</span><br><span class="line">        &#x27;/&#123;&#125;/forward&#x27;.format(API_VERSION): proxy_app_manager</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>不同的manager对应不同模块的功能。详细说明参照REF1，</p>
</li>
<li><p>fate_flow_server.py：调用db_models.init_database_tables()具体执行在 3 中。这里代码里是init_flow_db()，实际是db_models.init_database_tables()的别名。用来和init_arch_db()区分。</p>
</li>
<li><p>fate_flow/db/db_models.py： 初始化fate_flow相关表。注意，在类初始化时，这里会进行一次判断，cluster模式使用mysql，standalone 模式使用sqlite。这一部分日志会输出到fate_flow_stat.log 中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 07:14:02,439] [1:140691673888576] - db_models.py[line:60]: init mysql database on cluster mode successfully</span><br></pre></td></tr></table></figure>
<p>这里涉及t_job、t_task、t_tracking_metric、t_tracking_output_data_info、t_machine_learning_model_info、t_model_tag、t_tags、t_component_summary、t_model_operation_log、t_engine_registry 等10张表。会执行建表和建索引的相关操作。各表具体字段可以查看源码。这部分日志会在peewee.log 中打出。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(&#x27;CREATE TABLE IF NOT EXISTS `componentsummary` (`f_id` BIGINT AUTO_INCREMENT NOT NULL PRIMARY KEY, `f_create_time` BIGINT, `f_create_date` DATETIME, `f_update_time` BIGINT, `f_update_date` DATETIME, `f_job_id` VARCHAR(25) NOT NULL, `f_role` VARCHAR(25) NOT NULL, `f_party_id` VARCHAR(10) NOT NULL, `f_component_name` TEXT NOT NULL, `f_task_id` VARCHAR(50), `f_task_version` VARCHAR(50), `f_summary` LONGTEXT NOT NULL)&#x27;, [])</span><br></pre></td></tr></table></figure>
<p><strong>注：本地debug时，默认为standalone模式，会在目录生成一个fate_flow_sqlite.db数据库文件</strong></p>
</li>
<li><p>fate_flow_server.py： 调用db_models.init_database_tables() 具体执行在5。</p>
</li>
<li>fate_arch/storage/metastore/db_models.py：初始化fate_arch相关表，和3类似，也会根据部署模式选择不同的数据库。<br>诶，然后这里没打日志。。。<br>这里涉及t_storage_table_meta、t_session_record 两张表。也会执行建表和建索引的相关操作。各表具体字段可以查看源码。这部分日志会在peewee.log 中紧接着3打出。</li>
<li>fate_flow_server.py： 使用argparse解析入参</li>
<li>fate_flow_server.py：调用RuntimeConfig.init_ent() 加载环境变量，调用RuntimeConfig.set_process_role() 设置为driver(?这里driver和executor 的区别？）</li>
<li>fate_flow_server.py：调用PrivilegeAuth.init() 进行鉴权模块初始化。</li>
<li>authentication_utils.py：根据配置项（默认是否）决定是否初始化各个role支持的component，这一部分日志会输出在fate_flow_stat.log中。</li>
<li>fate_flow_server.py：调用ServiceUtils.register() 注册服务</li>
<li>authentication_utils.py：根据配置项（默认是否），决定是否注册。如需注册，需要安装zookeeper，这一部分日志会输出在fate_flow_stat.log中。</li>
<li>fate_flow_server.py：调用ResourceManager.initialize() 初始化资源管理器</li>
<li>resource_manager.py：调用register_engine 初始化各项信息。<br>这里会根据配置文件python/fate_flow/settings.py 中的如下内容<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># Storage engine is used for component output data</span><br><span class="line">SUPPORT_BACKENDS_ENTRANCE = &#123;</span><br><span class="line">    &quot;fate_on_eggroll&quot;: &#123;</span><br><span class="line">        EngineType.COMPUTING: (ComputingEngine.EGGROLL, &quot;clustermanager&quot;),</span><br><span class="line">        EngineType.STORAGE: (StorageEngine.EGGROLL, &quot;clustermanager&quot;),</span><br><span class="line">        EngineType.FEDERATION: (FederationEngine.EGGROLL, &quot;rollsite&quot;),</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;fate_on_spark&quot;: &#123;</span><br><span class="line">        EngineType.COMPUTING: (ComputingEngine.SPARK, &quot;spark&quot;),</span><br><span class="line">        EngineType.STORAGE: (StorageEngine.HDFS, &quot;hdfs&quot;),</span><br><span class="line">        EngineType.FEDERATION: (FederationEngine.RABBITMQ, &quot;rabbitmq&quot;),</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
遍历不同的EngineType的engine_name，即COMPUTING、STORAGE、FEDERATION三个部分，创建相关记录。再将如上EngineType中各个engine_name替换为standalone，再遍历一次。<br>创建相关记录流程为先查询f_engine_entrance表中，是有有该f_engine_type和f_engine_name的值，如没有，执行insert 如有，则update 相关信息。故而针对如上配置的流程为：<ul>
<li>依此遍历fate_on_eggroll，fate_on_spark中 clustermanager，clustermanager，rollsite。因select 之后的结果都为空，故相关操作都是create信息，在peewee.log 中的日志为INSERT</li>
<li>fate_on_eggroll中，将engine_name替换为standalone后，再一次遍历。因select 之后的结果都为空，故相关操作都是create信息，在peewee.log 中的日志为INSERT。</li>
<li>fate_on_spark中，将engine_name替换为standalone后，再一次遍历。因上一步已经create相关记录，皆为update操作，在peewee.log 中的日志为UPDATE。</li>
</ul>
</li>
</ol>
<p>sql执行情况样例见 peewee.log<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 07:14:06,066] [1:140691673888576] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_engine_type`, `t1`.`f_engine_name`, `t1`.`f_engine_entrance`, `t1`.`f_engine_config`, `t1`.`f_cores`, `t1`.`f_memory`, `t1`.`f_remaining_cores`, `t1`.`f_remaining_memory`, `t1`.`f_nodes` FROM `t_engine_registry` AS `t1` WHERE ((`t1`.`f_engine_type` = %s) AND (`t1`.`f_engine_name` = %s))&#x27;, [&#x27;computing&#x27;, &#x27;EGGROLL&#x27;])</span><br><span class="line">[DEBUG] [2021-07-26 07:14:06,072] [1:140691673888576] - peewee.py[line:2863]: (&#x27;INSERT INTO `t_engine_registry` (`f_create_time`, `f_create_date`, `f_update_time`, `f_update_date`, `f_engine_type`, `f_engine_name`, `f_engine_entrance`, `f_engine_config`, `f_cores`, `f_memory`, `f_remaining_cores`, `f_remaining_memory`, `f_nodes`) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)&#x27;, [1627283646068, datetime.datetime(2021, 7, 26, 7, 14, 6), 1627283646068, datetime.datetime(2021, 7, 26, 7, 14, 6), &#x27;computing&#x27;, &#x27;EGGROLL&#x27;, &#x27;clustermanager&#x27;, &#x27;&#123;&quot;cores_per_node&quot;: 20, &quot;nodes&quot;: 1&#125;&#x27;, 20, 0, 20, 0, 1])</span><br><span class="line"></span><br><span class="line">[DEBUG] [2021-07-26 07:14:06,242] [1:140691673888576] - peewee.py[line:2863]: (&#x27;UPDATE `t_engine_registry` SET `f_engine_config` = %s, `f_cores` = %s, `f_memory` = %s, `f_remaining_cores` = (`t_engine_registry`.`f_remaining_cores` + %s), `f_remaining_memory` = (`t_engine_registry`.`f_remaining_memory` + %s), `f_nodes` = %s WHERE ((`t_engine_registry`.`f_engine_type` = %s) AND (`t_engine_registry`.`f_engine_name` = %s))&#x27;, [&#x27;&#123;&quot;nodes&quot;: 1, &quot;cores_per_node&quot;: 20&#125;&#x27;, 20, 0, 0, 0, 1, &#x27;storage&#x27;, &#x27;STANDALONE&#x27;])</span><br></pre></td></tr></table></figure></p>
<p>fate_flow具体的日志，打在fate_flow_stat.log 中，如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 07:14:06,077] [1:140691673888576] - resource_manager.py[line:94]: create computing engine EGGROLL clustermanager registration information</span><br><span class="line">[INFO] [2021-07-26 07:14:06,097] [1:140691673888576] - resource_manager.py[line:94]: create storage engine EGGROLL clustermanager registration information</span><br><span class="line">[INFO] [2021-07-26 07:14:06,117] [1:140691673888576] - resource_manager.py[line:94]: create federation engine EGGROLL rollsite registration information</span><br><span class="line">[INFO] [2021-07-26 07:14:06,139] [1:140691673888576] - resource_manager.py[line:94]: create computing engine SPARK spark registration information</span><br><span class="line">[INFO] [2021-07-26 07:14:06,175] [1:140691673888576] - resource_manager.py[line:94]: create storage engine HDFS hdfs registration information</span><br><span class="line">[INFO] [2021-07-26 07:14:06,199] [1:140691673888576] - resource_manager.py[line:94]: create federation engine RABBITMQ rabbitmq registration information</span><br><span class="line">[INFO] [2021-07-26 07:14:06,207] [1:140691673888576] - resource_manager.py[line:94]: create computing engine STANDALONE fateflow registration information</span><br><span class="line">[INFO] [2021-07-26 07:14:06,216] [1:140691673888576] - resource_manager.py[line:94]: create storage engine STANDALONE fateflow registration information</span><br><span class="line">[INFO] [2021-07-26 07:14:06,227] [1:140691673888576] - resource_manager.py[line:94]: create federation engine STANDALONE fateflow registration information</span><br><span class="line">[INFO] [2021-07-26 07:14:06,236] [1:140691673888576] - resource_manager.py[line:76]: update computing engine STANDALONE fateflow registration information takes no effect</span><br><span class="line">[INFO] [2021-07-26 07:14:06,243] [1:140691673888576] - resource_manager.py[line:76]: update storage engine STANDALONE fateflow registration information takes no effect</span><br><span class="line">[INFO] [2021-07-26 07:14:06,253] [1:140691673888576] - resource_manager.py[line:76]: update federation engine STANDALONE fateflow registration information takes no effect</span><br></pre></td></tr></table></figure></p>
<ol>
<li>fate_flow_server.py：启动探测器， Detecor().start，每隔5秒轮询</li>
<li>detect.py： 一次探测如下四个类型的任务running_task，running_job，resource_record，expired_session，探测到之后，执行相关操作。日志包括两部分，查询DB的日志记录在peewee.log，fate_flow的日志记录在fate_flow/fate_flow_detect.log 中<ul>
<li>running_task：查询db获取所有处于running的TASK的信息-&gt;遍历每个TASK的pid，查看是否存在(通过kill(pid,0)检查）。如不存在（不在运行），则存入stop_job_ids-&gt; 遍历stop_job_ids，发起stop请求(此处仍为异步)-&gt;打印出running状态的task数量。</li>
<li>running_job：查询db获取所有处于running的JOB的信息-&gt;遍历每个JOB判断是否超时（默认超时限制为3天）-&gt; 对超时的job发起stop请求。</li>
<li>resource_record：回收资源，查询DB，获取所有资源处于使用中，且任务状态已经结束，并且申请资源时间超过600s的任务，依次遍历任务回收资源。</li>
<li>expired_session：查询过期(超过5小时)session ，依次遍历并终止</li>
</ul>
</li>
</ol>
<p>注意，这里打日志，是调用log.py 中 detect_log() 方法，而不是 settings.py 中的LoggerFactory.getLogger(“fate_flow_detect”)<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 07:14:11,255] [1:140691103205120] - detector.py[line:38]: start to detect running task..</span><br><span class="line">[INFO] [2021-07-26 07:14:11,264] [1:140691103205120] - detector.py[line:70]: finish detect 0 running task</span><br><span class="line">[INFO] [2021-07-26 07:14:11,264] [1:140691103205120] - detector.py[line:74]: start detect running job</span><br><span class="line">[INFO] [2021-07-26 07:14:11,272] [1:140691103205120] - detector.py[line:88]: finish detect running job</span><br><span class="line">[INFO] [2021-07-26 07:14:11,273] [1:140691103205120] - detector.py[line:93]: start detect resource recycle</span><br><span class="line">[INFO] [2021-07-26 07:14:11,280] [1:140691103205120] - detector.py[line:116]: finish detect resource recycle</span><br><span class="line">[INFO] [2021-07-26 07:14:11,280] [1:140691103205120] - detector.py[line:120]: start detect expired session</span><br></pre></td></tr></table></figure></p>
<ol>
<li>fate_flow_server.py：启动DagScheduler，每隔2秒轮询，调度处于waiting状态的任务</li>
<li>dag_scheduler.py：调度job，依次调度如下五部分</li>
</ol>
<ul>
<li>调度处于waiting 状态的job:schedule_waiting_jobs(job=job)，调用start_job 启动任务 ，调度的日志输出在fate_flow/fate_flow_scheduler.log 中，start_job 中，再调用FederatedScheduler.start_job(job=job)的日志，就输出到jobid/fate_flow_scheduler.log 中了。<br>这里每次只能调度一个处于waiting 状态的任务，通过order_by=”create_time” 和  job = jobs[0] 实现</li>
<li>调度处于running 状态的job:，不同于waiting，因为是异步提交，考虑到资源问题，每次只调度一个，running状态的调度，主要检查状态等，故从DB中获取到所有running状态的任务后，都会依次遍历，调用schedule_running_job(job=job)，是判断任务是否被取消，任务状态为结束时，保存模型。并调用FederatedScheduler.sync_job_status(job=job)同步任务状态。</li>
<li>调度ready状态的job:schedule_ready_job(job=job)</li>
<li>调度rerun任务的job:schedule_rerun_job(job=job)</li>
<li>更新已经为endstatus的job的status：end_scheduling_updates(job_id=job.f_job_id)</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 07:14:08,324] [1:140259369826048] - dag_scheduler.py[line:134]: start schedule waiting jobs</span><br><span class="line">[INFO] [2021-07-26 07:14:08,339] [1:140259369826048] - dag_scheduler.py[line:136]: have 0 waiting jobs</span><br><span class="line">[INFO] [2021-07-26 07:14:08,339] [1:140259369826048] - dag_scheduler.py[line:146]: schedule waiting jobs finished</span><br><span class="line">[INFO] [2021-07-26 07:14:08,339] [1:140259369826048] - dag_scheduler.py[line:148]: start schedule running jobs</span><br><span class="line">[INFO] [2021-07-26 07:14:08,348] [1:140259369826048] - dag_scheduler.py[line:150]: have 0 running jobs</span><br><span class="line">[INFO] [2021-07-26 07:14:08,349] [1:140259369826048] - dag_scheduler.py[line:158]: schedule running jobs finished</span><br><span class="line">[INFO] [2021-07-26 07:14:08,349] [1:140259369826048] - dag_scheduler.py[line:161]: start schedule ready jobs</span><br><span class="line">[INFO] [2021-07-26 07:14:08,359] [1:140259369826048] - dag_scheduler.py[line:163]: have 0 ready jobs</span><br><span class="line">[INFO] [2021-07-26 07:14:08,359] [1:140259369826048] - dag_scheduler.py[line:171]: schedule ready jobs finished</span><br><span class="line">[INFO] [2021-07-26 07:14:08,359] [1:140259369826048] - dag_scheduler.py[line:173]: start schedule rerun jobs</span><br><span class="line">[INFO] [2021-07-26 07:14:08,367] [1:140259369826048] - dag_scheduler.py[line:175]: have 0 rerun jobs</span><br><span class="line">[INFO] [2021-07-26 07:14:08,367] [1:140259369826048] - dag_scheduler.py[line:183]: schedule rerun jobs finished</span><br><span class="line">[INFO] [2021-07-26 07:14:08,368] [1:140259369826048] - dag_scheduler.py[line:185]: start schedule end status jobs to update status</span><br><span class="line">[INFO] [2021-07-26 07:14:08,375] [1:140259369826048] - dag_scheduler.py[line:187]: have 0 end status jobs</span><br><span class="line">[INFO] [2021-07-26 07:14:08,376] [1:140259369826048] - dag_scheduler.py[line:199]: schedule end status jobs finished</span><br></pre></td></tr></table></figure>
<p>每次查询各状态的任务时，都会操作db，对应的peewee.log 日志类似<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 07:14:08,260] [1:140691094812416] - peewee.py[line:2863]: (&#x27;SELECT `t1`.`f_create_time`, `t1`.`f_create_date`, `t1`.`f_update_time`, `t1`.`f_update_date`, `t1`.`f_user_id`, `t1`.`f_job_id`, `t1`.`f_name`, `t1`.`f_description`, `t1`.`f_tag`, `t1`.`f_dsl`, `t1`.`f_runtime_conf`, `t1`.`f_runtime_conf_on_party`, `t1`.`f_train_runtime_conf`, `t1`.`f_roles`, `t1`.`f_work_mode`, `t1`.`f_initiator_role`, `t1`.`f_initiator_party_id`, `t1`.`f_status`, `t1`.`f_status_code`, `t1`.`f_role`, `t1`.`f_party_id`, `t1`.`f_is_initiator`, `t1`.`f_progress`, `t1`.`f_ready_signal`, `t1`.`f_ready_time`, `t1`.`f_cancel_signal`, `t1`.`f_cancel_time`, `t1`.`f_rerun_signal`, `t1`.`f_end_scheduling_updates`, `t1`.`f_engine_name`, `t1`.`f_engine_type`, `t1`.`f_cores`, `t1`.`f_memory`, `t1`.`f_remaining_cores`, `t1`.`f_remaining_memory`, `t1`.`f_resource_in_use`, `t1`.`f_apply_resource_time`, `t1`.`f_return_resource_time`, `t1`.`f_start_time`, `t1`.`f_start_date`, `t1`.`f_end_time`, `t1`.`f_end_date`, `t1`.`f_elapsed` FROM `t_job` AS `t1` WHERE ((`t1`.`f_is_initiator` = %s) AND (`t1`.`f_status` = %s)) ORDER BY `t1`.`f_create_time` ASC&#x27;, [True, &#x27;waiting&#x27;])</span><br></pre></td></tr></table></figure></p>
<ol>
<li>fate_flow_server.py：启动grpc server服务，用于不同的rollsite 通信<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 07:14:06,255] [1:140691673888576] - fate_flow_server.py[line:107]: start grpc server thread pool by 40 max workers</span><br><span class="line">[INFO] [2021-07-26 07:14:06,268] [1:140691673888576] - fate_flow_server.py[line:115]: FATE Flow grpc server start successfully</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>fate_flow_server.py：启动http server服务，用于处理本地fate_flow_client 和 fate_flow_server 之间的通信。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 07:14:06,269] [1:140691673888576] - fate_flow_server.py[line:118]: FATE Flow http server start...</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h1><p><a href="https://flask.palletsprojects.com/en/2.0.x/">Flask</a><br><a href="https://os.51cto.com/art/202105/664200.htm">os.kill(pid,0)</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="喵十八"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">喵十八</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">58</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">78</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Yao544303" title="GitHub → https://github.com/Yao544303" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yao544303963@gmail.com" title="E-Mail → mailto:yao544303963@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/yao544303963" title="CSDN → https://blog.csdn.net/yao544303963" rel="noopener" target="_blank"><i class="fa fa-crosshairs fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/yourname" title="Twitter → https://twitter.com/yourname" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">喵十八</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


</body>
</html>
