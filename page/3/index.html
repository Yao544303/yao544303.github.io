<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0-rc2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":true,"nav":{"gitalk":{"order":-1}},"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="喵十八の小窝">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="喵十八の小窝">
<meta property="og:locale">
<meta property="article:author" content="喵十八">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>喵十八の小窝</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">喵十八の小窝</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fate-log-1-dir-struct/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fate-log-1-dir-struct/" class="post-title-link" itemprop="url">FATE学习：跟着日志读源码（一）日志目录结构</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 12:10:35 / Modified: 12:18:49" itemprop="dateCreated datePublished" datetime="2023-08-20T12:10:35+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>介绍fate运行过程中产生的各个类型日志</p>
<h1 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h1><p>部署方式为KubeFATE。相关版本为：</p>
<ul>
<li>FATE: 1.5.1</li>
<li>KubeFATE: v1.3.0</li>
</ul>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><ul>
<li>job：一个完整的调度单元，可以拆分成不同的task。</li>
<li>task：最小的执行单元。</li>
<li>component：预先定义的不同组件，具体的task执行，就是运行不同的组件。</li>
</ul>
<h1 id="FATE框架"><a href="#FATE框架" class="headerlink" title="FATE框架"></a>FATE框架</h1><p>根据官方的架构图，在单个Party的上FATE-Flow 的架构如下<br><img src="/image/fate/fea45d92e84d4785acd417e65dc420d7.png" alt=""></p>
<p>整体分成6大块：</p>
<ul>
<li>FATE-Flow Client: 客户端，提供给用户的交互接口，日常提交的命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python fate_flow_client.py -f submit_job -c examples/test_hetero_lr_job_conf.json -d examples/test_hetero_lr_job_dsl.json</span><br></pre></td></tr></table></figure>
就是调用了客户端。</li>
<li>FATE-Flow Server: 服务端，用于处理Client 提交的各类请求。</li>
<li>FATE-Board: Web UI，用于监控FATE 任务的运行情况。</li>
<li>Transfer : 用来处理多方联邦时的交互和通信</li>
<li>Metadata Service: 对联邦过程，产生的各类Metadata进行存储、管理并提供查询</li>
<li>Local FileSystem: 本地文件系统，进行持久化</li>
<li>Storage &amp; Computing: 底层存储和计算引擎</li>
</ul>
<p>其中 FATE-Flow Server 最为复杂，</p>
<ul>
<li>API Service: 处理Client 提交的各类请求</li>
<li>Job Queue: 异步调度的方式，所有提交的job 先进入job queue （见后文，所有job创建完毕，都是waiting状态）,根据资源情况，进行下发（调度策略是啥？？）</li>
<li>DAG Scheduler: 每个job 会根据涉及的计算内容，解析为一个DAG（有向无环图），图中的每个节点为一个task。针对每个job，通过一个DAG Scheduler 进行该job下涉及task 的调度。</li>
<li>Task Scheduler: task 在本Party的调度，涉及到跨多个Party 会调用Federated Task Scheduler 进行调度。</li>
<li>Federated Task Scheduler:涉及到跨多个Party 的Task 的调度</li>
<li>Executor: 联邦任务执行节点，支持不同的 Operator 容器。这里会调用Framework </li>
<li>Framework: 计算框架抽象层，根据backend 的设置 调用底层的Storage &amp; Computing，同时若为联邦任务，则和Transfer 进行通信。</li>
<li>DSL Parser: 是调度的核心，通过 DSL parser 解析到一个计算任务的上下游关系及依赖等。</li>
<li>Controller: 任务的控制器</li>
<li>Model Registry: 模型管理器</li>
<li>Tracking Manager：任务输入输出的实时追踪，包括每个 task 输出的 data 和 model。</li>
</ul>
<h1 id="日志分类"><a href="#日志分类" class="headerlink" title="日志分类"></a>日志分类</h1><p>从FATE的框架，可以看出FATE 涉及大量的http/grpc 请求， 以及DB操作，因而按照日志的操作来源分，主要有一下三类：</p>
<ul>
<li>http/grpc 请求日志</li>
<li>操作DB的日志</li>
<li>fate 框架运行时的日志</li>
</ul>
<p>而从日志输出的位置来看，则可以分为如下三类：</p>
<ul>
<li>Console 日志</li>
<li>容器日志</li>
<li>FATE Flow 日志</li>
</ul>
<p>鉴于按照位置来看，可以更好的体现出整个执行的时序，下文会按照这个维度，来进行解析</p>
<h1 id="Console-日志"><a href="#Console-日志" class="headerlink" title="Console 日志"></a>Console 日志</h1><p>控制台部分，也是就正常提交任务之后会产生的日志，例如 执行命令<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python fate_flow_client.py -f upload -c examples/upload_guest.json</span><br></pre></td></tr></table></figure></p>
<p>返回的日志为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;data&quot;: &#123;</span><br><span class="line">        &quot;board_url&quot;: &quot;http://fateboard:8080/index.html#/dashboard?job_id=20210720163310959474309&amp;role=local&amp;party_id=0&quot;,</span><br><span class="line">        &quot;job_dsl_path&quot;: &quot;/data/projects/fate/jobs/20210720163310959474309/job_dsl.json&quot;,</span><br><span class="line">        &quot;job_id&quot;: &quot;20210720163310959474309&quot;,</span><br><span class="line">        &quot;job_runtime_conf_on_party_path&quot;: &quot;/data/projects/fate/jobs/20210720163310959474309/local/job_runtime_on_party_conf.json&quot;,</span><br><span class="line">        &quot;job_runtime_conf_path&quot;: &quot;/data/projects/fate/jobs/20210720163310959474309/job_runtime_conf.json&quot;,</span><br><span class="line">        &quot;logs_directory&quot;: &quot;/data/projects/fate/logs/20210720163310959474309&quot;,</span><br><span class="line">        &quot;model_info&quot;: &#123;</span><br><span class="line">            &quot;model_id&quot;: &quot;local-0#model&quot;,</span><br><span class="line">            &quot;model_version&quot;: &quot;20210720163310959474309&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;namespace&quot;: &quot;cl&quot;,</span><br><span class="line">        &quot;pipeline_dsl_path&quot;: &quot;/data/projects/fate/jobs/20210720163310959474309/pipeline_dsl.json&quot;,</span><br><span class="line">        &quot;table_name&quot;: &quot;bgame3342_20210719&quot;,</span><br><span class="line">        &quot;train_runtime_conf_path&quot;: &quot;/data/projects/fate/jobs/20210720163310959474309/train_runtime_conf.json&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;jobId&quot;: &quot;20210720163310959474309&quot;,</span><br><span class="line">    &quot;retcode&quot;: 0,</span><br><span class="line">    &quot;retmsg&quot;: &quot;success&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>包含4个部分：</p>
<ul>
<li>data: 提交任务的相关参数</li>
<li>jobId: FATE为该job分配的id</li>
<li>retcode: 提交请求的返回状态码</li>
<li>retmsg: 提交请求返回的状态信息。如不成功，会有相关报错。<br>这里需要关注的日志信息，只有retmsg。</li>
</ul>
<h1 id="Server日志"><a href="#Server日志" class="headerlink" title="Server日志"></a>Server日志</h1><p>这一部分日志，可以在部署fate_flow server 的容器中看到。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10.200.224.54 - - [20/Jul/2021 16:33:12] &quot;POST /v1/party/20210720163310959474309/local/0/create HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.224.54 - - [20/Jul/2021 16:33:12] &quot;POST /v1/data/upload?%7B%22file%22:%20%22/data/projects/fate/python/cl/fc/data/predict_data/20210719/bgame3342_20210719.csv%22,%20%22head%22:%201,%20%22partition%22:%201,%20%22work_mode%22:%201,%20%22table_name%22:%20%22bgame3342_20210719%22,%20%22namespace%22:%20%22cl%22,%20%22count%22:%20752361,%20%22config%22:%20%22/data/projects/fate/python/cl/fc/config/20210719/upload_20210719_bgame3342.json%22,%20%22function%22:%20%22upload%22,%20%22drop%22:%20%221%22%7D HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.224.54 - - [20/Jul/2021 16:33:14] &quot;POST /v1/party/20210720163310959474309/local/0/resource/apply HTTP/1.1&quot; 200 -</span><br><span class="line">10.200.224.54 - - [20/Jul/2021 16:33:14] &quot;POST /v1/party/20210720163310959474309/local/0/start HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure><br>记录了 FATE-Flow Server 收到的POST请求。<br>这一部分主要是federate_scheduler.py 向server 发起的POST 请求。</p>
<h1 id="FATE-Flow-日志"><a href="#FATE-Flow-日志" class="headerlink" title="FATE Flow 日志"></a>FATE Flow 日志</h1><p>这一部分是fate运行过程中的主要产生的日志，用来排查fate job、task的运行状况。目录位于kubefate 的容器中， /data/projects/fate/logs/<br>其中 fate_flow 目录记录了fate 启动以来的总体的日志。 各个${jobid} 目录下，记录了各个job详细的日志。<br>相关处理类：python/fate_arch/common/log.py</p>
<h2 id="fate-flow-目录下日志分类"><a href="#fate-flow-目录下日志分类" class="headerlink" title="fate_flow 目录下日志分类"></a>fate_flow 目录下日志分类</h2><p>总的结构类似，分成如下几个类型的日志</p>
<ul>
<li>DEBUG.log</li>
<li>INFO.log</li>
<li>ERROR.log</li>
<li>WARNING.log</li>
<li>peewee.log</li>
<li>stat.log</li>
<li>fate_flow_audit.log </li>
<li>fate_flow_detect.log</li>
<li>fate_flow_stat.log</li>
<li>fate_flow_schedule.log </li>
</ul>
<h3 id="DEBUG、INFO、ERROR、WARNING"><a href="#DEBUG、INFO、ERROR、WARNING" class="headerlink" title="DEBUG、INFO、ERROR、WARNING"></a>DEBUG、INFO、ERROR、WARNING</h3><p>正常四个级别的日志输出</p>
<h3 id="peewee-log"><a href="#peewee-log" class="headerlink" title="peewee.log"></a>peewee.log</h3><p>fate 操作数据是使用peewee 这一ORM 实现的，peewee.log 记录了相关操作的日志。关于peewee 可以参考<a href="http://docs.peewee-orm.com/en/latest/index.html">官方文档</a></p>
<h3 id="stat-log"><a href="#stat-log" class="headerlink" title="stat.log"></a>stat.log</h3><p>记录了各param 的check ，感觉可有可无，不知道单独放一个日志的设计意图。</p>
<p>样例<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG] [2021-07-26 15:26:37,778] [1150092:140485761271616] - intersect_param.py[line:61]: Finish encode parameter check!</span><br><span class="line">[DEBUG] [2021-07-26 15:26:37,778] [1150092:140485761271616] - intersect_param.py[line:184]: Finish intersect parameter check!</span><br><span class="line">[DEBUG] [2021-07-26 15:26:37,778] [1150092:140485761271616] - intersect_param.py[line:61]: Finish encode parameter check!</span><br><span class="line">[DEBUG] [2021-07-26 15:26:37,778] [1150092:140485761271616] - intersect_param.py[line:184]: Finish intersect parameter check!</span><br><span class="line">[DEBUG] [2021-07-26 15:26:37,780] [1150092:140485761271616] - encrypt_param.py[line:71]: Finish encrypt parameter check!</span><br><span class="line">[DEBUG] [2021-07-26 15:26:37,780] [1150092:140485761271616] - predict_param.py[line:44]: Finish predict parameter check!</span><br><span class="line">[DEBUG] [2021-07-26 15:26:37,781] [1150092:140485761271616] - encrypt_param.py[line:71]: Finish encrypt parameter check!</span><br><span class="line">[DEBUG] [2021-07-26 15:26:37,781] [1150092:140485761271616] - predict_param.py[line:44]: Finish predict parameter check!</span><br><span class="line">[DEBUG] [2021-07-26 15:26:37,782] [1150092:140485761271616] - encrypt_param.py[line:71]: Finish encrypt parameter check!</span><br><span class="line">[DEBUG] [2021-07-26 15:26:37,782] [1150092:140485761271616] - predict_param.py[line:44]: Finish predict parameter check!</span><br></pre></td></tr></table></figure></p>
<h3 id="fate-flow-audit-log"><a href="#fate-flow-audit-log" class="headerlink" title="fate_flow_audit.log"></a>fate_flow_audit.log</h3><p>记录发起的grpc 请求。函数为 audit_logger。有调用的地方在<br>python/fate_flow/utils/api_utils.py 中的<br>federated_coordination_on_grpc<br>federated_coordination_on_http<br>forward_api</p>
<p>和 python/fate_flow/utils/grpc_utils.py 中的<br>unaryCall</p>
<p>日志样例：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-05-18 08:00:26,886] [1:140215515608832] - grpc_utils.py[line:93]: rpc receive: header &#123;</span><br><span class="line">  task &#123;</span><br><span class="line">    taskId: &quot;2021051808002667189911&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  src &#123;</span><br><span class="line">    name: &quot;2021051808002667189911&quot;</span><br><span class="line">    partyId: &quot;9999&quot;</span><br><span class="line">    role: &quot;fateflow&quot;</span><br><span class="line">    callback &#123;</span><br><span class="line">      ip: &quot;10.200.96.205&quot;</span><br><span class="line">      port: 9360</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  dst &#123;</span><br><span class="line">    name: &quot;2021051808002667189911&quot;</span><br><span class="line">    partyId: &quot;10000&quot;</span><br><span class="line">    role: &quot;fateflow&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  command &#123;</span><br><span class="line">    name: &quot;fateflow&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  operator: &quot;POST&quot;</span><br><span class="line">  conf &#123;</span><br><span class="line">    overallTimeout: 30000</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">body &#123;</span><br><span class="line">  key: &quot;/v1/party/2021051808002667189911/host/10000/create&quot;</span><br><span class="line">  value: &quot;&#123;\&quot;name\&quot;: \&quot;\&quot;, \&quot;description\&quot;: \&quot;\&quot;, \&quot;tag\&quot;: \&quot;\&quot;, \&quot;is_initiator\&quot;: false, \&quot;progress\&quot;: 0, \&quot;ready_signal\&quot;: false, \&quot;cancel_signal\&quot;: false, \&quot;rerun_signal\&quot;: false, \&quot;end_scheduling_updates\&quot;: 0, \&quot;cores\&quot;: 0, \&quot;memory\&quot;: 0, \&quot;remaining_cores\&quot;: 0, \&quot;remaining_memory\&quot;: 0, \&quot;resource_in_use\&quot;: false, \&quot;job_id\&quot;: \&quot;2021051808002667189911\&quot;, \&quot;dsl\&quot;: &#123;\&quot;components\&quot;: &#123;\&quot;dataio_0\&quot;: &#123;\&quot;module\&quot;: \&quot;DataIO\&quot;, \&quot;input\&quot;: &#123;\&quot;model\&quot;: [\&quot;pipeline.dataio_0.dataio\&quot;], \&quot;data\&quot;: &#123;\&quot;data\&quot;: [\&quot;args.eval_data\&quot;]&#125;&#125;, \&quot;output\&quot;: &#123;\&quot;data\&quot;: [\&quot;train\&quot;]&#125;, \&quot;CodePath\&quot;: \&quot;federatedml/util/data_io.py/DataIO\&quot;&#125;, \&quot;intersection_0\&quot;: &#123;\&quot;module\&quot;: \&quot;Intersection\&quot;, \&quot;output\&quot;: &#123;\&quot;data\&quot;: [\&quot;train\&quot;]&#125;, \&quot;input\&quot;: &#123;\&quot;data\&quot;: &#123;\&quot;data\&quot;: [\&quot;dataio_0.train\&quot;]&#125;&#125;, \&quot;CodePath\&quot;: \&quot;federatedml/statistic/intersect/intersect_model.py/IntersectGuest\&quot;&#125;, \&quot;secureboost_0\&quot;: &#123;\&quot;module\&quot;: \&quot;HeteroSecureBoost\&quot;, \&quot;input\&quot;: &#123;\&quot;model\&quot;: [\&quot;pipeline.secureboost_0.train\&quot;], \&quot;data\&quot;: &#123;\&quot;test_data\&quot;: [\&quot;intersection_0.train\&quot;]&#125;&#125;, \&quot;output\&quot;: &#123;\&quot;data\&quot;: [\&quot;train\&quot;]&#125;, \&quot;CodePath\&quot;: \&quot;federatedml/ensemble/boosting/hetero/hetero_secureboost_guest.py/HeteroSecureBoostingTreeGuest\&quot;&#125;&#125;&#125;, \&quot;train_runtime_conf\&quot;: &#123;\&quot;initiator\&quot;: &#123;\&quot;role\&quot;: \&quot;guest\&quot;, \&quot;party_id\&quot;: 9999&#125;, \&quot;job_parameters\&quot;: &#123;\&quot;job_type\&quot;: \&quot;train\&quot;, \&quot;work_mode\&quot;: 1, \&quot;backend\&quot;: 0, \&quot;computing_engine\&quot;: \&quot;EGGROLL\&quot;, \&quot;federation_engine\&quot;: \&quot;EGGROLL\&quot;, \&quot;storage_engine\&quot;: \&quot;EGGROLL\&quot;, \&quot;engines_address\&quot;: &#123;&#125;, \&quot;federated_mode\&quot;: \&quot;MULTIPLE\&quot;, \&quot;task_cores\&quot;: 2, \&quot;task_parallelism\&quot;: 1, \&quot;computing_partitions\&quot;: 2, \&quot;federated_status_collect_type\&quot;: \&quot;PULL\&quot;, \&quot;model_id\&quot;: \&quot;guest-9999#host-10000#model\&quot;, \&quot;model_version\&quot;: \&quot;2021051807524507002410\&quot;, \&quot;eggroll_run\&quot;: &#123;&#125;, \&quot;spark_run\&quot;: &#123;&#125;, \&quot;rabbitmq_run\&quot;: &#123;&#125;, \&quot;adaptation_parameters\&quot;: &#123;\&quot;task_nodes\&quot;: 1, \&quot;task_cores_per_node\&quot;: 2, \&quot;task_memory_per_node\&quot;: 0, \&quot;request_task_cores\&quot;: 2, \&quot;if_initiator_baseline\&quot;: true&#125;&#125;, \&quot;role\&quot;: &#123;\&quot;guest\&quot;: [9999], \&quot;host\&quot;: [10000]&#125;, \&quot;role_parameters\&quot;: &#123;\&quot;guest\&quot;: &#123;\&quot;args\&quot;: &#123;\&quot;data\&quot;: &#123;\&quot;train_data\&quot;: [&#123;\&quot;name\&quot;: \&quot;breast_hetero_guest\&quot;, \&quot;namespace\&quot;: \&quot;experiment\&quot;&#125;], \&quot;eval_data\&quot;: [&#123;\&quot;name\&quot;: \&quot;breast_hetero_guest\&quot;, \&quot;namespace\&quot;: \&quot;experiment\&quot;&#125;]&#125;&#125;, \&quot;dataio_0\&quot;: &#123;\&quot;with_label\&quot;: [true], \&quot;label_name\&quot;: [\&quot;y\&quot;], \&quot;label_type\&quot;: [\&quot;int\&quot;], \&quot;output_format\&quot;: [\&quot;dense\&quot;]&#125;&#125;, \&quot;host\&quot;: &#123;\&quot;args\&quot;: &#123;\&quot;data\&quot;: &#123;\&quot;train_data\&quot;: [&#123;\&quot;name\&quot;: \&quot;breast_hetero_host\&quot;, \&quot;namespace\&quot;: \&quot;experiment\&quot;&#125;], \&quot;eval_data\&quot;: [&#123;\&quot;name\&quot;: \&quot;breast_hetero_host\&quot;, \&quot;namespace\&quot;: \&quot;experiment\&quot;&#125;]&#125;&#125;, \&quot;dataio_0\&quot;: &#123;\&quot;with_label\&quot;: [false], \&quot;output_format\&quot;: [\&quot;dense\&quot;]&#125;&#125;&#125;, \&quot;algorithm_parameters\&quot;: &#123;\&quot;secureboost_0\&quot;: &#123;\&quot;task_type\&quot;: \&quot;classification\&quot;, \&quot;learning_rate\&quot;: 0.1, \&quot;num_trees\&quot;: 5, \&quot;subsample_feature_rate\&quot;: 1, \&quot;n_iter_no_change\&quot;: false, \&quot;tol\&quot;: 0.0001, \&quot;bin_num\&quot;: 50, \&quot;objective_param\&quot;: &#123;\&quot;objective\&quot;: \&quot;cross_entropy\&quot;&#125;, \&quot;encrypt_param\&quot;: &#123;\&quot;method\&quot;: \&quot;paillier\&quot;&#125;, \&quot;predict_param\&quot;: &#123;\&quot;threshold\&quot;: 0.5&#125;, \&quot;cv_param\&quot;: &#123;\&quot;n_splits\&quot;: 5, \&quot;shuffle\&quot;: false, \&quot;random_seed\&quot;: 103, \&quot;need_cv\&quot;: false&#125;, \&quot;validation_freqs\&quot;: 1&#125;, \&quot;evaluation_0\&quot;: &#123;\&quot;eval_type\&quot;: \&quot;binary\&quot;&#125;&#125;, \&quot;config\&quot;: \&quot;/data/projects/fate/examples/min_test_task/test/submit_job_guest.config_1621324363_9498\&quot;, \&quot;dsl\&quot;: \&quot;/data/projects/fate/examples/min_test_task/config/test_secureboost_train_dsl.json\&quot;, \&quot;function\&quot;: \&quot;submit_job\&quot;&#125;, \&quot;roles\&quot;: &#123;\&quot;guest\&quot;: [9999], \&quot;host\&quot;: [10000], \&quot;arbiter\&quot;: []&#125;, \&quot;work_mode\&quot;: 1, \&quot;initiator_role\&quot;: \&quot;guest\&quot;, \&quot;initiator_party_id\&quot;: 9999, \&quot;role\&quot;: \&quot;guest\&quot;, \&quot;party_id\&quot;: 9999, \&quot;runtime_conf\&quot;: &#123;\&quot;initiator\&quot;: &#123;\&quot;role\&quot;: \&quot;guest\&quot;, \&quot;party_id\&quot;: 9999&#125;, \&quot;job_parameters\&quot;: &#123;\&quot;job_type\&quot;: \&quot;predict\&quot;, \&quot;work_mode\&quot;: 1, \&quot;backend\&quot;: 0, \&quot;computing_engine\&quot;: \&quot;EGGROLL\&quot;, \&quot;federation_engine\&quot;: \&quot;EGGROLL\&quot;, \&quot;storage_engine\&quot;: \&quot;EGGROLL\&quot;, \&quot;engines_address\&quot;: &#123;&#125;, \&quot;federated_mode\&quot;: \&quot;MULTIPLE\&quot;, \&quot;task_parallelism\&quot;: 1, \&quot;computing_partitions\&quot;: 4, \&quot;federated_status_collect_type\&quot;: \&quot;PULL\&quot;, \&quot;model_id\&quot;: \&quot;guest-9999#host-10000#model\&quot;, \&quot;model_version\&quot;: \&quot;2021051807524507002410\&quot;, \&quot;eggroll_run\&quot;: &#123;&#125;, \&quot;spark_run\&quot;: &#123;&#125;, \&quot;rabbitmq_run\&quot;: &#123;&#125;, \&quot;adaptation_parameters\&quot;: &#123;\&quot;task_nodes\&quot;: 1, \&quot;task_cores_per_node\&quot;: 4, \&quot;task_memory_per_node\&quot;: 0, \&quot;request_task_cores\&quot;: 4, \&quot;if_initiator_baseline\&quot;: true&#125;&#125;, \&quot;role\&quot;: &#123;\&quot;guest\&quot;: [9999], \&quot;host\&quot;: [10000], \&quot;arbiter\&quot;: []&#125;, \&quot;role_parameters\&quot;: &#123;\&quot;guest\&quot;: &#123;\&quot;args\&quot;: &#123;\&quot;data\&quot;: &#123;\&quot;eval_data\&quot;: [&#123;\&quot;name\&quot;: \&quot;breast_hetero_guest\&quot;, \&quot;namespace\&quot;: \&quot;experiment\&quot;&#125;]&#125;&#125;&#125;, \&quot;host\&quot;: &#123;\&quot;args\&quot;: &#123;\&quot;data\&quot;: &#123;\&quot;eval_data\&quot;: [&#123;\&quot;name\&quot;: \&quot;breast_hetero_host\&quot;, \&quot;namespace\&quot;: \&quot;experiment\&quot;&#125;]&#125;&#125;&#125;&#125;, \&quot;config\&quot;: \&quot;/data/projects/fate/examples/min_test_task/test/submit_job_guest.config_1621324825_2041\&quot;, \&quot;function\&quot;: \&quot;submit_job\&quot;&#125;, \&quot;runtime_conf_on_party\&quot;: &#123;\&quot;initiator\&quot;: &#123;\&quot;role\&quot;: \&quot;guest\&quot;, \&quot;party_id\&quot;: 9999&#125;, \&quot;job_parameters\&quot;: &#123;\&quot;job_type\&quot;: \&quot;predict\&quot;, \&quot;work_mode\&quot;: 1, \&quot;backend\&quot;: 0, \&quot;computing_engine\&quot;: \&quot;EGGROLL\&quot;, \&quot;federation_engine\&quot;: \&quot;EGGROLL\&quot;, \&quot;storage_engine\&quot;: \&quot;EGGROLL\&quot;, \&quot;engines_address\&quot;: &#123;&#125;, \&quot;federated_mode\&quot;: \&quot;MULTIPLE\&quot;, \&quot;task_parallelism\&quot;: 1, \&quot;computing_partitions\&quot;: 4, \&quot;federated_status_collect_type\&quot;: \&quot;PULL\&quot;, \&quot;model_id\&quot;: \&quot;guest-9999#host-10000#model\&quot;, \&quot;model_version\&quot;: \&quot;2021051807524507002410\&quot;, \&quot;eggroll_run\&quot;: &#123;&#125;, \&quot;spark_run\&quot;: &#123;&#125;, \&quot;rabbitmq_run\&quot;: &#123;&#125;, \&quot;adaptation_parameters\&quot;: &#123;\&quot;task_nodes\&quot;: 1, \&quot;task_cores_per_node\&quot;: 4, \&quot;task_memory_per_node\&quot;: 0, \&quot;request_task_cores\&quot;: 4, \&quot;if_initiator_baseline\&quot;: true&#125;&#125;, \&quot;role\&quot;: &#123;\&quot;guest\&quot;: [9999], \&quot;host\&quot;: [10000], \&quot;arbiter\&quot;: []&#125;, \&quot;role_parameters\&quot;: &#123;\&quot;guest\&quot;: &#123;\&quot;args\&quot;: &#123;\&quot;data\&quot;: &#123;\&quot;eval_data\&quot;: [&#123;\&quot;name\&quot;: \&quot;breast_hetero_guest\&quot;, \&quot;namespace\&quot;: \&quot;experiment\&quot;&#125;]&#125;&#125;&#125;, \&quot;host\&quot;: &#123;\&quot;args\&quot;: &#123;\&quot;data\&quot;: &#123;\&quot;eval_data\&quot;: [&#123;\&quot;name\&quot;: \&quot;breast_hetero_host\&quot;, \&quot;namespace\&quot;: \&quot;experiment\&quot;&#125;]&#125;&#125;&#125;&#125;, \&quot;config\&quot;: \&quot;/data/projects/fate/examples/min_test_task/test/submit_job_guest.config_1621324825_2041\&quot;, \&quot;function\&quot;: \&quot;submit_job\&quot;&#125;, \&quot;src_role\&quot;: \&quot;guest\&quot;, \&quot;src_party_id\&quot;: 9999&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="fate-flow-detect-log"><a href="#fate-flow-detect-log" class="headerlink" title="fate_flow_detect.log"></a>fate_flow_detect.log</h3><p>detector.py 产生的日志，涉及如下函数</p>
<ul>
<li>detect_running_task：探测正在运行的task</li>
<li>detect_running_job：探测正在运行的job</li>
<li>detect_resource_record：探测资源使用记录</li>
<li>detect_expired_session：探测是否有过期的session，有的话，调用request_stop_jobs进行stop<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 10:01:34,230] [1:139736070596352] - detector.py[line:38]: start to detect running task..</span><br><span class="line">[INFO] [2021-07-26 10:01:34,241] [1:139736070596352] - detector.py[line:70]: finish detect 1 running task</span><br><span class="line">[INFO] [2021-07-26 10:01:34,241] [1:139736070596352] - detector.py[line:74]: start detect running job</span><br><span class="line">[INFO] [2021-07-26 10:01:34,251] [1:139736070596352] - detector.py[line:88]: finish detect running job</span><br><span class="line">[INFO] [2021-07-26 10:01:34,251] [1:139736070596352] - detector.py[line:93]: start detect resource recycle</span><br><span class="line">[INFO] [2021-07-26 10:01:34,255] [1:139736070596352] - detector.py[line:116]: finish detect resource recycle</span><br><span class="line">[INFO] [2021-07-26 10:01:34,255] [1:139736070596352] - detector.py[line:120]: start detect expired session</span><br><span class="line">[INFO] [2021-07-26 10:01:39,260] [1:139736070596352] - detector.py[line:38]: start to detect running task..</span><br><span class="line">[INFO] [2021-07-26 10:01:39,270] [1:139736070596352] - detector.py[line:70]: finish detect 1 running task</span><br><span class="line">[INFO] [2021-07-26 10:01:39,270] [1:139736070596352] - detector.py[line:74]: start detect running job</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="fate-flow-scheduler-log"><a href="#fate-flow-scheduler-log" class="headerlink" title="fate_flow_scheduler.log"></a>fate_flow_scheduler.log</h3><p>这里和${jobid} 目录下的fate_flow_scheduler.log 记录具体job的调度细节不同，只记录最外层的job级别的调度。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-26 10:02:14,169] [1:139736062203648] - dag_scheduler.py[line:152]: schedule running job 202107260958386097411239</span><br><span class="line">[INFO] [2021-07-26 10:02:55,598] [1:139736062203648] - dag_scheduler.py[line:152]: schedule running job 202107260959086853751240</span><br><span class="line">[INFO] [2021-07-26 10:03:46,124] [1:139736062203648] - dag_scheduler.py[line:152]: schedule running job 202107261000016603571241</span><br><span class="line">[INFO] [2021-07-26 10:04:37,635] [1:139736062203648] - dag_scheduler.py[line:158]: schedule running jobs finished</span><br><span class="line">[INFO] [2021-07-26 10:04:37,635] [1:139736062203648] - dag_scheduler.py[line:161]: start schedule ready jobs</span><br><span class="line">[INFO] [2021-07-26 10:04:37,645] [1:139736062203648] - dag_scheduler.py[line:163]: have 0 ready jobs</span><br><span class="line">[INFO] [2021-07-26 10:04:37,645] [1:139736062203648] - dag_scheduler.py[line:171]: schedule ready jobs finished</span><br><span class="line">[INFO] [2021-07-26 10:04:37,645] [1:139736062203648] - dag_scheduler.py[line:173]: start schedule rerun jobs</span><br><span class="line">[INFO] [2021-07-26 10:04:37,652] [1:139736062203648] - dag_scheduler.py[line:175]: have 0 rerun jobs</span><br><span class="line">[INFO] [2021-07-26 10:04:37,652] [1:139736062203648] - dag_scheduler.py[line:183]: schedule rerun jobs finished</span><br><span class="line">[INFO] [2021-07-26 10:04:37,652] [1:139736062203648] - dag_scheduler.py[line:185]: start schedule end status jobs to update status</span><br><span class="line">[INFO] [2021-07-26 10:04:37,673] [1:139736062203648] - dag_scheduler.py[line:187]: have 5 end status jobs</span><br><span class="line">[INFO] [2021-07-26 10:04:37,674] [1:139736062203648] - dag_scheduler.py[line:189]: schedule end status job 202107260956208255521237</span><br><span class="line">[INFO] [2021-07-26 10:04:37,829] [1:139736062203648] - dag_scheduler.py[line:189]: schedule end status job 202107260956590660001238</span><br><span class="line">[INFO] [2021-07-26 10:04:37,956] [1:139736062203648] - dag_scheduler.py[line:189]: schedule end status job 202107260958386097411239</span><br><span class="line">[INFO] [2021-07-26 10:04:38,088] [1:139736062203648] - dag_scheduler.py[line:189]: schedule end status job 202107260959086853751240</span><br><span class="line">[INFO] [2021-07-26 10:04:38,225] [1:139736062203648] - dag_scheduler.py[line:189]: schedule end status job 202107261000016603571241</span><br></pre></td></tr></table></figure></p>
<h3 id="fate-flow-stat-log"><a href="#fate-flow-stat-log" class="headerlink" title="fate_flow_stat.log"></a>fate_flow_stat.log</h3><p>记录各个进程的状态<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[INFO] [2021-07-25 17:20:50,581] [1:139738990319424] - job_utils.py[line:345]: child process 676448 exit with exitcode 0</span><br><span class="line">[INFO] [2021-07-25 17:20:50,582] [1:139738990319424] - job_utils.py[line:342]: no child process was immediately available</span><br><span class="line">[INFO] [2021-07-25 17:20:56,256] [1:139738990319424] - job_utils.py[line:345]: child process 676533 exit with exitcode 0</span><br><span class="line">[INFO] [2021-07-25 17:20:56,256] [1:139738990319424] - job_utils.py[line:342]: no child process was immediately available</span><br><span class="line">[INFO] [2021-07-25 17:21:02,272] [1:139738990319424] - job_utils.py[line:345]: child process 676692 exit with exitcode 0</span><br><span class="line">[INFO] [2021-07-25 17:21:02,273] [1:139738990319424] - job_utils.py[line:342]: no child process was immediately available</span><br><span class="line">[INFO] [2021-07-25 17:21:09,043] [1:139738990319424] - job_utils.py[line:345]: child process 676378 exit with exitcode 0</span><br><span class="line">[INFO] [2021-07-25 17:21:09,043] [1:139738990319424] - job_utils.py[line:342]: no child process was immediately available</span><br><span class="line">[INFO] [2021-07-25 17:21:15,706] [1:139738990319424] - job_utils.py[line:345]: child process 676612 exit with exitcode 0</span><br><span class="line">[WARNING] [2021-07-25 17:21:15,707] [1:139738990319424] - job_utils.py[line:348]: current process has no existing unwaited-for child processes.</span><br></pre></td></tr></table></figure></p>
<h2 id="jobid-目录下日志"><a href="#jobid-目录下日志" class="headerlink" title="${jobid} 目录下日志"></a>${jobid} 目录下日志</h2><p>${jobid} 目录下的日志与 fate_flow 的日志不完全一致，主要分成如下几个部分</p>
<ul>
<li>fate_flow_audit.log  </li>
<li>fate_flow_schedule.log  </li>
<li>fate_flow_sql.log</li>
<li>${role}/${party_id}/</li>
</ul>
<h3 id="fate-flow-audit-log-1"><a href="#fate-flow-audit-log-1" class="headerlink" title="fate_flow_audit.log"></a>fate_flow_audit.log</h3><p>同fate_flow 目录下的fate_flow_audit.log，fate_flow 下的fate_flow_audit.log 是各个${jobid} 中fate_flow_audit.log 的集合</p>
<h3 id="fate-flow-schedule-log"><a href="#fate-flow-schedule-log" class="headerlink" title="fate_flow_schedule.log"></a>fate_flow_schedule.log</h3><p>记录fate调度的主要日志，函数为schedule_logger。不同于fate_flow 下的fate_flow_schedule.log，只记录dag_scheduler.py 的日志，调度过程中，记录了众多调用模块的日志，后文详细说明。</p>
<h3 id="fate-flow-sql-log"><a href="#fate-flow-sql-log" class="headerlink" title="fate_flow_sql.log"></a>fate_flow_sql.log</h3><p>记录操作DB的sql 日志。函数为sql_logger，FATE中操作DB的日志，调用在 job_saver.py：将job的各项metrics 写DB 和 save_model_info.py 将模型的相关信息写DB</p>
<p>python/fate_flow/operation/job_saver.py<br>create_job_family_entity 函数，创建job时，将job初始化信息写DB<br>execute_update 函数：更新job相关信息</p>
<p>FATE-1.5.1/python/fate_flow/utils/model_utils.py 中<br>save_model_info 函数，将模型相关信息写DB</p>
<h3 id="role-party-id"><a href="#role-party-id" class="headerlink" title="${role}/${party_id}/"></a>${role}/${party_id}/</h3><p>记录了各个role &amp; party_id 下具体task执行的日志<br>具体目录结构为</p>
<ul>
<li>DEBUG.log</li>
<li>INFO.log</li>
<li>ERROR.log</li>
<li>WARNING.log</li>
<li>${taskName}/DEBUG.log</li>
<li>${taskName}/INFO.log</li>
<li>${taskName}/ERROR.log</li>
<li>${taskName}/WARNING.log</li>
<li>${taskName}/peewee.log</li>
<li>${taskName}/fate_flow_schedule.log</li>
<li>${taskName}/stat.log</li>
<li>${taskName}/std.log</li>
</ul>
<p>其中 DEBUG、INFO、WARNING、ERROR 是各个${taskName} 下对应日志的合集。</p>
<p>${taskName}/fate_flow_schedule.log 记录了task_executor.py 执行该task的日志<br>${taskName}/peewee.log 是该task 通过peewee 操作DB的记录<br>${taskName}/stat.log 记录了该task的相关统计值<br>${taskName}/std.log std 输出</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://wdxtub.com/flt/flt-c1/2021/07/02/">【联邦学习之旅】C1 FATE Flow 源码解析</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/08/20/fedai-overview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/20/fedai-overview/" class="post-title-link" itemprop="url">联邦学习哪家强，中国山东找saber</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-08-20 11:46:42 / Modified: 12:06:59" itemprop="dateCreated datePublished" datetime="2023-08-20T11:46:42+08:00">2023-08-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FATE/" itemprop="url" rel="index"><span itemprop="name">FATE</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>ERROR：本文要素过多，包含开车、粗鄙之语、魔法、表情包等。但不包含联邦学习的具体说明，相关内容，文末给出传送门，请自行参阅。</strong></p>
<h1 id="先吐槽"><a href="#先吐槽" class="headerlink" title="先吐槽"></a>先吐槽</h1><p>人呐就都不知道，自己不可以预料，一个人的职业发展啊，当然要靠自我奋斗，但是也要考虑技术的演进。我绝对不知道，我作为一个搞大数据的，怎么开始搞联邦学习了？</p>
<p><img src="/image/fate/0d5a5e318d7f8e52bbfa2f45ffa42349.jpg" alt=""></p>
<p>所以当领导给我安排任务，说“公司都决定了，你来调研联邦学习吧”。</p>
<p>我说另请高明吧，我实在也不是谦虚。我一个玩大数据的，一年正经代码写不了几行，到是sql和shell 写的飞起的咸鱼，怎么就能研究联邦学习了呢？但是，领导说“公司已经研究决定了”。后来我就装了两虚拟机。</p>
<p>一台主机名是gou，一台主机名是qi，提醒我，工作再多，也得有健康的身体去享受</p>
<p><img src="/image/fate/6be630a085ee553471e954f804ec2e78.png" alt=""></p>
<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>说到联邦学习，最近概念有点活，相关在大神遍地的知乎，随便一搜就是了。当然，我有个朋友对此很是不屑，评价到</p>
<blockquote>
<p>联邦学习反映了大数据在面对隐私时既想当xx又想立xx的复杂心情 —by 我的一个朋友</p>
</blockquote>
<p>当然，无论我朋友说啥，反正他又不发我工资，该调研FATE，还是继续调研哈。</p>
<p><img src="/image/fate/d7811ed7c9a0ec4f3e1d9b5455a7bc55.png" alt=""></p>
<p>然后本着博（不）采（务）众（正）长（业）的态度，想看看除了FATE，其他框架的情况，以及好久没写python，就想写个爬虫，练练手的，即复习了python，又能增加装逼素材</p>
<p><img src="/image/fate/143340550b2dd66479ff3a34f1769640.png" alt=""></p>
<p>于是，在github， 使用federated learning关键词搜索，爬取了star数 top30的repository，以及之前有了解的京东的9nfl和 字节跳动的Fedlearner ，一共32个项目的数据。</p>
<p>然而，像腾讯的AngelFL，这种未开源，只见文章的框架，暂时还无法统计。</p>
<p>因为时间精力有限，无法走读所有项目的源码，只能爬取git上的数据，进行一些简单的分析（吹逼），给有志于从事联邦学习的小伙伴在选择入门框架上一（带）些（到）建（坑）议（里）。</p>
<p><img src="/image/fate/c0b77fe777fbd6d6221af27f74d21581.png" alt=""></p>
<h2 id="repository的类型"><a href="#repository的类型" class="headerlink" title="repository的类型"></a>repository的类型</h2><p>我们先从repository 的类型，开始吹起，粗略分了一下类，大致为三分天下，一类是Framework Or System 即联邦学习的框架或者系统，一类是Research Collections即学习资料收集，如研究类文献、paper和最新的idea的收集整理，还有一类是配套的设施，支持，如K8s 解决方案方案 KubeFATE，分布式机器学习 eggroll 等。</p>
<p><img src="/image/fate/4ceb3991d18b35a14529065b3bbfd80f.png" alt=""></p>
<p>总的来看Framework Or System 独占7成。毕竟是个新兴的领域，Research 也不少。而相关的配套就比较少了，只有可怜的6.25%</p>
<h2 id="活跃度"><a href="#活跃度" class="headerlink" title="活跃度"></a>活跃度</h2><p>其次，从issue、commit、pr等指标来看，分别统计了各项指标的排列前三的项目，可以发现FATE 和 tensorflow federated(缩写TFF） 双雄争霸，是社区活跃度最高的两个项目。</p>
<p><img src="/image/fate/c14af37c2188b47e09f9a3b4ae2ceddf.png" alt=""></p>
<p>TFF自不必说，背靠Google这颗大树好乘凉，又有TensorFlow 强大的算法库支持。整个项目规划清晰，文档完善，除了tutorials，连design，openmined2020 都给你贴出来了。假如你之前就是个TensorFlow玩家，给我一个不用TFF 入门的理由？</p>
<p>而FATE</p>
<p><img src="/image/fate/e7fa568f70e6b63871f77d1f6d33cf17.png" alt=""></p>
<p>不好意思，放错图了，是这个</p>
<p><img src="/image/fate/98b49a10bdc993bc245288fa7ce586db.png" alt=""></p>
<p>号称工业级的开源联邦学习框架，在项目的完整性和易用性上，完全不虚TFF，各种文档一应俱全，还有热心网友编写教程，手把手教你怎么玩。项目1.5重构后，整体规划也更加清晰。同时还支持双语教学，对于英语不好的同学来说，简直就是福音。</p>
<p><img src="/image/fate/7735f07951812f4f2cf5ca97c4c830f6.png" alt=""></p>
<p>唯一美中不足的，可能是进化太快了？（看看这个release数，看看这个commit数），一些老的文档已经跟不上最新的版本了。</p>
<p><img src="/image/fate/749b372183589fd41e67e2484d62e4df.png" alt=""></p>
<p>字节跳动的 Fedlearner凭着极其简洁的文档和天马行空的代码结构，能够在开源不久就获得如此之高的star数，看来凭借推荐算法起家的字节跳动，其能力都得到了大家的认可。（访问github 双击鼠标不加star吧？）</p>
<p><img src="/image/fate/53a9e0713e1d6c24cf7e67dd92d4ab4f.png" alt=""></p>
<p>百度的PaddleFL虽然人气比不过上面几个，不过依旧默默努力。加上有源于产业实践的开源深度学习平台 飞桨的加持，愿天道酬勤吧？</p>
<p>FedML 则是一个更加学术性的项目，查了下貌似没啥大公司的加成，更加偏向于一些paper和 idea 的实践和论证，是一个不错的学习和拓宽思路的项目。</p>
<p>xaynet 第一次看到xaynetwork 这个名字，我是陌生的，后来一查，居然是一家德国的公司，作为一个 潜在的巴伐利亚拖拉机主，不禁心头狂喜（deploy 这个项目的时候，需要在机柜边上放个油纸包么？） 的确，欧洲一直以来，没什么让人亮眼的互联网公司，但随着GDPR的出台，欧洲可能也在谋求些什么。</p>
<p><img src="/image/fate/d92f7328044b4a58cb60b631e4a69187.png" alt=""></p>
<p>Train on the Edge with Federated Learning，这个巨大的title，仿佛就是Google 最初联邦学习想法的实现。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>虽然选了top30 的，但从活跃度的绝对数量上看，头部聚集效应明显，无论是commits on master/main 的数量，还是pr 和 issues 的数量，头部的几位都把后面的远远甩在了身后。</p>
<p><img src="/image/fate/be914640aedcd715d8491f68de188b9d.png" alt=""></p>
<h2 id="使用语言"><a href="#使用语言" class="headerlink" title="使用语言"></a>使用语言</h2><p><img src="/image/fate/f091be675bf0c77cd5d712c4291e294e.png" alt=""></p>
<p>再从开发的语言上来看看，python 一马当先，一骑绝尘，一夫当关，一统天下</p>
<p>有志于此的小伙伴，还是好好学python 吧。</p>
<p><img src="/image/fate/f4d146cc8d2463ee9fb74e043930dff4.png" alt=""></p>
<p>当然仔细分析一下，像FATE 依赖的分布式机器学习引擎eggroll，也涉及了scala 和java。 还有TTF依赖的TensorFlow，也是C++ 写的，也就是在引擎层面，python 还是未够班啊。</p>
<p><img src="/image/fate/9e13bdd07be8bd7dbe20f3ddb73bc0fc.png" alt=""></p>
<h2 id="公司-amp-组织参与度"><a href="#公司-amp-组织参与度" class="headerlink" title="公司&amp;组织参与度"></a>公司&amp;组织参与度</h2><p>从公司参与度上 ，微众银行、IBM、GOOGLE 位列三甲。</p>
<p><img src="/image/fate/a2c71f164052ea76a79d0bbf81758d0e.png" alt=""></p>
<p>当然，FATE也并非微众一家之功，从现有的信息来看，VMare也在FATE的实现中，出了不少力 。</p>
<p>GOOGLE作为科技巨头，上榜也一点也不意外。</p>
<p>到是看到了蓝色巨人IBM，蓝色巨人的底蕴还是深厚的<br>[图片上传失败…(image-b0cc3b-1607480144280)]</p>
<p>不禁想起了我的又一个朋友，身为前IBM员工，一直感叹：</p>
<blockquote>
<p>老东家在云计算、大数据方向，IBM都是起了个大早，赶了个晚集 ！</p>
</blockquote>
<p>如果联邦学习会成为下个趋势的话，期望看到蓝色巨人有所作为吧。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>以上，就是基于一个不靠谱的爬虫获取的不靠谱的分析 。</p>
<p>如果非要有什么结论，或者在选型上有所建议的话，个人的建议是 双持FATE和TTF。</p>
<p><img src="/image/fate/3b952bd5eef7f17ff3db63d10e738e71.png" alt=""></p>
<p>TTF背靠大树，以及有着TensorFlow 这么丰富的宝库，必定后劲绵长。而FATE，尤其完善的配套（可以去看下FATE下的repo），活跃的社区，中文的支持。学习起来，必然事半功倍。</p>
<p>当然，除了以上两个，本着open source 的精神，还是要博采众长。尤其是一些走在前沿，带着极强research性质的框架，可能功能不是那么完善和强大，但是很多思路确可以借鉴。作为一个技术人员，切不可固步自封，而应该更加的开放，不是么？</p>
<p><img src="/image/fate/d0c304da9af60fb9424373c4fa125f77.png" alt=""></p>
<h1 id="假装必须有的FAQ"><a href="#假装必须有的FAQ" class="headerlink" title="假装必须有的FAQ"></a>假装必须有的FAQ</h1><h2 id="Q1：-为什么开头是ERROR-？"><a href="#Q1：-为什么开头是ERROR-？" class="headerlink" title="Q1： 为什么开头是ERROR ？"></a>Q1： 为什么开头是ERROR ？</h2><p>A: WARNNING你会看？</p>
<h2 id="Q2-为什么是山东"><a href="#Q2-为什么是山东" class="headerlink" title="Q2: 为什么是山东?"></a>Q2: 为什么是山东?</h2><p><img src="/image/fate/444088ba625e3d41b24131aa5ca3ff51.png" alt=""></p>
<p>A:即便诸葛村夫的广告你没看过， 喜马拉雅山以东啊，懂？</p>
<h2 id="Q3-学好了FATE-可以补魔么？"><a href="#Q3-学好了FATE-可以补魔么？" class="headerlink" title="Q3: 学好了FATE 可以补魔么？"></a>Q3: 学好了FATE 可以补魔么？</h2><p>A:不用FATE，给你自己new 一个对象，def 一个补魔的function，配合一个while(ture) 你就可以永动补魔到OOM了</p>
<p><img src="/image/fate/9a5a82a041930e346697ace5e76185c6.png" alt=""></p>
<h2 id="Q4：为什么是潜在巴伐利亚拖拉机主，不是别的？"><a href="#Q4：为什么是潜在巴伐利亚拖拉机主，不是别的？" class="headerlink" title="Q4：为什么是潜在巴伐利亚拖拉机主，不是别的？"></a>Q4：为什么是潜在巴伐利亚拖拉机主，不是别的？</h2><p>A: 人呢，要知足，我觉得有拖拉机开就不错了，不奢求开破二手车 更不奢望压金砖 况且，拖拉机和我的气质更配</p>
<h2 id="Q5-你说的那么多朋友，真的是朋友？"><a href="#Q5-你说的那么多朋友，真的是朋友？" class="headerlink" title="Q5: 你说的那么多朋友，真的是朋友？"></a>Q5: 你说的那么多朋友，真的是朋友？</h2><p>A:</p>
<p><img src="/image/fate/a2aa239b5fb920c7a384dcaf349dcc8a.jpg" alt=""></p>
<h1 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h1><ul>
<li><a href="http://news.yesky.com/hotnews/363/714746363.shtml">9nfl</a></li>
<li><a href="https://mp.weixin.qq.com/s/MHUpJT1jr71Rt93BhPCvvg">Fedlearner</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/112983993">AngelFL</a> </li>
<li><a href="https://github.com/PaddlePaddle/PaddleFL">PaddleFL</a></li>
<li><a href="https://tensorflow.google.cn/">TensorFlow</a></li>
<li><a href="https://tensorflow.google.cn/federated">TFF</a></li>
<li><a href="https://fedml.ai/">FedML</a></li>
<li><a href="https://github.com/xaynetwork">xaynet</a></li>
<li><a href="https://gdpr-info.eu/">GDPR</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/101644082">GOOGLE 联邦学习漫画</a></li>
<li><a href="https://github.com/WeBankFinTech/eggroll">eggroll</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/postpmml4LR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/06/postpmml4LR/" class="post-title-link" itemprop="url">机器学习不只是调包--通过PMML解析线性回归和逻辑回归</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-08-06 21:45:18 / Modified: 21:47:03" itemprop="dateCreated datePublished" datetime="2018-08-06T21:45:18+08:00">2018-08-06</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/pmml/" itemprop="url" rel="index"><span itemprop="name">pmml</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><ul>
<li>线性回归介绍</li>
<li>线性回归pmml 介绍</li>
<li>线性回归模型结构</li>
<li>如何手动写一个java类表述线性回归</li>
</ul>
<p>很多时候，我们在看机器学习的算法的时候，看到的都是一些列的公式推导。那么这些公式推导出来的结果是什么？最后又是如何组织的？作为一个码农，更关心的是，这些公式最后又是如何变为代码的？<br>本系列将借助PMML这一工具，可以用来解析模型的结构，了解各种模型中都有那些元素？这些元素又是通过何种组合方式，计算公式得到最后的结果的？<br>本文针对偏工程人员，不涉及具体的模型优化求解问题，我们关注的是模型实质的结构，以及根据这些信息，如何实现跨平台的使用模型。至于模型的求解过程，前人已经总结完备，不过多赘述，在文中会给出地址，如有兴趣，可以自行查阅推导。</p>
<h1 id="先从简单的线性回归开始"><a href="#先从简单的线性回归开始" class="headerlink" title="先从简单的线性回归开始"></a>先从简单的线性回归开始</h1><h2 id="什么是线性回归"><a href="#什么是线性回归" class="headerlink" title="什么是线性回归"></a>什么是线性回归</h2><p>定义：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在统计学中，线性回归(Linear Regression)是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归,大于一个自变量情况的叫做多元回归。</span><br></pre></td></tr></table></figure><br>线性回归是数据挖掘中的基础算法之一，从某种意义上来说，在学习函数的时候已经开始接触线性回归了，只不过那时候并没有涉及到误差项。线性回归的思想其实就是解一组方程，得到回归函数，不过在出现误差项之后，方程的解法就存在了改变，一般使用最小二乘法进行计算。</p>
<h3 id="解决问题流程"><a href="#解决问题流程" class="headerlink" title="解决问题流程"></a>解决问题流程</h3><p>Step1. 选择一个模型函数h<br>Step2. 为h找到适应数据的最优解，即找出最优解下的h的参数。</p>
<h3 id="函数模型"><a href="#函数模型" class="headerlink" title="函数模型"></a>函数模型</h3><p><img src="https://images0.cnblogs.com/blog2015/633472/201503/262037556613399.jpg" alt="线性回归函数模型"><br>其中h()是一个线性函数，所有的自变量构成一个一维向量X，所有参数构成一个一维向量W，就可以将第一行的公式改写为第二行的形式。</p>
<p>假设存在训练数据集<br><img src="https://images0.cnblogs.com/blog2015/633472/201503/262041198028564.jpg" alt=""><br>为了方便，可以改写为矩阵的形式<br><img src="https://images0.cnblogs.com/blog2015/633472/201503/262042295678545.jpg" alt=""></p>
<p>其中x可以看成特征，theater看成是权重。我们的目标就是找出所有的权重，进而出现新的x值时，可以对函数的输出进行估计。那我们如何求得使函数输出最接近样本的值呢？函数输出最接近样本值就意味着二者之差尽可能的小。我们假设输入的特征为，对应的样本值为，我们用模型估计出的值为，估计值与真实值之间的误差表示为<br>成为损失函数，损失函数的自变量为，所以我们需要找到最小时的取值。</p>
<p>在机器学习中我们采用梯度下降算法求解该方程，</p>
<p>一般的求解方法有梯度下降法，牛顿法，共轭梯度法，启发式优化方法等，在这篇<a href="http://www.cnblogs.com/maybe2030/p/4751804.html">博文</a>中介绍的比较详细。再次不多赘述。</p>
<p>OK,通过求解损失函数最小化，我们会得到一组参数，这就是线性回归的解，根据这个解，就有了我们的模型。</p>
<h2 id="操作实例"><a href="#操作实例" class="headerlink" title="操作实例"></a>操作实例</h2><h3 id="sklearn-实现线性回归"><a href="#sklearn-实现线性回归" class="headerlink" title="sklearn 实现线性回归"></a>sklearn 实现线性回归</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn2pmml import PMMLPipeline</span><br><span class="line">from sklearn2pmml import sklearn2pmml</span><br><span class="line">from sklearn import linear_model</span><br><span class="line">clf = linear_model.LinearRegression()</span><br><span class="line">X = [[0,0],[1,1],[2,2]]</span><br><span class="line">y = [0,1,2]</span><br><span class="line">pipeline = PMMLPipeline([(&quot;classifier&quot;, clf)])</span><br><span class="line">pipeline.fit(X,y)</span><br></pre></td></tr></table></figure>
<p>以上是希望拟合y=0.5 <em> x1 + 0.5 </em> x2。<br>测试下<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipeline.predict([[1.0,2.0]])</span><br></pre></td></tr></table></figure><br>结果为：1.5 符合预期</p>
<p>将其导出为pmml<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn2pmml(pipeline,&quot;linearregression.pmml&quot;,with_repr = True)  </span><br></pre></td></tr></table></figure></p>
<h3 id="线性回归的PMML及结构"><a href="#线性回归的PMML及结构" class="headerlink" title="线性回归的PMML及结构"></a>线性回归的PMML及结构</h3><p>上一节中的模型，导出PMML文件的主要部分如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;DataDictionary&gt;</span><br><span class="line">	&lt;DataField name=&quot;y&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">	&lt;DataField name=&quot;x1&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">	&lt;DataField name=&quot;x2&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">&lt;/DataDictionary&gt;</span><br><span class="line">&lt;RegressionModel functionName=&quot;regression&quot;&gt;</span><br><span class="line">	&lt;MiningSchema&gt;</span><br><span class="line">		&lt;MiningField name=&quot;y&quot; usageType=&quot;target&quot;/&gt;</span><br><span class="line">		&lt;MiningField name=&quot;x1&quot;/&gt;</span><br><span class="line">		&lt;MiningField name=&quot;x2&quot;/&gt;</span><br><span class="line">	&lt;/MiningSchema&gt;</span><br><span class="line">	&lt;RegressionTable intercept=&quot;2.220446049250313E-16&quot;&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x1&quot; coefficient=&quot;0.4999999999999999&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x2&quot; coefficient=&quot;0.49999999999999983&quot;/&gt;</span><br><span class="line">	&lt;/RegressionTable&gt;</span><br><span class="line">&lt;/RegressionModel&gt;</span><br></pre></td></tr></table></figure><br>模型一共两个输入 x1 x2,一个目标输出y<br>x1，x2 对应的参数分别为 0.4999999999999999 和 0.49999999999999983 （注意，这里不是0.5，是因为拟合的误差原因）整个的截距是2.220446049250313E-16</p>
<p>只要有了这几个参数，你就有了训练好的模型。针对任意的输入的x1，x2，你都能直接输入一个拟合好的y，掉包 不存在的。</p>
<h3 id="用Scala实现线性回归的预测"><a href="#用Scala实现线性回归的预测" class="headerlink" title="用Scala实现线性回归的预测"></a>用Scala实现线性回归的预测</h3><p>这里，参考了Spark MLlib中的源码，简单写了几个类，主要用于说明线性回归的结构，以及预测的逻辑。没有涉及到模型的训练。<br>从上一节中，可以看出线性回归模型中，其实就两个参数，1个权重向量，1个截距。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class LinerRegressionModel(</span><br><span class="line">   val weights: Array[Double],</span><br><span class="line">   val intercept: Double</span><br><span class="line">   ) &#123;</span><br><span class="line"></span><br><span class="line">  def predict(testData:Array[Double]): Double =&#123;</span><br><span class="line">    predictPoint(testData,weights,intercept)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def predictPoint(</span><br><span class="line">    dataMatrix: Array[Double],</span><br><span class="line">    weightMatrix: Array[Double],</span><br><span class="line">    intercept: Double): Double = &#123;</span><br><span class="line">    DenseVector(dataMatrix).dot(DenseVector(weightMatrix)) + intercept</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义线性回归模型，预测结果是输入向量和权重向量点积加上截距。<br>权重向量就是上边每个入参对应的参数。<br>测试类如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def testLinerRegression(): Unit =&#123;</span><br><span class="line">  val weight = Array(0.4999999999999999, 0.49999999999999983)</span><br><span class="line">  val intercept = 2.220446049250313E-16</span><br><span class="line">  val model = new LinerRegressionModel(weight,intercept)</span><br><span class="line">  val x = Array(1.0, 2.0)</span><br><span class="line">  val y = model.predict(x)</span><br><span class="line">  println(f&quot;The Result Of Model is $&#123;y&#125;&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>预测(1.0, 2.0)结果为：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The Result Of Model is 1.4999999999999998</span><br></pre></td></tr></table></figure><br>四舍五入和python结果一致。</p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>根据上文的叙述，线性回归的模型是求出输出特征向量Y和输入样本矩阵X之间的线性关系系数theater,使其满足Y=theater X，如果的Y是连续的，所以是回归模型。如果我们想要Y是离散的话，怎么办呢？一个可以想到的办法是，我们对于这个Y再做一次函数转换，变为g(Y)。如果我们令g(Y)的值在某个实数区间的时候是类别A，在另一个实数区间的时候是类别B，就可以得到一个分类模型。<br>在逻辑回归中，这个函数就是sigmoid函数<br><img src="https://gss3.bdstatic.com/-Po3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D99/sign=a46bd6f1dd33c895a27e9472d01340df/0df3d7ca7bcb0a4659502a5f6f63f6246b60af62.jpg" alt=""></p>
<p>下图展示了将分布函数变形的过程。<br><img src="https://img-blog.csdn.net/20171005175521991?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3lteTAwMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>具体的求解过程，可以参见这篇文章的叙述，本文不做赘述<a href="http://www.aboutyun.com/thread-10650-1-1.html">http://www.aboutyun.com/thread-10650-1-1.html</a></p>
<h2 id="二元逻辑回归"><a href="#二元逻辑回归" class="headerlink" title="二元逻辑回归"></a>二元逻辑回归</h2><p>如果结果的类别只有两种，那么就是一个二元分类模型了。<br>二元逻辑回归的预测值由下式求得<br><img src="https://img-blog.csdn.net/20141209123917993" alt=""></p>
<p>因此，逻辑回归分类器的解就是一组权值向量，和线性回归是一致的。</p>
<h3 id="二元逻辑回归python实现"><a href="#二元逻辑回归python实现" class="headerlink" title="二元逻辑回归python实现"></a>二元逻辑回归python实现</h3><p>使用自带的iris数据集进行操作，iris中包含3个分类，为了体现二分类的特性，删除了一个分类。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn2pmml <span class="keyword">import</span> PMMLPipeline</span><br><span class="line"><span class="keyword">from</span> sklearn2pmml <span class="keyword">import</span> sklearn2pmml</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"><span class="comment"># 导入数据，为了后续方便，将三类中的一类去除，使之变为二分类问题。</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">df = pd.DataFrame(iris.data)</span><br><span class="line">df[<span class="string">&quot;class&quot;</span>] = iris.target</span><br><span class="line">df.columns=[<span class="string">&#x27;V0&#x27;</span>,<span class="string">&#x27;V1&#x27;</span>,<span class="string">&#x27;V2&#x27;</span>,<span class="string">&#x27;V3&#x27;</span>,<span class="string">&#x27;class&#x27;</span>]</span><br><span class="line">df = df[df[<span class="string">&#x27;class&#x27;</span>] &lt; <span class="number">2</span>]</span><br><span class="line">df.describe()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(df[df.columns.difference([<span class="string">&#x27;class&#x27;</span>])], df[<span class="string">&#x27;class&#x27;</span>], test_size=<span class="number">0.5</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">pipeline = PMMLPipeline([(<span class="string">&quot;classifier&quot;</span>, lr)])</span><br><span class="line">pipeline.fit(X_train,y_train)</span><br></pre></td></tr></table></figure></p>
<p>然后将训练好的模型导出为PMML<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn2pmml import sklearn2pmml</span><br><span class="line">sklearn2pmml(pipeline, &quot;LRbin.pmml&quot;, with_repr = True)</span><br></pre></td></tr></table></figure></p>
<h3 id="二元逻辑回归PMML分析"><a href="#二元逻辑回归PMML分析" class="headerlink" title="二元逻辑回归PMML分析"></a>二元逻辑回归PMML分析</h3><p>上一节代码生成的PMML中的主要部分如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;DataDictionary&gt;</span><br><span class="line">		&lt;DataField name=&quot;class&quot; optype=&quot;categorical&quot; dataType=&quot;integer&quot;&gt;</span><br><span class="line">			&lt;Value value=&quot;0&quot;/&gt;</span><br><span class="line">			&lt;Value value=&quot;1&quot;/&gt;</span><br><span class="line">		&lt;/DataField&gt;</span><br><span class="line">		&lt;DataField name=&quot;V0&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">		&lt;DataField name=&quot;V1&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">		&lt;DataField name=&quot;V2&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">		&lt;DataField name=&quot;V3&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">	&lt;/DataDictionary&gt;</span><br><span class="line">	&lt;RegressionModel functionName=&quot;classification&quot; normalizationMethod=&quot;logit&quot;&gt;</span><br><span class="line">		&lt;MiningSchema&gt;</span><br><span class="line">			&lt;MiningField name=&quot;class&quot; usageType=&quot;target&quot;/&gt;</span><br><span class="line">			&lt;MiningField name=&quot;V0&quot;/&gt;</span><br><span class="line">			&lt;MiningField name=&quot;V1&quot;/&gt;</span><br><span class="line">			&lt;MiningField name=&quot;V2&quot;/&gt;</span><br><span class="line">			&lt;MiningField name=&quot;V3&quot;/&gt;</span><br><span class="line">		&lt;/MiningSchema&gt;</span><br><span class="line">		&lt;Output&gt;</span><br><span class="line">			&lt;OutputField name=&quot;probability(0)&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot; feature=&quot;probability&quot; value=&quot;0&quot;/&gt;</span><br><span class="line">			&lt;OutputField name=&quot;probability(1)&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot; feature=&quot;probability&quot; value=&quot;1&quot;/&gt;</span><br><span class="line">		&lt;/Output&gt;</span><br><span class="line">		&lt;RegressionTable intercept=&quot;-0.24391923532173168&quot; targetCategory=&quot;1&quot;&gt;</span><br><span class="line">			&lt;NumericPredictor name=&quot;V0&quot; coefficient=&quot;-0.31738779611631857&quot;/&gt;</span><br><span class="line">			&lt;NumericPredictor name=&quot;V1&quot; coefficient=&quot;-1.2346299390640323&quot;/&gt;</span><br><span class="line">			&lt;NumericPredictor name=&quot;V2&quot; coefficient=&quot;1.920449906205768&quot;/&gt;</span><br><span class="line">			&lt;NumericPredictor name=&quot;V3&quot; coefficient=&quot;0.8753093733469249&quot;/&gt;</span><br><span class="line">		&lt;/RegressionTable&gt;</span><br><span class="line">		&lt;RegressionTable intercept=&quot;0.0&quot; targetCategory=&quot;0&quot;/&gt;</span><br><span class="line">	&lt;/RegressionModel&gt;</span><br></pre></td></tr></table></figure><br>一共四个入参，V0，V1，V2，V4 都为double类型。目标输出为0，1分类。<br>模型是一个<code>classification</code>，标准化使用的是<code>logit</code>函数，也就是sigmod函数。<br>权重矩阵为(-0.31738779611631857,-1.2346299390640323,1.920449906205768,0.8753093733469249),截距为-0.24391923532173168。<br>这里需要注意，二分类只需要一个RegressionTable就能满足分类的需求，后续的多分类会涉及到多个RegressionTable。<br>这里就能发现，二分类的LR，其实就是对输入求了一次线性回归的值，然后对这个值再求其sigmod解。因而，有了权重矩阵和截距，我们就能求出逻辑回归的预测值。</p>
<h3 id="scala简单实现"><a href="#scala简单实现" class="headerlink" title="scala简单实现"></a>scala简单实现</h3><p>定义一个用于二元逻辑回归计算预测概率值的类。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class LRBinModel(</span><br><span class="line">    val weights: Array[Double],</span><br><span class="line">    val intercept: Double) &#123;</span><br><span class="line"></span><br><span class="line">  def predict(testData:Array[Double]): Double =&#123;</span><br><span class="line">    predictPoint(testData,weights,intercept)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def predictPoint(</span><br><span class="line">                    dataMatrix: Array[Double],</span><br><span class="line">                    weightMatrix: Array[Double],</span><br><span class="line">                    intercept: Double): Double = &#123;</span><br><span class="line">    val margin = DenseVector(dataMatrix).dot(DenseVector(weightMatrix)) + intercept</span><br><span class="line">    val score = 1.0 / (1.0 + math.exp(-margin))</span><br><span class="line">    score</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>取测试集的第一条记录，进行测试<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_t=X_test.head(1)</span><br><span class="line">print(X_t)</span><br><span class="line">y_t=y_test.head(1)</span><br><span class="line">print(y_t)</span><br><span class="line">pipeline.predict_proba(X_t)</span><br></pre></td></tr></table></figure><br>可以看到，第一条记录的数据为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">6.0  2.7  5.1  1.6</span><br></pre></td></tr></table></figure><br>实际类别为1<br>预测结果为<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0.00329174,  0.99670826]])</span><br></pre></td></tr></table></figure><br>意为属于类别0的概率为0.0032917，属于类别1的概率为0.99670826，两者的和正好为1。故而，求出为类别1的概率之后，用1减去该值就为类别0的概率。</p>
<p>编写一个简单的测试方法，测试改组数据<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def testLRbin(): Unit =&#123;</span><br><span class="line">  val weight = Array(-0.31738779611631857,-1.2346299390640323,1.920449906205768,0.8753093733469249)</span><br><span class="line">  val intercept = -0.24391923532173168</span><br><span class="line">  val model = new LRBinModel(weight, intercept)</span><br><span class="line">  val x = Array(6.0, 2.7, 5.1, 1.6)</span><br><span class="line">  val y = model.predict(x)</span><br><span class="line">  println(f&quot;The Probability Of Class 1 is $&#123;y&#125;&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>结果为：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The Probability Of Class 1 is 0.9967082628300301</span><br></pre></td></tr></table></figure><br>属于类别1的概率为0.9967082628300301 和python 的预测结果基本一致。<br>然后就可以根据设定的阈值，判别属于哪一类了。</p>
<h3 id="模型中的调优参数"><a href="#模型中的调优参数" class="headerlink" title="模型中的调优参数"></a>模型中的调优参数</h3><p>对于逻辑回归模型，会有一些参数需要调节，比如<code>C</code>，<code>max_iter</code>，<code>penalty</code>等，这几个值在模型求解的过程中生效，在已经求解的模型中，并无体现。</p>
<h2 id="多元逻辑回归分析"><a href="#多元逻辑回归分析" class="headerlink" title="多元逻辑回归分析"></a>多元逻辑回归分析</h2><p>多元逻辑回归，和二元类似，分别计算属于每个类别的概率，选取其中的最大值作为预测值。具体叙述参见<a href="https://blog.csdn.net/quiet_girl/article/details/70216899"></a></p>
<h3 id="多元逻辑回归python实现"><a href="#多元逻辑回归python实现" class="headerlink" title="多元逻辑回归python实现"></a>多元逻辑回归python实现</h3><p>我们还是使用iris数据集进行示例，这次不用删除类别了。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn2pmml import PMMLPipeline</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">iris = load_iris()</span><br><span class="line">clf = LogisticRegression()</span><br><span class="line">pipeline = PMMLPipeline([(&quot;classifier&quot;, clf)])</span><br><span class="line">pipeline.fit(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line"># 导出为PMML</span><br><span class="line">from sklearn2pmml import sklearn2pmml</span><br><span class="line">sklearn2pmml(pipeline, &quot;LR.pmml&quot;, with_repr = True)</span><br></pre></td></tr></table></figure></p>
<h3 id="多元逻辑回归PMML分析"><a href="#多元逻辑回归PMML分析" class="headerlink" title="多元逻辑回归PMML分析"></a>多元逻辑回归PMML分析</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;DataDictionary&gt;</span><br><span class="line">	&lt;DataField name=&quot;y&quot; optype=&quot;categorical&quot; dataType=&quot;integer&quot;&gt;</span><br><span class="line">		&lt;Value value=&quot;0&quot;/&gt;</span><br><span class="line">		&lt;Value value=&quot;1&quot;/&gt;</span><br><span class="line">		&lt;Value value=&quot;2&quot;/&gt;</span><br><span class="line">	&lt;/DataField&gt;</span><br><span class="line">	&lt;DataField name=&quot;x1&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">	&lt;DataField name=&quot;x2&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">	&lt;DataField name=&quot;x3&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">	&lt;DataField name=&quot;x4&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot;/&gt;</span><br><span class="line">&lt;/DataDictionary&gt;</span><br><span class="line">&lt;RegressionModel functionName=&quot;classification&quot; normalizationMethod=&quot;logit&quot;&gt;</span><br><span class="line">	&lt;MiningSchema&gt;</span><br><span class="line">		&lt;MiningField name=&quot;y&quot; usageType=&quot;target&quot;/&gt;</span><br><span class="line">		&lt;MiningField name=&quot;x1&quot;/&gt;</span><br><span class="line">		&lt;MiningField name=&quot;x2&quot;/&gt;</span><br><span class="line">		&lt;MiningField name=&quot;x3&quot;/&gt;</span><br><span class="line">		&lt;MiningField name=&quot;x4&quot;/&gt;</span><br><span class="line">	&lt;/MiningSchema&gt;</span><br><span class="line">	&lt;Output&gt;</span><br><span class="line">		&lt;OutputField name=&quot;probability(0)&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot; feature=&quot;probability&quot; value=&quot;0&quot;/&gt;</span><br><span class="line">		&lt;OutputField name=&quot;probability(1)&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot; feature=&quot;probability&quot; value=&quot;1&quot;/&gt;</span><br><span class="line">		&lt;OutputField name=&quot;probability(2)&quot; optype=&quot;continuous&quot; dataType=&quot;double&quot; feature=&quot;probability&quot; value=&quot;2&quot;/&gt;</span><br><span class="line">	&lt;/Output&gt;</span><br><span class="line">	&lt;RegressionTable intercept=&quot;0.26560616797551695&quot; targetCategory=&quot;0&quot;&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x1&quot; coefficient=&quot;0.4149883282957013&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x2&quot; coefficient=&quot;1.4612973885622267&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x3&quot; coefficient=&quot;-2.2621411772020728&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x4&quot; coefficient=&quot;-1.02909509924489&quot;/&gt;</span><br><span class="line">	&lt;/RegressionTable&gt;</span><br><span class="line">	&lt;RegressionTable intercept=&quot;1.0854237423889572&quot; targetCategory=&quot;1&quot;&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x1&quot; coefficient=&quot;0.41663968559520786&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x2&quot; coefficient=&quot;-1.6008331852575897&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x3&quot; coefficient=&quot;0.5776576286775582&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x4&quot; coefficient=&quot;-1.3855384286634223&quot;/&gt;</span><br><span class="line">	&lt;/RegressionTable&gt;</span><br><span class="line">	&lt;RegressionTable intercept=&quot;-1.2147145780786366&quot; targetCategory=&quot;2&quot;&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x1&quot; coefficient=&quot;-1.7075251538239047&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x2&quot; coefficient=&quot;-1.5342683399889876&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x3&quot; coefficient=&quot;2.4709716807720206&quot;/&gt;</span><br><span class="line">		&lt;NumericPredictor name=&quot;x4&quot; coefficient=&quot;2.5553821129820884&quot;/&gt;</span><br><span class="line">	&lt;/RegressionTable&gt;</span><br><span class="line">&lt;/RegressionModel&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>基本上和二元逻辑回归类似，只是RegressionTable 有三个，这是因为一共有三个类别，需要三组权重矩阵和截距，分别计算属于当前类别的概率值，因而对于多元逻辑回归而言，有多少元，输出的概率值就有多少个。<br>然后再针对所有输出的概率，求和，然后计算每个概率和求和概率的比值。这是为了保证形式上的统一。</p>
<h3 id="Scala实现"><a href="#Scala实现" class="headerlink" title="Scala实现"></a>Scala实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class LRMultiModel(</span><br><span class="line">   val weights: Array[Array[Double]],</span><br><span class="line">   val intercept: Array[Double]</span><br><span class="line">                          ) &#123;</span><br><span class="line"></span><br><span class="line">  def predict(testData:Array[Double]): Array[Double] =&#123;</span><br><span class="line">    val classNum = weights.size</span><br><span class="line">    val pro = new ArrayBuffer[Double]</span><br><span class="line">    for (i &lt;- 0 until classNum)&#123;</span><br><span class="line">      pro.append(predictPoint(testData,weights(i),intercept(i)))</span><br><span class="line">    &#125;</span><br><span class="line">    val sum = pro.sum</span><br><span class="line">    val result = pro.toArray.map(x=&gt;(x/sum))</span><br><span class="line">    result</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def predictPoint(</span><br><span class="line">                    dataMatrix: Array[Double],</span><br><span class="line">                    weightMatrix: Array[Double],</span><br><span class="line">                    intercept: Double): Double = &#123;</span><br><span class="line">    val margin = DenseVector(dataMatrix).dot(DenseVector(weightMatrix)) + intercept</span><br><span class="line">    val score = 1.0 / (1.0 + math.exp(-margin))</span><br><span class="line">    score</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于python训练的模型，选取head(1)进行测试<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_t=X_test.head(1)</span><br><span class="line">print(X_t)</span><br><span class="line">y_t=y_test.head(1)</span><br><span class="line">print(y_t)</span><br><span class="line">pipeline.predict_proba(X_t)</span><br></pre></td></tr></table></figure><br>结果如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[ 0.00122453  0.39920192  0.59957355]]</span><br></pre></td></tr></table></figure></p>
<p>编写测试方法测试<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">def testLRMul(): Unit =&#123;</span><br><span class="line">   val weight = Array(</span><br><span class="line">     Array(0.4149883282957013,1.4612973885622267,-2.2621411772020728,-1.02909509924489),</span><br><span class="line">     Array(0.41663968559520786,-1.6008331852575897,0.5776576286775582,-1.3855384286634223),</span><br><span class="line">     Array(-1.7075251538239047,-1.5342683399889876,2.4709716807720206,2.5553821129820884)</span><br><span class="line">   )</span><br><span class="line"></span><br><span class="line">   val intercept = Array(0.26560616797551695, 1.0854237423889572, -1.2147145780786366)</span><br><span class="line">   val model = new LRMultiModel(weight, intercept)</span><br><span class="line">   val x = Array(6.0, 2.7, 5.1, 1.6)</span><br><span class="line">   val y = model.predict(x)</span><br><span class="line">   var mclass = 0</span><br><span class="line">   var max = 0.0</span><br><span class="line">   for (i &lt;- 0 until y.size)&#123;</span><br><span class="line">     println(f&quot;The Probability Of Class $&#123;i&#125; is $&#123;y(i)&#125;&quot;)</span><br><span class="line">     if (y(i) &gt; max)&#123;</span><br><span class="line">       max = y(i)</span><br><span class="line">       mclass = i</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   println(s&quot;The Class May Be $&#123;mclass&#125;&quot;)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><br>结果如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">The Probability Of Class 0 is 0.0012245308619260621</span><br><span class="line">The Probability Of Class 1 is 0.39920191920408243</span><br><span class="line">The Probability Of Class 2 is 0.5995735499339914</span><br><span class="line">The Class May Be 2</span><br></pre></td></tr></table></figure></p>
<p>两者完全一致。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文借助了PMML，解析了简单线性回归和逻辑回归的结构。介绍了这两种模型是如何实现预测的。其实所有看起来，或者听起来“高大上”的模型，在码农的眼里，最终的呈现都是一系列的“参数”而已。<br>通过不同的方式将这些参数组合起来，便可实现一些神奇的功能。</p>
<h1 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h1><p><a href="https://blog.csdn.net/fleurdalis/article/details/54931721">https://blog.csdn.net/fleurdalis/article/details/54931721</a><br>李航 统计学习方法</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/05/postCLT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/05/postCLT/" class="post-title-link" itemprop="url">【翻译活动】面向数据科学的概率论-14.中心极限定律</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-08-05 19:29:19 / Modified: 19:33:20" itemprop="dateCreated datePublished" datetime="2018-08-05T19:29:19+08:00">2018-08-05</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BF%BB%E8%AF%91/" itemprop="url" rel="index"><span itemprop="name">翻译</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="十四、-中心极限定律"><a href="#十四、-中心极限定律" class="headerlink" title="十四、 中心极限定律"></a>十四、 中心极限定律</h1><blockquote>
<p>原文：<a href="https://nbviewer.jupyter.org/github/prob140/textbook/blob/gh-pages/notebooks/Chapter_14/">prob140/textbook/notebooks/ch_14</a></p>
<p>译者：<a href="https://github.com/Yao544303">喵十八</a></p>
<p>协议：<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p>
<p>自豪地采用<a href="https://translate.google.cn/">谷歌翻译</a></p>
</blockquote>
<h1 id="本章依赖的python"><a href="#本章依赖的python" class="headerlink" title="本章依赖的python"></a>本章依赖的python</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line"><span class="keyword">from</span> datascience <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> prob140 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">&#x27;fivethirtyeight&#x27;</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dist_sum</span>(<span class="params">n, probs_0_through_N</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the distribution of S_n,</span></span><br><span class="line"><span class="string">    the sum of n i.i.d. copies</span></span><br><span class="line"><span class="string">    of a random variable with distribution probs_0_through_N</span></span><br><span class="line"><span class="string">    on the integers 0, 1, 2, ..., N&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Find the possible values of S_n</span></span><br><span class="line">    N = <span class="built_in">len</span>(probs_0_through_N) - <span class="number">1</span>   </span><br><span class="line">    values_Sn = np.arange(n*N + <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Find the probailities of those values</span></span><br><span class="line">    coeffs_X1 = np.flipud(probs_0_through_N)</span><br><span class="line">    pgf_X1 = np.poly1d(coeffs_X1)</span><br><span class="line">    pgf_Sn = pgf_X1**n</span><br><span class="line">    coeffs_Sn = pgf_Sn.c</span><br><span class="line">    probs_Sn = np.flipud(coeffs_Sn)</span><br><span class="line">    </span><br><span class="line">    t = Table().with_columns(</span><br><span class="line">        <span class="string">&#x27;Value&#x27;</span>, values_Sn,</span><br><span class="line">        <span class="string">&#x27;Probability&#x27;</span>, probs_Sn</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> t</span><br></pre></td></tr></table></figure>
<h1 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h1><p>标准差是广为流传的衡量标准之一，此外，还有很多其他的衡量标准。为什么使用标准差？主要的原因是标准差和<a href="https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/7246669?fr=aladdin">正态曲线</a>之间的联系。为何正态曲线如此重要？本章将回答该问题。</p>
<p>我们将从分析一个独立同分布的概率和开始。并已知其均值和标准差。在本章中，我们将研究分布的形状：当我们可以计算它的精确形状时，我们计算它，当数据量过大时，我们计算一个其近似值。</p>
<h2 id="精确分布"><a href="#精确分布" class="headerlink" title="精确分布"></a>精确分布</h2><p>我们已经知道如何找到任意两个离散随机变量之和的分布。</p>
<script type="math/tex; mode=display">
P(X+Y = k) = \sum_j P(X=j, Y=k-j)</script><p>如果$X$和$Y$是独立的，这简化为成为<em>离散卷积公式</em>：</p>
<script type="math/tex; mode=display">
P(X+Y = k) = \sum_j P(X=j)P(Y=k-j)</script><p>通过归纳，我们可以将其扩展到任何有限数量的自变量的和。</p>
<p>所以原则上讲，我们知道如何找到$n$个（$n &gt; 1$）独立随机变量的概率分布之和。但是，对于很大的$n$，这种方式很难实现。</p>
<p>在本节中，我们将研究另一种分布求和的方法。正如您将看到的，它更容易实现自动化，但最终也会遇到计算障碍。</p>
<h3 id="概率生成函数"><a href="#概率生成函数" class="headerlink" title="概率生成函数"></a>概率生成函数</h3><p>设$X$是一个随机变量，对于给定的$N$，其可能取值为$0, 1, 2, \ldots, N$。<br>为简洁起见，令$p_k = P(X = k)$，其中$k$的取值范围为0到$N$。</p>
<p>定义$X$的<em>概率生成函数</em>(pgf)为</p>
<script type="math/tex; mode=display">
G_X(s) ~  = ~ \sum_{k=0}^N p_ks^k, ~~~ -\infty < s < \infty</script><p>对于具有无限多个非负整数随机变量的扩展，请参阅本节末尾的技术说明。</p>
<p>上面的定义表明对任何$s$，有</p>
<script type="math/tex; mode=display">
G_X(s) ~ = ~ p_0 + p_1s + p_2s^2 + p_3s^3 + \cdots + p_Ns^N</script><p>你可以看到$G_X$是一个$N$次多项式，并且$s^k$的系数是$p_k = P(X=k)$。</p>
<p>因此，如果给你一个随机变量的pgf，你可以通过简单地列出所有的权重和相应的系数来计算出随机变量的分布。</p>
<p>要了解这如何帮助我们找到总和的分布，请观察每一个$s$，$G_X(s)$的期望为</p>
<script type="math/tex; mode=display">
G_X(s) ~ = ~ \sum_{k=0}^N s^kP(X=k) ~ = ~ E(s^X)</script><p>因此，如果$X$和$Y$是独立的非负整数随机变量，那么对于每个$s$有</p>
<script type="math/tex; mode=display">
G_{X+Y}(s) ~ = ~ E(s^{X+Y}) ~ = ~ E(s^X s^Y) ~ = ~ E(s^X)E(s^Y)
~ = ~ G_X(s)G_Y(s)</script><p>我们已经使用了这样的事实：对于独立的随机变量，其相乘的期望是期望的相乘。</p>
<p>结果表明两个独立随机变量之和的pgf是两个pgf的乘积。这很容易扩展到两个以上的随机变量，并为独立同分布变量之和的pgf产生一个简单的公式。</p>
<h3 id="一个独立同分布样本分布之和的PGF"><a href="#一个独立同分布样本分布之和的PGF" class="headerlink" title="一个独立同分布样本分布之和的PGF"></a>一个独立同分布样本分布之和的PGF</h3><p>设$X_1, X_2, \ldots, X_n$是分布在$0, 1, 2, \ldots, N$上的独立同分布事件。令$S_n = X_1 + X_2 + \cdots + X_n$，那么$S_n$的pgf为：</p>
<script type="math/tex; mode=display">
G_{S_n}(s) ~ = ~ \big{(}G_{X_1}(s)\big{)}^n, ~~~ -\infty < s < \infty</script><p>因为$G<em>{X_1}$是一个$N$次多项式，$G</em>{S_n}$也是一个$nN$次多项式。与任何pgf一样，$s^k$的系数是$k$的概率。也就是说，对于每一个在0到$nN$范围内的$k$有</p>
<script type="math/tex; mode=display">
P(S_n = k) = \text{coefficient of } s^k \text{ in } G_{S_n}(s)</script><p>我们现在有一个查找$S_n$分布的算法。</p>
<ul>
<li>从$X_1$的pgf开始。</li>
<li>增加幂至$n$。也就是$S_n$的pgf。</li>
<li>读取$S_n$的pgf.</li>
</ul>
<p>精彩！我们完成了！除了实际上这样做涉及将多项式升幂。当数很大时，这是一项艰巨的任务。</p>
<p>幸运的是，正如您将在下一节中看到的那样，<code>NumPy</code>使用一组多项式方法来解决问题。</p>
<p><em>技术说明。</em>我们已经为具有有限多个非负整数值的随机变量定义了概率生成函数。该定义可以扩展到具有无限多个非负整数值的随机变量。但在这种情况下，pgf是一个无限系列，我们必须小心收敛。通常，pdf是的值域 $|s| \le 1$，这样它就会收敛。 </p>
<h2 id="NumPy中的PGF"><a href="#NumPy中的PGF" class="headerlink" title="NumPy中的PGF"></a>NumPy中的PGF</h2><p>回忆一下，我们找到$S_n$分布的算法。</p>
<ul>
<li>从$X_1$的pgf开始。</li>
<li>增加幂至$n$。也就是$S_n$的pgf。</li>
<li>读取$S_n$的pgf.</li>
</ul>
<p>在本节中，我们将使用<code>NumPy</code>实践此算法。</p>
<p>假设$X_1$的分布为$p_0 = 0.1$，$p_1 = 0.5$，$p_2 = 0.4$。令数组<code>probs_X1</code>包含了0,1,2的概率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">probs_X1 = make_array(<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.4</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dist_X1 = Table().values(np.arange(<span class="number">3</span>)).probability(probs_X1)</span><br><span class="line">Plot(dist_X1)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_02_output_5_0.png" alt="png"></p>
<p>$X_1$的pgf是：</p>
<script type="math/tex; mode=display">
0.1 + 0.5s + 0.4s^2</script><p><code>NumPy</code> 以标准的数学方式表示这个多项式，以最高次项开始：</p>
<script type="math/tex; mode=display">
0.4s^2 + 0.5s + 0.1</script><p>方法<code>np.flipud</code>将概率数组反转为与该系数的顺序一致。<code>ud</code>代表“up down”。NumPy正在考虑将数组作为一个列。<code>NumPy</code>考虑将该数组转为一列。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">coeffs_X1 = np.flipud(probs_X1)</span><br><span class="line">coeffs_X1</span><br></pre></td></tr></table></figure>
<pre><code>array([ 0.4,  0.5,  0.1])
</code></pre><p>方法<code>np.poly1d</code>以系数数组为参数，构造多项式。方法名中的<code>1d</code>代表”一维”。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pgf_X1 = np.poly1d(coeffs_X1)</span><br><span class="line"><span class="built_in">print</span>(pgf_X1)</span><br></pre></td></tr></table></figure>
<pre><code>     2
0.4 x + 0.5 x + 0.1
</code></pre><p>调用<code>print</code>方法，打印出该多项式。在$s$的位置，用$x$代替表示。请记住，最后一项是$x^0$的系数。</p>
<p>现在假设$S_3$是三个$X_1$副本的和。$S_3$的pgf是$X_1$pgf的三次方，并且可以按照您的希望计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pgf_S3 = pgf_X1**<span class="number">3</span></span><br><span class="line"><span class="built_in">print</span>(pgf_S3)</span><br></pre></td></tr></table></figure>
<pre><code>       6        5         4         3         2
0.064 x + 0.24 x + 0.348 x + 0.245 x + 0.087 x + 0.015 x + 0.001
</code></pre><p>$S_3$中多项式的幂为从0到6，因为$S_3$是三个幂从0到2的值的副本的和。系数是$S_3$分布的概率。</p>
<p>你可以使用属性<code>c</code>输出其“系数”。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">coeffs_S3 = pgf_S3.c</span><br><span class="line">coeffs_S3</span><br></pre></td></tr></table></figure>
<pre><code>array([ 0.064,  0.24 ,  0.348,  0.245,  0.087,  0.015,  0.001])
</code></pre><p>这些是从6次到0次项的系数。在概率中，更习惯从低到高的顺序来看，所以再使用一次<code>np.flipud</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">probs_S3 = np.flipud(coeffs_S3)</span><br><span class="line">probs_S3</span><br></pre></td></tr></table></figure>
<pre><code>array([ 0.001,  0.015,  0.087,  0.245,  0.348,  0.24 ,  0.064])
</code></pre><p>您现在拥有绘制$S_3$的概率直方图所需的输入了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dist_S3 = Table().values(np.arange(<span class="number">7</span>)).probability(probs_S3)</span><br><span class="line">Plot(dist_S3)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_02_output_17_0.png" alt="png"></p>
<h3 id="计算分布-S-n-的函数"><a href="#计算分布-S-n-的函数" class="headerlink" title="计算分布$S_n$的函数"></a>计算分布$S_n$的函数</h3><p>我们将结合上面的步骤来创建一个函数<code>dist_sum</code>，入参为副本个数$n$和$X_1$的分布，返回值为$n$个$X_1$的副本的和的分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dist_sum</span>(<span class="params">n, probs_0_through_N</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the distribution of S_n,</span></span><br><span class="line"><span class="string">    the sum of n i.i.d. copies</span></span><br><span class="line"><span class="string">    of a random variable with distribution probs_0_through_N</span></span><br><span class="line"><span class="string">    on the integers 0, 1, 2, ..., N&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Find the possible values of S_n</span></span><br><span class="line">    N = <span class="built_in">len</span>(probs_0_through_N) - <span class="number">1</span>   </span><br><span class="line">    values_Sn = np.arange(n*N + <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Find the probailities of those values</span></span><br><span class="line">    coeffs_X1 = np.flipud(probs_0_through_N)</span><br><span class="line">    pgf_X1 = np.poly1d(coeffs_X1)</span><br><span class="line">    pgf_Sn = pgf_X1**n</span><br><span class="line">    coeffs_Sn = pgf_Sn.c</span><br><span class="line">    probs_Sn = np.flipud(coeffs_Sn)</span><br><span class="line">    </span><br><span class="line">    t = Table().with_columns(</span><br><span class="line">        <span class="string">&#x27;Value&#x27;</span>, values_Sn,</span><br><span class="line">        <span class="string">&#x27;Probability&#x27;</span>, probs_Sn</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> t</span><br></pre></td></tr></table></figure>
<h3 id="n-次掷骰子游戏的和"><a href="#n-次掷骰子游戏的和" class="headerlink" title="$n$次掷骰子游戏的和"></a>$n$次掷骰子游戏的和</h3><p>在第3章中，我们通过列出所有的$6^5$种可能情况，并计算他们从而找到了5次掷骰子游戏的和的分布。这种方法难以处理大数据量的情况。让我们看看我们的新方法是否可以找到10个骰子总和的分布。</p>
<p>我们必须从单个筛子的分布开始，为此重要的是要记住包含0作为0个点的概率。否则pgf将是错误的，因为<code>NumPy</code>不知道它不应该包括0次项。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">die = np.append(<span class="number">0</span>, (<span class="number">1</span>/<span class="number">6</span>)*np.ones(<span class="number">6</span>))</span><br><span class="line">die</span><br></pre></td></tr></table></figure>
<pre><code>array([ 0.        ,  0.16666667,  0.16666667,  0.16666667,  0.16666667,
        0.16666667,  0.16666667])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plot(dist_sum(<span class="number">1</span>, die))</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_02_output_22_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plot(dist_sum(<span class="number">10</span>, die))</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_02_output_23_0.png" alt="png"></p>
<h3 id="制作波"><a href="#制作波" class="headerlink" title="制作波"></a>制作波</h3><p>10个筛子和的分布，看上去很符合正态分布。是所有的和都这样么？</p>
<p>要探索这个问题，让$X_1$的分布为$p_1 = p_2 = p_9 = 1/3$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">probs_X1 = make_array(<span class="number">0</span>, <span class="number">1</span>/<span class="number">3</span>, <span class="number">1</span>/<span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>/<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>这是$X_1$的分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plot(dist_sum(<span class="number">1</span>, probs_X1))</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_02_output_27_0.png" alt="png"></p>
<p>$S_{10}$的概率直方图表明“和”并不总是具有平滑的分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plot(dist_sum(<span class="number">10</span>, probs_X1))</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_02_output_29_0.png" alt="png"></p>
<p>$S_{30}$的分布看上去头发乱糟糟的剑龙。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plot(dist_sum(<span class="number">30</span>, probs_X1))</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_02_output_31_0.png" alt="png"></p>
<p>$S_{100}$的分布是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plot(dist_sum(<span class="number">100</span>, probs_X1))</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_02_output_33_0.png" alt="png"></p>
<p>… 非常正态分布了. </p>
<p>这看起来好像这里有什么定理。在本章的其余部分，我们将研究该定理，该定理是关于大量独立同分布样本之和的近似分布。</p>
<p>请记住，只要<code>NumPy</code>能够处理计算,我们的pgf方法就能求出有限多个非负整数上的独立同分布样本分布总和的<em>精确分布</em>。在上面的例子中， $S_{100}$的pgf是一个最高次项为900的多项式。<code>NumPy</code>处理得很好。</p>
<h2 id="中心极限定理-1"><a href="#中心极限定理-1" class="headerlink" title="中心极限定理"></a>中心极限定理</h2><p>顾名思义，这个定理是概率，统计和数据科学领域的核心。它解释了上一节中出现的正态曲线。</p>
<p>在我们得到定理之前，让我们回顾一下数据8和本课程前面的一些事实。</p>
<h3 id="标准单位"><a href="#标准单位" class="headerlink" title="标准单位"></a>标准单位</h3><p>正如我们之前看到的，随机变量 $X$转换为<em>标准单位</em>如下</p>
<script type="math/tex; mode=display">
Z = \frac{X - \mu_X}{\sigma_X}</script><p>$Z$以标准差为单位，衡量了$X$离开均值的距离（如，均值4，标准差1,5就离开均值1个标准差的距离）。换句话说$Z$表示了$X$高于均值的标准差的数。</p>
<p>按线性函数规则，无论$X$的分布是什么，都有</p>
<script type="math/tex; mode=display">
E(Z) = 0 ~~~ \text{and} ~~~ SD(Z) = 1</script><h3 id="标准正态曲线"><a href="#标准正态曲线" class="headerlink" title="标准正态曲线"></a>标准正态曲线</h3><p>回顾数据8，标准正常曲线由通常用小写希腊字母phi，$\phi$表示的函数定义，。</p>
<script type="math/tex; mode=display">
\phi(z) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}z^2}, ~~~ -\infty < z < \infty</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line">Plot_norm(x_limits=(-<span class="number">4</span>, <span class="number">4</span>), mu=<span class="number">0</span>, sigma=<span class="number">1</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$z$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;$\phi(z)$&#x27;</span>, rotation=<span class="number">0</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Standard Normal Curve&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_03_output_5_0.png" alt="png"></p>
<p>该曲线关于0对称。其拐点在$z=-1$和$z=1$。您在Data 8中观察到了这一点并且可以通过微积分证明它。</p>
<p><strong>术语</strong> 我们将说曲线具有<em>位置参数</em> 0 和<em>比例</em> 参数 1。我们还将使用术语<em>平均值</em>来表示位置和<em>标准差</em>来表示比例，类似于标准单位中随机变量的均值和标准差。在本课程的后面，我们将证明这与具有连续值的随机变量的均值和标准差的定义一致。</p>
<p>曲线下的总面积为1。这需要一些工作来证明。您可能已经在微积分课中看到过它。我们将在课程的后期使用概率方法证明它。</p>
<p>如果是随机变量$X$的分布大致是钟形，那么标准化变量$Z$的分布大致遵循上面的标准正态曲线。</p>
<p>请注意，几乎没有概率落在范围$(-3, 3)之外。回顾一下数据8中的一下数据：</p>
<ul>
<li>介于-1和1之间的面积：约68％</li>
<li>介于-2和2之间的面积：约95％</li>
<li>介于-3和3之间的面积：约99.73％</li>
</ul>
<h3 id="正态曲线"><a href="#正态曲线" class="headerlink" title="正态曲线"></a>正态曲线</h3><p>标准正态曲线是这样一<em>类</em>正态曲线，由其位置和比例参数参数，及均值和标准差确定。</p>
<p>均值为$\mu$，方差为$\sigma$的正态曲线定义如下：</p>
<script type="math/tex; mode=display">
f(x) ~ = ~ \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}, ~~~ -\infty < x < \infty</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line">Plot_norm(x_limits=(-<span class="number">4</span>, <span class="number">4</span>), mu=<span class="number">0</span>, sigma=<span class="number">1</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$x$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;$f(x)$&#x27;</span>, rotation=<span class="number">0</span>)</span><br><span class="line">plt.yticks(np.arange(<span class="number">0</span>, <span class="number">0.401</span>, <span class="number">0.05</span>), np.array(<span class="number">7</span>*[<span class="string">&#x27;&#x27;</span>]))</span><br><span class="line">plt.xticks(np.arange(-<span class="number">4</span>, <span class="number">4.1</span>), [<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;$\mu-2\sigma$&#x27;</span>, <span class="string">&#x27;$\mu - \sigma$&#x27;</span>, <span class="string">&#x27;$\mu$&#x27;</span>, <span class="string">&#x27;$\mu+\sigma$&#x27;</span>,<span class="string">&#x27;$\mu+2\sigma$&#x27;</span>,<span class="string">&#x27;&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Normal Curve, mean $\mu$, SD $\sigma$&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_03_output_8_0.png" alt="png"></p>
<p>形状看起来与标准正常曲线完全相同。唯一的区别在于轴上的测量尺度。中心现在是$\mu$而不是0，并且拐点远离中心距离是以$\sigma$为单位而不是1。</p>
<p>现在给出正态曲线的重要性：</p>
<h3 id="中心极限定理-2"><a href="#中心极限定理-2" class="headerlink" title="中心极限定理"></a>中心极限定理</h3><p>设 $X_1, X_2, \ldots$ 是i.i.d., 每一个都有均值$\mu$和标准差$\sigma$。令$S_n = X_1 + X_2 + \cdots + X_n$，则有</p>
<script type="math/tex; mode=display">
E(S_n) = n\mu ~~~~~~~~~~ SD(S_n) = \sqrt{n}\sigma</script><p>我们还不知道$S_n$的分布的形状。<em>中心极限定理</em>（CLT）告诉我们，当$n$很大时，曲线会很平滑。</p>
<h4 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h4><p>当$n$很大时，标准分布的和为</p>
<script type="math/tex; mode=display">
\frac{S_n - n\mu}{\sqrt{n}\sigma}</script><p>无论$X_i$的分布如何，最终将大致遵循标准正态分布。</p>
<p>换言之，当$n$很大时，无论$X_i$的分布如何，$S_n$的分布与均值$n\mu$和标准差$\sqrt{n}\sigma$有关</p>
<p>中心极限定理是使用标准差对分布进行衡量的主要原因。</p>
<p>究竟当$n$多大时，估计值能够有一个较好的结果？这取决于$X_i$的分布。我们稍后会详细说明。现在，假设我们使用的样本大小足够大，以使正态估计合理。</p>
<p>该定理的证明超出了本课程的范围。但是你已经在数据8中进行的模拟以及前一节中计算的总和的精确分布中看到了大量的证据。</p>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>假设一个样本为100人的重量，是独立同分布的，其均值为150磅，标准差为15磅。然后所采样的人的总重量的均值为$100 \times 150 = 15,000$，标准差为$\sqrt{100} \times 15 = 150$。</p>
<p>谁在乎一群随机人的总重量？询问那些建造体育馆，电梯和飞机的人。</p>
<p>您可以使用<code>prob140</code>方法绘制此分布<code>Plot_norm</code>。参数是您希望绘制曲线的间隔，平均值和标准差。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">100</span></span><br><span class="line">mu = <span class="number">150</span></span><br><span class="line">sigma = <span class="number">15</span></span><br><span class="line"></span><br><span class="line">mean = n*mu</span><br><span class="line">sd = (n**<span class="number">0.5</span>)*sigma</span><br><span class="line"></span><br><span class="line">plot_interval = make_array(mean-<span class="number">4</span>*sd, mean+<span class="number">4</span>*sd)</span><br><span class="line"></span><br><span class="line">Plot_norm(plot_interval, mean, sd)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_03_output_12_0.png" alt="png"></p>
<h3 id="正态曲线下的概率"><a href="#正态曲线下的概率" class="headerlink" title="正态曲线下的概率"></a>正态曲线下的概率</h3><p>假设我们想要找到抽样人员的总重量小于15,100磅的概率。这大约是下面的黄金区域。这是使用正态曲线的一个估计。</p>
<p>请注意参数<code>right_end=15100</code>。这告诉<code>Plot_norm</code>其右边界。如果没有指定左端，则最左端视为其左边界。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plot_norm(plot_interval, mean, sd, right_end=<span class="number">15100</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_03_output_14_0.png" alt="png"></p>
<p>和以前一样，返回点左边所有概率的函数称为分布的<em>累积分布函数</em>（cdf）。<code>stats.norm.cdf</code>使用适当的参数，概率不到75％。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stats.norm.cdf(<span class="number">15100</span>, mean, sd)</span><br></pre></td></tr></table></figure>
<pre><code>0.74750746245307709
</code></pre><p>为了估计总重量在14,800磅到15,100磅之间的概率率是多少？现在我们指定两个参数<code>left_end</code>和<code>right_end</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plot_norm(plot_interval, mean, sd, left_end=<span class="number">14800</span>, right_end=<span class="number">15100</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_03_output_18_0.png" alt="png"></p>
<p>阴影面积约为65.6％.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stats.norm.cdf(<span class="number">15100</span>, mean, sd) - stats.norm.cdf(<span class="number">14800</span>, mean, sd)</span><br></pre></td></tr></table></figure>
<pre><code>0.65629624272720921
</code></pre><h3 id="标准正态-CDF-Phi"><a href="#标准正态-CDF-Phi" class="headerlink" title="标准正态 CDF $\Phi$"></a>标准正态 CDF $\Phi$</h3><p>实际上只有一条正常曲线很重要 - 标准正态曲线。所有其他的都是标准正态曲线通过水平轴的线性变换获得的。因此，通过标准化，可以根据标准正态cdf完成上述所有计算，如下所述。</p>
<p>要找到总重量小于15,100磅的大概几率，首先将重量标准化，然后使用标准正态cdf。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">z_right = (<span class="number">15100</span> - mean)/sd</span><br><span class="line"></span><br><span class="line">stats.norm.cdf(z_right)  <span class="comment"># The standard curve is the default</span></span><br></pre></td></tr></table></figure>
<pre><code>0.74750746245307709
</code></pre><p>要找到总重量在14,800磅到15,100磅之间的概率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">z_left = (<span class="number">14800</span> - mean)/sd</span><br><span class="line"></span><br><span class="line">stats.norm.cdf(z_right) - stats.norm.cdf(z_left)</span><br></pre></td></tr></table></figure>
<pre><code>0.65629624272720921
</code></pre><p>标准正态cdf的常用符号是大写字母$\Phi$，因为它是$\phi$的积分：</p>
<script type="math/tex; mode=display">
\Phi(x) = \int_{-\infty}^x \phi(z)dz, ~~~~ -\infty < x < \infty</script><p>这个积分虽然是有限的，但没有封闭形式的公式，可以用算术运算，幂，三角函数，指数和对数函数以及组合来改写。它必须通过数值积分来求近似值。这就是为什么每个统计系统都有内置功能，例如<code>stats.norm.cdf</code>提供出色的近似值功能。</p>
<p>标准化标准正态累积分布函数$\Phi$为所有正态曲线下的面积值提供了紧凑的表示法。我们不必对不同的参数使用不同的函数。</p>
<p>在CLT的假设下，对于大的值$n$我们有近似值</p>
<script type="math/tex; mode=display">
P(S_n \le x) ~ \approx ~ \Phi \big{(} \frac{x - n\mu}{\sqrt{n}\sigma} \big{)} ~~~ \text{for all } x</script><p>正如您在数据8中看到的那样，近似值通常在分布的尾部中表现不佳。如果使用CLT来逼近尾部区域的概率，请注意近似值可能非常粗糙。</p>
<h3 id="二项分布-n-p-的估计"><a href="#二项分布-n-p-的估计" class="headerlink" title="二项分布 $(n, p)$ 的估计"></a>二项分布 $(n, p)$ 的估计</h3><p>一个二项随机分布$(n, p)$ 是$n$个i.i.d.分布的和。CLT表明，如果$n$足够大，无论$p$是什么，分布是大致成正态分布的。但我们在第6章中说过，如果$n$很大，$p$很小，那么二项分布大致是泊松分布。</p>
<p>那么它到底是正态分布还是泊松分布？这是两个二项式直方图，两者都有大的$n$但有不同的形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">k1 = np.arange(<span class="number">25</span>, <span class="number">76</span>)</span><br><span class="line">probs1 = stats.binom.pmf(k1, <span class="number">100</span>, <span class="number">0.5</span>)</span><br><span class="line">binom_fair = Table().values(k1).probability(probs1)</span><br><span class="line">Plot(binom_fair)</span><br><span class="line">plt.title(<span class="string">&#x27;Binomial (100, 0.5)&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_03_output_27_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">k2 = np.arange(<span class="number">0</span>, <span class="number">11</span>)</span><br><span class="line">probs2 = stats.binom.pmf(k2, <span class="number">100</span>, <span class="number">0.01</span>)</span><br><span class="line">binom_biased = Table().values(k2).probability(probs2)</span><br><span class="line">Plot(binom_biased)</span><br><span class="line">plt.title(<span class="string">&#x27;Binomial (100, 0.1)&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_03_output_28_0.png" alt="png"></p>
<p>差异是由于分布的扩散。当分布在0附近时，泊松近似适用。当扩展较大时，在均值的任一侧存在大量可能值，则可以尝试正态分布。</p>
<p>为了量化这一点，许多文本根据给出了粗略的阈值$n$和$p$，使得，如果$n$大于阈值，那么二项式$(n, p)$大致是正态分布。如果$n$很大，二项分布类似于泊松，意味着$n$没有超过正态分布的阈值。</p>
<p>阈值通常以“标准差$\sqrt{npq}$大于3” 或“$np$和$nq$都大于10”来表示，这些不完全一致，但非常相近。</p>
<p>您可以通过比较二项式与相应泊松之间的总变化距离以及二项式与相应法线之间的总变化距离来了解您对这些阈值的看法。然而，在这个过程中，对二项式的法线与泊松近似的选择很少会成为一个问题，因为当$n$和$p$的值都给出时， 如果您对使用哪个有疑问，那么您可以使用确切的二项式概率。</p>
<p>这是二项式（100,0.5）分布和近似正态曲线。曲线的参数是$np = 50$和$\sqrt{npq} = 5$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Plot(binom_fair)</span><br><span class="line">Plot_norm((<span class="number">25</span>, <span class="number">75</span>), <span class="number">50</span>, <span class="number">5</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">25</span>, <span class="number">76</span>, <span class="number">5</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Binomial (100, 0.5) and its Normal Approximation&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_03_output_31_0.png" alt="png"></p>
<p>注意点“$\mbox{mean } \pm \mbox{ SD}$“$= 50 \pm 5$是曲线的拐点。</p>
<h2 id="样本均值"><a href="#样本均值" class="headerlink" title="样本均值"></a>样本均值</h2><p>中心极限定理的核心是什么？一个答案是它允许我们基于随机样本做出推论，即使我们对总体的分布知之甚少。</p>
<p>在数据8中，您看到如果我们想要估计总体的平均值，我们可以基于大随机样本的平均值来构建参数的置信区间。在该过程中，您使用引导程序生成样本均值的经验分布，然后使用经验分布来创建置信区间。你会记得那些经验分布总是钟形的。</p>
<p>在本节中，我们将研究样本均值的概率分布，并表明您可以使用它来构建总体均值的置信区间，而无需进行任何重新采样。</p>
<p>让我们从样本总和开始，我们现在很清楚。回想一下我们的假设和符号：</p>
<p>设$X<em>1, X_2, \ldots, X_n$ 是一个i.i.d采样, 设每一个$X_i$的均值为$\mu$标准差为$\sigma$。设$S_n$是样本总和，即$S_n = \sum</em>{i=1}^n X_i$。可以得到</p>
<script type="math/tex; mode=display">
E(S_n) = n\mu ~~~~~~~~~~  SD(S_n) = \sqrt{n}\sigma</script><p>这些结果意味着随着样本量的增加，样本总和的分布向右移动并变得更加分散。</p>
<p>您可以在下图中看到这一点。该图显示了5个筛子的总和和20个筛子的总和的分布。分布是精确的，使用本章前面定义的<code>dist_sum</code>方法计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">die = np.append(<span class="number">0</span>, (<span class="number">1</span>/<span class="number">6</span>)*np.ones(<span class="number">6</span>))</span><br><span class="line">dist_sum_5 = dist_sum(<span class="number">5</span>, die)</span><br><span class="line">dist_sum_20 = dist_sum(<span class="number">20</span>, die)</span><br><span class="line">Plots(<span class="string">&#x27;Sum of 5 dice&#x27;</span>, dist_sum_5, <span class="string">&#x27;Sum of 20 dice&#x27;</span>, dist_sum_20)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_04_output_4_0.png" alt="png"></p>
<p>您可以看到正态分布已经显示为5和20个样本的总和。</p>
<p>您还可以看到黄金区域不是蓝色区域的四倍，尽管黄金区域中的样本大小是蓝色的四倍。黄金区域高只有蓝色一半，分布是蓝色的两倍。那是因为总和的标准与$\sqrt{n}$成正比。它增长比$n$慢。由于样本量大4倍，因此黄金分布的标准差为蓝色的 $\sqrt{4} = 2$倍。</p>
<p>样本的<em>平均值</em>表现不同</p>
<h3 id="IID-样本的均值"><a href="#IID-样本的均值" class="headerlink" title="IID 样本的均值"></a>IID 样本的均值</h3><p>设$\bar{X}_n$是样本年均值，即</p>
<script type="math/tex; mode=display">
\bar{X}_n = \frac{S_n}{n}</script><p>然后$\bar{X}_n$只是$S_n$的线性变换，所以</p>
<script type="math/tex; mode=display">
E(\bar{X}_n) = \frac{E(S_n)}{n} = \frac{n\mu}{n} = \mu ~~~~ \text{for all }n</script><p>样本均值的期望总是总体的均值$\mu$，无论样本大小。因此，无论样本大小如何，样本均值都是总体均值的无偏估计。</p>
<p>样本均值标准差是</p>
<script type="math/tex; mode=display">
SD(\bar{X}_n) = \frac{SD(S_n)}{n} = \frac{\sqrt{n}\sigma}{n} = \frac{\sigma}{\sqrt{n}}</script><p>随着样本量的增加，样本均值的变化性降低。因此，随着样本量的增加，样本均值对总体均值的估计更准确。</p>
<p>下图显示了5个筛子和20个筛子的平均值的分布。两者都以3.5为中心，但较大样本的均值分布较窄。您在数据8中经常看到这一点：随着样本量的增加，样本均值的分布更集中在总体均值周围。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line">dist_mean_5 = Table().with_columns(</span><br><span class="line">    <span class="string">&#x27;Value&#x27;</span>, dist_sum_5.column(<span class="number">0</span>)/<span class="number">5</span>,</span><br><span class="line">    <span class="string">&#x27;Probability&#x27;</span>, <span class="number">5</span>*dist_sum_5.column(<span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">dist_mean_20 = Table().with_columns(</span><br><span class="line">    <span class="string">&#x27;Value&#x27;</span>, dist_sum_20.column(<span class="number">0</span>)/<span class="number">20</span>,</span><br><span class="line">    <span class="string">&#x27;Probability&#x27;</span>, <span class="number">20</span>*dist_sum_20.column(<span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">Plots(<span class="string">&#x27;Mean of 5 dice&#x27;</span>, dist_mean_5, <span class="string">&#x27;Mean of 20 dice&#x27;</span>, dist_mean_20, width=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_04_output_7_0.png" alt="png"></p>
<p>精确是有代价的。样本平均值的标准差随着样本大小的平方根减小。因此，如果要将样本均值的标准差降低3倍，则必须将样本量增加$3^2 = 9$倍。</p>
<p>一般结果通常可作为反例进行证明。</p>
<h4 id="平方根法则"><a href="#平方根法则" class="headerlink" title="平方根法则"></a>平方根法则</h4><p>如果将样本扩大n倍，则样本均值的均值会减少$\sqrt{n}$倍。</p>
<h3 id="弱大数定律"><a href="#弱大数定律" class="headerlink" title="弱大数定律"></a>弱大数定律</h3><p>样本均值是总体均值的无偏估计，并且当样本较大时，其标准差比较小。因此，大样本的平均值接近总体平均值的概率很高。</p>
<p>这一结论称为<em>弱大数定律</em>。</p>
<p>令$X_1, X_2, \ldots, X_n$是i.i.d.，每一个有均值$\mu$和标准差$\sigma$，令$\bar{X}_n$是样本均值。取一个极小数$\epsilon &gt; 0$，有</p>
<script type="math/tex; mode=display">
P(|\bar{X}_n - \mu| < \epsilon) \to 1 ~~~ \text{as } n \to \infty</script><p>也就是说，对于$n$取值很大时，几乎可以确定均值在$\mu \pm \epsilon$的范围内，</p>
<p>为了证明该定律，我命将证明$P(|\bar{X}_n - \mu| \ge \epsilon) \to 0$，这是用切比雪夫不等式很容易求解。</p>
<script type="math/tex; mode=display">
P(|\bar{X}_n - \mu| \ge \epsilon)~ \le ~ \frac{\sigma_{\bar{X}_n}^2}{\epsilon^2} 
~ = ~ \frac{\sigma^2}{n\epsilon^2} ~ \to ~ 0 ~~~ \text{as } n \to \infty</script><h3 id="相关定律"><a href="#相关定律" class="headerlink" title="相关定律"></a>相关定律</h3><ul>
<li><strong>强大数定律。</strong> 这表示在概率为1时，样本平均值收敛到极限，并且该极限是常数$\mu$。请参阅<a href="https://terrytao.wordpress.com/2008/06/18/the-strong-law-of-large-numbers/">Fields Medalist Terence Tao撰写的这篇博客文章</a>。他陈述了基础标准差可能不存在的情况下的定律情况。请注意，我们的弱大数定律证明方法在这种情况下无效; 结果仍然是正确的，但证据需要更多的探索。</li>
<li><strong>小数定律。</strong> 这是<a href="https://en.wikipedia.org/wiki/Ladislaus_Bortkiewicz">Ladislaus Bortkiewicz</a> (1868-1931)一本书的标题。其中他描述了低概率事件分布的泊松近似。这就是为什么这些注释的第6.4节被称为小数定律。</li>
<li><strong>平均定律。</strong> 在总体是二元的情况下，这是弱法则的通用名称，样本均值只是样本中成功的比例。在通常的使用中，人们有时会忘记定律是一种限制性陈述。如果你正在抛硬币并连续看到10个正面，那么下一个抛正面的机会仍然是1/2。平均律并没有说你“应该是反面”。它不适用于有限的投掷集。</li>
</ul>
<h3 id="分布的形状"><a href="#分布的形状" class="headerlink" title="分布的形状"></a>分布的形状</h3><p>中心极限定理告诉我们，对于大样本，样本均值的分布大致是正态的。样本均值是样本和的线性变换。因此，如果样本总和的分布大致是正态的，则样本均值的分布也大致是正态的，但具有不同的参数。具体来说，对于$n$很大的情况下</p>
<script type="math/tex; mode=display">
P(\bar{X}_n \le x) ~ \approx ~ \Phi \big{(} \frac{x - \mu}{\sigma/\sqrt{n}} \big{)} ~~~~ \text{for all } x</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line">Plot_norm(x_limits=(-<span class="number">4</span>, <span class="number">4</span>), mu=<span class="number">0</span>, sigma=<span class="number">1</span>)</span><br><span class="line">plt.yticks(np.arange(<span class="number">0</span>, <span class="number">0.401</span>, <span class="number">0.05</span>), np.array(<span class="number">7</span>*[<span class="string">&#x27;&#x27;</span>]))</span><br><span class="line">plt.xticks(np.arange(-<span class="number">4</span>, <span class="number">4.1</span>),[<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;$\mu - \sigma/\sqrt&#123;n&#125;$&#x27;</span>, <span class="string">&#x27;$\mu$&#x27;</span>, <span class="string">&#x27;$\mu+\sigma/\sqrt&#123;n&#125;$&#x27;</span>,<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Approximate Distribution of Sample Mean&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_04_output_12_0.png" alt="png"></p>
<h2 id="置信区间"><a href="#置信区间" class="headerlink" title="置信区间"></a>置信区间</h2><p>假设你有一个大的iid样本。CLT意味着有约95％的概率，样本均值在总体平均值的2个标准差距离内。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line">Plot_norm(x_limits=(-<span class="number">4</span>, <span class="number">4</span>), mu=<span class="number">0</span>, sigma=<span class="number">1</span>, left_end=-<span class="number">2</span>, right_end=<span class="number">2</span>)</span><br><span class="line">plt.yticks(np.arange(<span class="number">0</span>, <span class="number">0.401</span>, <span class="number">0.05</span>), np.array(<span class="number">7</span>*[<span class="string">&#x27;&#x27;</span>]))</span><br><span class="line">plt.xticks(np.arange(-<span class="number">4</span>, <span class="number">4.1</span>),[<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;$\mu - 2\sigma/\sqrt&#123;n&#125;$&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;$\mu$&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;$\mu+2\sigma/\sqrt&#123;n&#125;$&#x27;</span>,<span class="string">&#x27;&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Sample Mean&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Gold Area: Approximately 95%&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_05_output_3_0.png" alt="png"></p>
<p>这可以用不同的方式表达：</p>
<ul>
<li>在所有样本集合的约95％的样本中，样本平均值在<em>总体平均值$\pm ~ 2 \sigma/\sqrt{n}$</em>的范围内。</li>
</ul>
<p>换言之：</p>
<ul>
<li>在所有样本集合的约95％的样本中， 总体的平均值在<em>样本均值 $\pm ~ 2 \sigma/\sqrt{n}$</em>的范围内。</li>
</ul>
<p>这就是为什么用<em>样本均值$\pm ~ 2 \sigma/\sqrt{n}$</em>作为$\mu$的估计间隔。</p>
<h3 id="mu-的置信区间"><a href="#mu-的置信区间" class="headerlink" title="$\mu$的置信区间"></a>$\mu$的置信区间</h3><p><em>样本均值$\pm ~ 2 \sigma/\sqrt{n}$</em>的区间称之为<em>参数$\mu$的95％置信区间</em>这个区间，拥有一个95%的<em>置信水平</em>。</p>
<p>你可以选择不同的置信水平，比如说80％。在这个选择下，你的期望区间会更窄。要确切了解中心两侧需要多少标准差的距离，来获得大约80％的中心区域，您必须找到在标准正态曲线上相应的$z$，如下图所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line">Plot_norm(x_limits=(-<span class="number">4</span>, <span class="number">4</span>), mu=<span class="number">0</span>, sigma=<span class="number">1</span>, left_end=-<span class="number">1.28</span>, right_end=<span class="number">1.28</span>)</span><br><span class="line">plt.yticks(np.arange(<span class="number">0</span>, <span class="number">0.401</span>, <span class="number">0.05</span>), np.array(<span class="number">7</span>*[<span class="string">&#x27;&#x27;</span>]))</span><br><span class="line">plt.xticks(make_array(-<span class="number">1.28</span>, <span class="number">0</span>, <span class="number">1.28</span>),[<span class="string">&#x27;$-z$&#x27;</span>, <span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;$z$&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Gold Area: Approximately 80%&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_05_output_6_0.png" alt="png"></p>
<p>正如您从数据8中所知，并且可以在图中看到，间隔从分布的第10百分位到第90百分位。所以$z$是标准正态曲线的第90个百分点，也称为曲线的“90％点”。<code>scipy</code>方法会调用<code>ppf</code>并将f分位数的十进制值作为其参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stats.norm.ppf(<span class="number">.9</span>)</span><br></pre></td></tr></table></figure>
<pre><code>1.2815515655446004
</code></pre><p>因此，总体的大约80％置信区间意味着总体均值$\mu$在”样本均值 $\pm ~ 1.28\sigma/\sqrt{n}$”范围内。</p>
<p>让我们仔细校验，2是$z$的一个很好的取值，这意味着95％的置信区间。该$z$我们需要的是97.5％的点数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stats.norm.ppf(<span class="number">.975</span>)</span><br></pre></td></tr></table></figure>
<pre><code>1.959963984540054
</code></pre><p>那是$z = 1.96$，这就是我们一直使用的2。这个值已经足够了，但是$z = 1.96$也常用于构建95％置信区间。</p>
<h3 id="一般定义"><a href="#一般定义" class="headerlink" title="一般定义"></a>一般定义</h3><p>设$\lambda$是一个置信水平，令$z<em>\lambda$代表了这样一个分位数，使得正态曲线中，$(-z</em>\lambda, ~ z<em>\lambda)$包含了$\lambda$%区域。在上面的例子中，$\lambda$的值是80， $z</em>\lambda$的值是1.28。</p>
<p>当$n$足够大时，有</p>
<script type="math/tex; mode=display">
\frac{\lambda}{100} ~ \approx ~ 
P(\bar{X}_n \in \mu ~ \pm ~ z_\lambda \sigma/\sqrt{n}) ~ = ~
P(\mu \in \bar{X}_n ~ \pm ~ z_\lambda \sigma/\sqrt{n})</script><p>随机区间$\bar{X}<em>n ~ \pm ~ z</em>\lambda \sigma/\sqrt{n}$被称为<em>总体均值$\mu$的$\lambda$%置信区间</em>。这意味着，大约有$\lambda$%的概率，该随机区间包含$\mu$。</p>
<p>不同级别的置信区间之间的唯一区别是$z$的选择，这取决于置信水平。另外两个组成是样本均值和标准差。</p>
<h3 id="复习数据8中的示例"><a href="#复习数据8中的示例" class="headerlink" title="复习数据8中的示例"></a>复习数据8中的示例</h3><p>让我们回到数据8中非常熟悉的一个例子：1,174对母亲及其新生儿的随机样本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">baby = Table.read_table(<span class="string">&#x27;baby.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">baby</span><br></pre></td></tr></table></figure>
<p><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Birth Weight</th> <th>Gestational Days</th> <th>Maternal Age</th> <th>Maternal Height</th> <th>Maternal Pregnancy Weight</th> <th>Maternal Smoker</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>120         </td> <td>284             </td> <td>27          </td> <td>62             </td> <td>100                      </td> <td>False          </td>
        </tr>
    </tbody>
        <tr>
            <td>113         </td> <td>282             </td> <td>33          </td> <td>64             </td> <td>135                      </td> <td>False          </td>
        </tr>
    </tbody>
        <tr>
            <td>128         </td> <td>279             </td> <td>28          </td> <td>64             </td> <td>115                      </td> <td>True           </td>
        </tr>
    </tbody>
        <tr>
            <td>108         </td> <td>282             </td> <td>23          </td> <td>67             </td> <td>125                      </td> <td>True           </td>
        </tr>
    </tbody>
        <tr>
            <td>136         </td> <td>286             </td> <td>25          </td> <td>62             </td> <td>93                       </td> <td>False          </td>
        </tr>
    </tbody>
        <tr>
            <td>138         </td> <td>244             </td> <td>33          </td> <td>62             </td> <td>178                      </td> <td>False          </td>
        </tr>
    </tbody>
        <tr>
            <td>132         </td> <td>245             </td> <td>23          </td> <td>65             </td> <td>140                      </td> <td>False          </td>
        </tr>
    </tbody>
        <tr>
            <td>120         </td> <td>289             </td> <td>25          </td> <td>62             </td> <td>125                      </td> <td>False          </td>
        </tr>
    </tbody>
        <tr>
            <td>143         </td> <td>299             </td> <td>30          </td> <td>66             </td> <td>136                      </td> <td>True           </td>
        </tr>
    </tbody>
        <tr>
            <td>140         </td> <td>351             </td> <td>27          </td> <td>68             </td> <td>120                      </td> <td>False          </td>
        </tr>
    </tbody>
</table></p>
<p>... (1164 rows omitted)</p>



<p>第三栏包括母亲的年龄。让我们为总体中母亲的平均年龄构建大约95％的置信区间。我们在Data 8中使用bootstrap完成了这项工作，因此我们有了能够进行比较的结果。</p>
<p>因为我们的数据来自大型随机样本，我们可以应用本节的方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">1174</span></span><br><span class="line">ages = baby.column(<span class="string">&#x27;Maternal Age&#x27;</span>)</span><br><span class="line"></span><br><span class="line">samp_mean = np.mean(ages)</span><br><span class="line">samp_mean</span><br></pre></td></tr></table></figure>
<pre><code>27.228279386712096
</code></pre><p>可以发现样本的$\bar{X}_n$值是27.23。我们知道$n = 1174$，所以，我们需要总体的标准差$\sigma$然后就可以完成我们的计算。</p>
<p>但是，我们当然不知道总体的标准差$\sigma$。</p>
<p>所以，我们使用数据来估计$\sigma$，当然，这个估计存在一些误差，但它除以 $\sqrt{n}$后，误差会被缩小。请记住，我们的方法依赖于CLT，仅在$n$很大时有效。</p>
<p>$\sigma$的估计大约是5。82年。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sigma_estimate = np.std(ages)</span><br><span class="line">sigma_estimate</span><br></pre></td></tr></table></figure>
<pre><code>5.8153604041908968
</code></pre><p>一个总体的95%置信区间是$(26.89, 27.57)$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">samp_mean - <span class="number">2</span>*sigma_estimate/(n**<span class="number">0.5</span>), samp_mean + <span class="number">2</span>*sigma_estimate/(n**<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>
<pre><code>(26.888831911866099, 27.567726861558093)
</code></pre><p>不需要bootstrapping了! </p>
<p>现在让我们比较两种方法的结果。调用Data 8的<code>bootstrap_mean</code>方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bootstrap_mean</span>(<span class="params">original_sample, label, replications</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="string">&quot;&quot;&quot;Displays approximate 95% confidence interval for population mean.</span></span><br><span class="line"><span class="string">    original_sample: table containing the original sample</span></span><br><span class="line"><span class="string">    label: label of column containing the variable</span></span><br><span class="line"><span class="string">    replications: number of bootstrap samples</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    just_one_column = original_sample.column(label)</span><br><span class="line">    n = <span class="built_in">len</span>(just_one_column)</span><br><span class="line">    means = make_array()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(replications):</span><br><span class="line">        bootstrap_sample = np.random.choice(just_one_column, size=n)</span><br><span class="line">        resampled_mean = np.mean(bootstrap_sample)</span><br><span class="line">        means = np.append(means, resampled_mean)</span><br><span class="line">        </span><br><span class="line">    left = percentile(<span class="number">2.5</span>, means)</span><br><span class="line">    right = percentile(<span class="number">97.5</span>, means)</span><br><span class="line">    </span><br><span class="line">    resampled_means = Table().with_column(</span><br><span class="line">    <span class="string">&#x27;Bootstrap Sample Mean&#x27;</span>, means</span><br><span class="line">    )</span><br><span class="line">    resampled_means.hist(bins=<span class="number">15</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Approximate 95% confidence interval for population mean:&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(np.<span class="built_in">round</span>(left, <span class="number">2</span>), <span class="string">&#x27;to&#x27;</span>, np.<span class="built_in">round</span>(right, <span class="number">2</span>))</span><br><span class="line">    plt.plot(make_array(left, right), make_array(<span class="number">0</span>, <span class="number">0</span>), color=<span class="string">&#x27;yellow&#x27;</span>, lw=<span class="number">8</span>);</span><br></pre></td></tr></table></figure>
<p>让我们为总体平均值构建95％置信区间的bootstrap。我们将使用5000引导样本，就像我们在Data 8中所做的那样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bootstrap_mean(baby, <span class="string">&#x27;Maternal Age&#x27;</span>, <span class="number">5000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Approximate 95% confidence interval for population mean:
26.9 to 27.57
</code></pre><p><img src="/image/prob140/14_05_output_25_1.png" alt="png"></p>
<p>bootstrap置信区间与我们使用正态近似得到的区间（26.89,27.57）基本相同。</p>
<p>正如我们在数据8中所做的那样，我们观察到样本中母亲年龄的分布远非正态分布：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">baby.select(<span class="string">&#x27;Maternal Age&#x27;</span>).hist()</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/14_05_output_28_0.png" alt="png"></p>
<p>但是，样本均值的经验分布，显示为前一个单元格的输出，大致为钟形。这是因为由中心极限定理可得，大样本的平均值的概率分布是近似正态的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/29/ReMarkov/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/07/29/ReMarkov/" class="post-title-link" itemprop="url">【翻译活动】面向数据科学的概率论-11.反转马尔科夫链</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-07-29 17:54:27" itemprop="dateCreated datePublished" datetime="2018-07-29T17:54:27+08:00">2018-07-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-08-05 19:32:23" itemprop="dateModified" datetime="2018-08-05T19:32:23+08:00">2018-08-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BF%BB%E8%AF%91/" itemprop="url" rel="index"><span itemprop="name">翻译</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>原文：<a href="https://nbviewer.jupyter.org/github/prob140/textbook/blob/gh-pages/notebooks/Chapter_11/">prob140/textbook/notebooks/ch_11</a></p>
<p>译者：<a href="https://github.com/Yao544303">喵十八</a></p>
<p>协议：<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p>
<p>自豪地采用<a href="https://translate.google.cn/">谷歌翻译</a></p>
</blockquote>
<h1 id="本章所需python包"><a href="#本章所需python包" class="headerlink" title="本章所需python包"></a>本章所需python包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line"><span class="keyword">from</span> datascience <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> prob140 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">&#x27;fivethirtyeight&#x27;</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> misc</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line"><span class="keyword">from</span> datascience <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> prob140 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">&#x27;fivethirtyeight&#x27;</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> misc</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> permutations</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line"><span class="comment"># The alphabet</span></span><br><span class="line">alph = make_array(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;t&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line"><span class="comment"># Decode atdt using all possible decoders</span></span><br><span class="line">x1 = [[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;t&#x27;</span>], [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;d&#x27;</span>], [<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;t&#x27;</span>]]</span><br><span class="line">x2 = [[<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;a&#x27;</span>], [<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;d&#x27;</span>], [<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;a&#x27;</span>]]</span><br><span class="line">decoded = x1+x2</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line">decoding = Table().with_columns(</span><br><span class="line">    <span class="string">&#x27;Decoder&#x27;</span>, <span class="built_in">list</span>(permutations(alph)),</span><br><span class="line">    <span class="string">&#x27;atdt Decoded&#x27;</span>, decoded</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line"><span class="comment"># Make bigram transition matrix</span></span><br><span class="line"><span class="comment"># Data from Peter Norvig&#x27;s bigram table</span></span><br><span class="line"></span><br><span class="line">aa = <span class="number">1913489177</span></span><br><span class="line">dd = <span class="number">6513992572</span></span><br><span class="line">tt = <span class="number">19222971337</span></span><br><span class="line">ad = <span class="number">23202347740</span></span><br><span class="line">da = <span class="number">23279747379</span></span><br><span class="line">at = <span class="number">80609883139</span></span><br><span class="line">ta = <span class="number">42344542093</span></span><br><span class="line">dt = <span class="number">10976756096</span></span><br><span class="line">td = <span class="number">3231292348</span></span><br><span class="line"></span><br><span class="line">row1 = make_array(aa, ad, at)/<span class="built_in">sum</span>([aa, ad, at])</span><br><span class="line">row2 = make_array(da, dd, dt)/<span class="built_in">sum</span>([da, dd, dt])</span><br><span class="line">row3 = make_array(ta, td, tt)/<span class="built_in">sum</span>([ta, td, tt])</span><br><span class="line">rows = np.append(np.append(row1, row2), row3)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line">bigrams = MarkovChain.from_table(Table().states(alph).transition_probability(rows))</span><br></pre></td></tr></table></figure>
<h1 id="反转马尔科夫链"><a href="#反转马尔科夫链" class="headerlink" title="反转马尔科夫链"></a>反转马尔科夫链</h1><p>股票市场，变异病毒和计算机搜索引擎有什么共同之处？他们都使用马尔可夫链模型进行了分析。了解马尔可夫链的长期行为有助于我们理解许多不同的随机现象。</p>
<p>在数据科学中，马尔可夫链也用于完全不同的目的。马尔科夫链帮助数据科学家从对于标准采样方法来说太复杂的分布中抽取随机样本。马尔可夫链也可用于分布非常复杂或使用标准方法难以估计的未知量的近似值预估。这可以通过创建马尔可夫链来实现，该马尔可夫链具有作为其稳态分布的原型分布，然后长时间运行链直到它接近稳态。该方法称为马尔科夫链-蒙特卡洛法（Markov Chain Monte Carlo），缩写为MCMC。令人惊讶的是，它涉及了解马尔可夫链反向运行时会发生什么，也就是说当它们被<em>反转</em>时会发生什么。</p>
<p>要理解和实现MCMC算法，您必须研究马尔可夫链的可逆性并进行计算。在本章和随附的实验中，我们将简要介绍这一领域。</p>
<h2 id="详细的平衡"><a href="#详细的平衡" class="headerlink" title="详细的平衡"></a>详细的平衡</h2><p>我们一直在研究的马尔可夫链具有稳态分布，其中包含有关链的行为的大量信息。链的稳态分布是平衡方程的解。对于某些链，很容易得到平衡方程的解。但对于其他链条，求解过程可能很复杂或乏味。让我们看看我们是否能找到一种简单的方法来求解平衡方程。</p>
<p>回想一下我们早先关于方程中平衡态的描述。想象一下链的大量独立复制。例如，假设根据链的转移概率，大量粒子在状态间转移，所有粒子在时刻1, 2, 3, $\ldots$的转移都是相对独立的。</p>
<p>假设链处于稳态。正如我们之前所说，设$\pi(k)$为任意时刻离开状态$k$的粒子，那么平衡方程为</p>
<script type="math/tex; mode=display">
\pi(j) = \sum_{k \in S} \pi(k)P(k, j)</script><p>当离开状态$j$和进入它的粒子相同时，称链为平衡的。</p>
<p>请注意，左侧只是离开$j$的粒子的比例; 没有关于粒子去向的信息。</p>
<p>现在假设有<em>详细的平衡</em>，由下式给出</p>
<script type="math/tex; mode=display">
\pi(i)P(i, j) = \pi(j)P(j, i) ~~~ \text{for all states } i \ne j</script><p>这些被称为<em>详细平衡方程</em>。表示对于每一对状态$i$和$j$，离开状态 $i$进入状态$j$的粒子数量和离开状态$j$进入状态$i$的粒子数量一致。在状态$i = j$的情况下，方程无意义，因此被排除在外。</p>
<p>结果证明这是一个比平衡方程更强的条件。</p>
<h3 id="详细平衡意味着平衡"><a href="#详细平衡意味着平衡" class="headerlink" title="详细平衡意味着平衡"></a>详细平衡意味着平衡</h3><p>假设存在概率分布 $\pi$ 是详细平衡方程的解，那么$\pi$必然也是平衡方程的解。</p>
<script type="math/tex; mode=display">
\begin{align*}
\sum_{k \in S} \pi(k)P(k, j) &= \sum_{k \in S} \pi(j)P(j, k)  \text{(详细平衡方程)} \\
&= \pi(j) \sum_{k \in S} P(j, k) \\
&= \pi(j) \cdot 1  \text{(转移矩阵}j\text{th 行的和)} \\
&= \pi(j)
\end{align*}</script><p>我们从中学到的是，如果我们能够求解详细平衡方程，那么我们也能求解平衡方程。</p>
<p>这有两个原因：</p>
<ul>
<li>详细的平衡方程很简单。</li>
<li>详细平衡方程的数量很多，如果有$s$个状态，那么有$\binom{s}{2}$ 个详细平衡方程，包含$s$个未知变量。这为我们提供了许多尝试解决它们的方法。</li>
</ul>
<p>当然，所有这些$\binom{s}{2}$方程不是必须保持一致的，在这种情况下，这些平衡方程无解。在这种情况下，我们只能直接求解平衡方程。这里有一个例子表明，如果详细的平衡方程确实有解，我们就可以轻松地得到链的稳态分布。</p>
<h3 id="爱伦菲斯特链"><a href="#爱伦菲斯特链" class="headerlink" title="爱伦菲斯特链"></a>爱伦菲斯特链</h3><p>我们需要回到这个例子，因为它可以通过一些操作来求解平衡方程。我们将展示对于这个链和其他类似的链中，如何简便的求解详细的平衡方程，这为我们提供了一个快速求的稳态分布的途径。</p>
<p>状态空间是整数0到$N$。回想一下转移是如何进行的：在每一步，链条向前转移1个状态，保持不变，或者向后转移1个状态。这些链称为<em>生死</em>链，用于模拟许多随机模型，如赌徒的命运或人口规模。在我们的例子中，模拟了容器中气体粒子的数量。</p>
<p>对于这样的链，1-阶转移矩阵中，大多数转移概率是0，因为在一个步骤中链只能移动到两个相邻状态。所以大多数详细的平衡方程都是正确的。对于那些1-阶转移概率为正的两个状态$i$和$j$，两者之间的间隔必为1。（注意，详细平衡方程指定$i \ne j$）。在那种情况下，由于链不可约，$P(i, j)$和$P(j, i)$都为正。</p>
<p>这允许我们从最低状态开始向上移动来求解详细平衡方程。记住转移规则：</p>
<ul>
<li>在每个步骤中，从$N$中随机选取一个粒子，随意放入两个容器中的一个; 链计算容器1中的粒子数。</li>
</ul>
<p>详细的平衡方程式可以顺序求解：</p>
<script type="math/tex; mode=display">
\begin{align*}
\pi(0)\frac{1}{2} &= \pi(1)\frac{1}{2N} ~~ \implies ~~ \pi(1) = N\pi(0)
= \binom{N}{1}\pi(0) \\ \\
\pi(1)\frac{N-1}{2N} &= \pi(2)\frac{2}{2N} ~~ \implies ~~ \pi(2) = \frac{N-1}{2}\pi(1) = \frac{N(N-1)}{2}\pi(0) = \binom{N}{2}\pi(0) \\ \\
\pi(2)\frac{N-2}{2N} &= \pi(3)\frac{3}{2N} ~~ \implies ~~ \pi(3) = \frac{N-2}{3}\pi(2) = \frac{N(N-1)(N-2)}{3\cdot 2} \pi(0) = \binom{N}{3}\pi(0)
\end{align*}</script><p>等，从而对于$1 \le k \le N$,有</p>
<script type="math/tex; mode=display">
\pi(k) = \binom{N}{k} \pi(0)</script><p>通过比，归纳比求解平衡方程更容易。各项总和为</p>
<script type="math/tex; mode=display">
\pi(0)\big{(} 1 + \sum_{k=1}^N \binom{N}{k} \big{)}
= \pi(0)\sum_{k=0}^N \binom{N}{k}
= \pi(0)2^N</script><p>由二项式定理。所以$\pi(0) = 2^{-N}$并且稳态分布为二项分布$(N, 1/2)$.</p>
<p>在这一点上，值得记住的是对于数值 $N$，你可以使用<code>steady_state</code>来找到稳态分布。依靠Python来为你做所有的工作。这有一些明显的优点，但也有一些缺点：</p>
<ul>
<li>当$N$非常大时，Python无法处理计算。</li>
<li>你会看到分布是二项分布，但不知道是怎么得来的。</li>
</ul>
<p>这就是为什么即使在强大的个人计算机时代，找到使用数学解决问题的好方法仍然很重要。</p>
<h3 id="环形粘性随机漫步"><a href="#环形粘性随机漫步" class="headerlink" title="环形粘性随机漫步"></a>环形粘性随机漫步</h3><p>假设一个链在圆上顺时针顺序排列状态0,1,2,3,4。假设在每个步骤中保持在原位的概率为$s$，移动到逆时针邻居的概率为$p$，移动到顺时针邻居的概率为$r$。这里，$s$, $p$和 $r$都为正，且总和为1。</p>
<p>很明显，链的行为在五个状态中是对称的，因此从长远来看，预计在每个状态中花费的时间占比相同。状态上的稳态分布是均匀的。您也可以通过求解平衡方程来校验这一点。</p>
<p>让我们看看上述链是否满足详细的平衡方程。与上面的Ehrenfest链不同，这条链可以“环回”。所以不清楚是否满足详细的平衡方程。</p>
<p>详细的平衡方程是：</p>
<script type="math/tex; mode=display">
\begin{align*}
\pi(0)r = \pi(1)p ~~~~ \implies \pi(1) = \frac{r}{p}\pi(0) \\ 
\pi(1)r = \pi(2)p ~~~~ \implies \pi(2) = \frac{r^2}{p^2}\pi(0) \\ 
\pi(2)r = \pi(3)p ~~~~ \implies \pi(3) = \frac{r^3}{p^3}\pi(0) \\ 
\pi(3)r = \pi(4)p ~~~~ \implies \pi(4) = \frac{r^4}{p^4}\pi(0) 
\end{align*}</script><p>到目前为止一切都那么好，现在到了求解真相的关键：</p>
<script type="math/tex; mode=display">
\pi(4)r = \pi(0)p ~~~~ \implies \pi(4) = \frac{p}{r}\pi(0)</script><p>对于这个方程组，有解的前提是$\pi(4)$的两个表达式必须相等，也就是</p>
<script type="math/tex; mode=display">
\frac{r^4}{p^4} = \frac{p}{r}, ~~~ \text{that is, } ~r^5 = p^5</script><p>这只有在$r = p$时才会发生，在这种情况下，详细的平衡方程表示$\pi$ 的所有条目都是相等的，而这是已知的。</p>
<p>总结一下：</p>
<ul>
<li>在所有状态下，链的稳态分布是均匀的。均匀分布满足平衡方程。</li>
<li>当$r = p$, 详细的平衡方程有一个正解，即稳态分布。</li>
<li>当$r \ne p$详细的平衡方程没有概率分布作为解。</li>
</ul>
<p>显然，$r = p$ 有特殊的地位。这究竟对这个链的行为意味着什么？这是下一节的主题。目前，这里用于模拟链路径的两组参数：</p>
<ul>
<li><code>circle_walk_1</code>: $s = 0.1$, $r = 0.6$, $p = 0.3$</li>
<li><code>circle_walk_2</code>: $s = 0.1$, $r = 0.3$, $p = 0.6$</li>
</ul>
<p>保持原位的机会对于两者都是相同的，但顺时针和逆时针移动的机会已经切换。这是两条链的模拟路径。在图中，“顺时针”显示为向上移动，“逆时针”显示为向下移动。</p>
<p>查看路径（如果您愿意，可以模拟更多路径）并回答以下问题：</p>
<ul>
<li>哪一个有“向上”转移而不是“向下”？</li>
<li>如果有人向您展示了这两个流程之一的路径，但没有说明这两个流程中的哪一个，您能否确定是哪一个？</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">states = np.arange(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">s = <span class="number">0.1</span></span><br><span class="line">r = <span class="number">0.6</span></span><br><span class="line">p = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transition_prob</span>(<span class="params">i, j</span>):</span><br><span class="line">    <span class="keyword">if</span> i == j:</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line">    <span class="keyword">elif</span> j == (i+<span class="number">1</span>) % <span class="number">5</span>:</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line">    <span class="keyword">elif</span> j == (i-<span class="number">1</span>) % <span class="number">5</span>:</span><br><span class="line">        <span class="keyword">return</span> p</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">circle_walk_1 = MarkovChain.from_transition_function(states, transition_prob)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">circle_walk_1</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.3</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.3</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>0.1</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.6</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>0.1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">circle_walk_1.simulate_path(<span class="number">0</span>, <span class="number">50</span>, plot_path=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/11-1-output_8_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="number">0.1</span></span><br><span class="line">r = <span class="number">0.3</span></span><br><span class="line">p = <span class="number">0.6</span></span><br><span class="line"></span><br><span class="line">circle_walk_2 = MarkovChain.from_transition_function(states, transition_prob)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">circle_walk_2</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.6</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.6</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.6</td>
      <td>0.1</td>
      <td>0.3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.6</td>
      <td>0.1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">circle_walk_2.simulate_path(<span class="number">0</span>, <span class="number">50</span>, plot_path=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/11-2-output_11_0.png" alt="png"></p>
<h2 id="可逆性"><a href="#可逆性" class="headerlink" title="可逆性"></a>可逆性</h2><p>前一部分的随机漫步在环上顺时针顺序排列的状态0,1,2,3,4。在每个步骤中保持在原位的概率为$s$，移动到逆时针邻居的概率为$p$，移动到顺时针邻居的概率为$r$。链的稳态分布为每个状态的概率为0.2。</p>
<p>若$r &gt; p$, 那么链更可能顺时针方向而不是逆时针方向移动。例如，在稳态下，路径$0, 1, 2, 3$的概率为：</p>
<script type="math/tex; mode=display">
P(X_0 = 0)P(0, 1)P(1, 2)P(2, 3) = 0.2r^3</script><p>所述路径的<em>反转路径</em> $3, 2, 1, 0$ 的概率为</p>
<script type="math/tex; mode=display">
P(X_0 = 3)P(3, 2)P(2, 1)P(1, 0) = 0.2p^3</script><p>若 $r &gt; p$，那么原始路径的概率更高。</p>
<p>但如果$r = p$，那么原始路径与反向路径的概率相同; 在稳定状态下，链条可能朝任何一个方向上运行。如果某人在稳定状态下模拟链并向您显示原始路径以及反向路径，您将无法分辨哪个是哪个。</p>
<p>在本节中，我们将定义马尔科夫链以这种方式<em>可逆</em>的意义。</p>
<h3 id="反转过程"><a href="#反转过程" class="headerlink" title="反转过程"></a>反转过程</h3><p>设$X_0, X_1, \ldots $是一个定义在有限状态空间下，具有稳态分布$\pi$的不可约马尔可夫链。以这种稳态分布启动该链，也就是说，让$X_0$具有分布$\pi$。然后对于所有的$n \ge 1$，$X_n$的分布也是$\pi$。</p>
<p>修正，令$n &gt; 0$，并考虑<em>反向</em>序列$Y<em>0, Y_1, \ldots, Y_n$，其中$Y_k = X</em>{n-k}$， $k = 0, 1, \ldots, n$。称$X_0, X_1, \ldots, X_n$为<em>正向</em>序列。</p>
<p>反向序列是时间同质马尔可夫链的一个很好实例。为了了解原因，我们将检查马尔科夫性质是否成立。</p>
<p>在我们证明一般事实之前，让我们进行一些探索性的计算。从$n = 1$开始，此时有$Y_0 = X_1$ 和$Y_1 = X_0$。对于状态$i$和$j$。</p>
<script type="math/tex; mode=display">
\begin{align*}
P(Y_1 = j \mid Y_0 = i) ~ &= ~ \frac{P(Y_1 = j, Y_0 = i)}{P(Y_0 = i)} \\
&= ~ \frac{P(X_0 = j, X_1 = i)}{P(X_1 = i)} \\
&= ~ \frac{\pi(j)P(j, i)}{\pi(i)}
\end{align*}</script><p>因为正向序列处于稳定状态。我们已经使用转移矩阵和前向序列的稳态分布找到了反向序列的转移概率。</p>
<p>对于$n = 2$，我们有$Y_0 = X_2$，$Y_1 = X_1$， 和 $Y_2 = X_0$。对于状态$k$，$i$，和$j$</p>
<script type="math/tex; mode=display">
\begin{align*}
P(Y_2 = j \mid Y_0 = k, Y_1 = i) ~ &= ~ \frac{P(Y_2 = j, Y_1 = i, Y_0 = k)}{P(Y_1 = i, Y_0 = k)} \\
&= ~ \frac{P(X_0 = j, X_1 = i, X_2 = k)}{P(X_1 = i, X_2 = k)} \\
&= ~ \frac{\pi(j)P(j, i)P(i, k)}{\pi(i)P(i, k)} \\
&= ~ \frac{\pi(j)P(j, i)}{\pi(i)}
\end{align*}</script><p>解不依赖于$k$。这与马尔科夫性质保持一致。另外结合我们刚刚证明的两个事实，可以发现，转移概率是时间同质的。</p>
<p>对于更一般的$n$，修正状态$i$和$j$以及 0到$n-1$之间的整数$m$有</p>
<script type="math/tex; mode=display">
\begin{align*}
& P(Y_{m+1} = j \mid Y_0 = i_0, Y_1 = i_1, \ldots, Y_{m-1} = i_{m-1}, Y_m = i) \\ \\ 
&=
\frac{P(Y_0 = i_0, Y_1 = i_1 \ldots, Y_{m-1} = i_{m-1}, Y_m = i, Y_{m+1} = j)}
{P(Y_0 = i_0, Y_1 = i_1 \ldots, Y_{m-1} = i_{m-1}, Y_m = i)} \\ \\
&= \frac{P(X_n = i_0, X_{n-1} = i_1, \ldots, X_{n-m+1} = i_{m-1}, X_{n-m} = i, X_{n-m-1} = j)}
{P(X_n = i_0, X_{n-1} = i_1, \ldots, X_{n-m+1)} = i_{m-1}, X_{n-m} = i)} \\ \\
&= \frac{\pi(j)P(j, i)P(i, i_{m-1}) \cdots P(i_1, i_0)}
{\pi(i)P(i, i_{m-1}) \cdots P(i_1, i_0)} \\ \\
&= \frac{\pi(j)P(j, i)}{\pi(i)}
\end{align*}</script><p>这只涉及状态$i$和$j$，而和$i<em>0, i_1, \ldots, i</em>{m-1}$以及$m$无关。因此满足马尔可夫性质，转移概率是时间同质的。反向序列”状态$i$到状态$j$”的1-阶转移概率为</p>
<script type="math/tex; mode=display">
P(Y_1 = j \mid Y_0 = i) = \frac{\pi(j)P(j, i)}{\pi(i)}</script><h3 id="可逆链"><a href="#可逆链" class="headerlink" title="可逆链"></a>可逆链</h3><p>当原来的<em>正向</em>马尔科夫链$X_0, X_1, \ldots $中，对于每个$n$，其反向序列$Y_0, Y_1, \ldots Y_n$<em>的1-阶转移概率和原始序列一样</em>的情况，被称作是<em>可逆的</em>。也就是说</p>
<script type="math/tex; mode=display">
\frac{\pi(j)P(j, i)}{\pi(i)} = P(i, j) ~~~ \text{for all } i, j</script><p>如果链可逆，则有</p>
<script type="math/tex; mode=display">
\pi(i)P(i, j) = \pi(j)P(j, i) ~~~ \text{for all } i, j</script><p>换言之：</p>
<p><strong>如果详细的平衡方程具有正解，则链是可逆的。</strong> 这与我们在稳状下根据该链想象粒子的移动情况一致：在每个时刻，对于每一对状态$i$和$j$，粒子从$i$移动到$j$的比例与从$j$移动到$i$的比例完全相同。</p>
<p>在本节开始时，我们查看了一个环上的随机漫步。让我们看看可逆性的定义对于这个链是什么意思。</p>
<ul>
<li><p>在上一节中，我们展示了当 $p \ne r$时，详细的平衡方程没有正解。因此，当 $p \ne r$时，链条是不可逆的。这与我们之前的分析一致。</p>
</li>
<li><p>当$p = r$时，我们找到了详细平衡方程的解，因此链是可逆的。这形式化了我们的猜想，即如果$p = r$，那么在稳态下，链条“正向或者反向运行是一样的”。</p>
</li>
</ul>
<h3 id="生死链的可逆性"><a href="#生死链的可逆性" class="headerlink" title="生死链的可逆性"></a>生死链的可逆性</h3><p>回想一下，<em>生死链</em>是定义在整数上的马尔可夫链，其每一步的转移限制为增加1，减少1或者保持不变。不难校验具有有限状态空间的不可约的生死链是否可逆。您可以像我们在上一节中对Ehrenfest链所做的那样，通过求解详细的平衡方程来校验。</p>
<p>返回并查看文本和练习中的示例。切换链，反射随机漫步（包括懒惰和非懒惰的），Ehrenfest链和伯努利 - 拉普拉斯链都是不可简约的生死链，因此都是可逆的。</p>
<p>让我们在乍一看似乎不可逆转的生死链的情况下证实这一点。这是马尔可夫链 $X_0, X_1, \ldots $的转移图。</p>
<p><img src="/image/prob140/11-3-trans_b_and_d.png" alt="B&amp;D"></p>
<p>这条链以较高的概率向右移动（即生有孩子），所以看起来好像我们应该知道它是正向还是反向移动。但请记住，<em>时间逆转发生在稳态</em>。在稳态下，链条可能在状态3和4之间穿梭。您可以通过求解详细的平衡方程式来看到这一点。</p>
<script type="math/tex; mode=display">
\begin{align*}
\pi(1)\cdot 1 &= \pi(2) \cdot 0.1 ~~~~ \implies \pi(2) = 10\pi(1)  \\
\pi(2) \cdot 0.9 &= \pi(3) \cdot 0.1 ~~~~ \implies \pi(3) = 90\pi(1) \\
\pi(3) \cdot 0.9 &= \pi(4) \cdot 1 ~~~~~~~ \implies \pi(4) = 81\pi(1)
\end{align*}</script><p>它也将访问状态2和1，但很少，状态1特别罕见。这些访问将散布3和4中，并且这些路径将无法区分正向和反向移动。</p>
<p>让我们模拟这个过程的路径。首先，我们构造转移矩阵并确认我们$\pi$的计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">s = np.arange(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">trans</span>(<span class="params">i, j</span>):</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> i == <span class="number">4</span>:</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> j == i+<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.9</span></span><br><span class="line">    <span class="keyword">elif</span> j == i-<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">bnd = MarkovChain.from_transition_function(s, trans)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pi = bnd.steady_state()</span><br><span class="line">pi</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Value</th> <th>Probability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1    </td> <td>0.00549451 </td>
        </tr>
    </tbody>
        <tr>
            <td>2    </td> <td>0.0549451  </td>
        </tr>
    </tbody>
        <tr>
            <td>3    </td> <td>0.494505   </td>
        </tr>
    </tbody>
        <tr>
            <td>4    </td> <td>0.445055   </td>
        </tr>
    </tbody>
</table>



<p>我们可以使用<code>simulate_path</code>来绘制链的路径。请注意，与我们以前使用此方法不同，我们现在将初始分布作为第一个参数传递，而不是特定状态。第二个参数是步骤数，如前所述。</p>
<p>下图显示了一条长度为200的路径。运行单元格几次，并向前和向后查看每条路径。你不会发现两者之间的系统差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">n = <span class="number">200</span>                          <span class="comment"># the number of steps</span></span><br><span class="line">x = np.arange(n+<span class="number">1</span>)               <span class="comment"># the steps</span></span><br><span class="line">y = bnd.simulate_path(pi, n, plot_path=<span class="literal">True</span>)    <span class="comment"># the simulated state at each step</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Axis labels and title</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;$n$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;$X_n$&#x27;</span>, rotation=<span class="number">0</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Reversibility: Path of Birth and Death Chain in Steady State&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/11-4-output_11_0.png" alt="png"></p>
<h2 id="密码破解"><a href="#密码破解" class="headerlink" title="密码破解"></a>密码破解</h2><p>有趣的是，虽然许多马尔可夫链是可逆的，但到目前为止我们看到的例子并没有解释我们通过反转链条得到的结果。毕竟，如果它看起来像正向一样向前运行，为什么不向前运行呢？为什么要担心可逆性呢？</p>
<p>事实证明，逆转马尔可夫链可以帮助解决其他方法难以处理的一类问题。在本节中，我们将介绍如何出现此类问题的示例。在下一节中，我们将讨论一个解决方案。</p>
<h3 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h3><p>在网络安全成为我们生活的一部分之前，人们就已经对加密和解密非常感兴趣了。解码加密信息可能是复杂且计算密集的。逆转马尔可夫链可以帮助我们完成这项任务。</p>
<p>为了了解解决此类问题的方法以及问题的涉及范围，让我们尝试解码使用称为<em>替代代码</em>的简单代码加密的一小段文本。文本以字母表写，您可以将其视为一组字母和标点符号。在替换代码中，字母表中的每个字母简单地被另一个字母替换，使得代码只是字母表的排列。</p>
<p>要解码由替换代码加密的消息，您必须<em>反转</em>使用的排列。换句话说，您必须对<em>编码</em>消息应用置换以恢复原始文本。我们将这个置换称为<em>解码器</em>。</p>
<p>要解码文本消息，我们必须做出一些假设。例如，了解编写消息的语言，以及该语言中常见的字母组合。具体而言，就假设我们尝试解码用英语编写然后加密的消息。如果我们的解码过程以zzxtf和tbgdgaa之类的“单词”结束，我们可能想尝试不同的方式。</p>
<p>所以我们需要关于哪些字母序列是常见的数据。这些数据现在越来越容易收集; 例如由 <a href="http://norvig.com">Peter Norvig</a>, 一个谷歌的研究总监负责的<a href="http://norvig.com/ngrams/">网页</a></p>
<h3 id="解码信息"><a href="#解码信息" class="headerlink" title="解码信息"></a>解码信息</h3><p>让我们看看我们如何使用这种方法来解码消息。为简单起见，假设我们的字母表只包含三个字母a，d和t。现在假设我们得到编码消息atdt。我们相信这是一个英文单词。我们怎么能以一种可以被计算机重复的方式来解码呢？</p>
<p>作为第一步，我们将记下所有3！= 6个字母表中字母的可能排列，并使用每个字母对消息进行解码。该表<code>decoding</code>包含所有结果。<code>Decoder</code>中的每个条目都是一个排列，我们将应用于我们的编码文本atdt。确定我们将在解码过程中对哪些字母置换。</p>
<p>要了解如何执行此操作，请首先将字母“按字母顺序”的排序：’a’，’d’，’t’。现在看一下表格的行。</p>
<ul>
<li><p>第一行中的解码器是[‘a’，’d’，’t’]。这个解码器简单地保持字母不变; atdt被解码为atdt。 </p>
<script type="math/tex; mode=display">
\text{Decoder ['a', 'd', 't']: } ~~~ a \to a, ~~~ d \to d, ~~~ t \to t</script></li>
<li><p>第二行中的解码器是[‘a’，’t’，’d’]。这使得字母’a’的第一个字母保持不变，但将第二个字母’d’替换为’t’，将第三个字母’t’替换为’d’。</p>
<script type="math/tex; mode=display">
\text{Decoder ['a', 't', 'd']: } ~~~ a \to a, ~~~ d \to t, ~~~ t \to d</script><p>所以atdt被解码为adtd。</p>
</li>
</ul>
<p>您可以以相同的方式阅读表格的其余部分。. </p>
<p>请注意，在每个已解码的消息中，在索引1和3处出现相同字母。这是用于解码atdt中的t的字母。替换代码的一个特征是每个<em>字母原件</em>都用相同的字母进行<em>置换</em>，因而<em>字母原件</em>出现在文本中的位置都会替换为相同的<em>替换字母</em>。解码器必须具有相同的功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">decoding</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Decoder</th> <th>atdt Decoded</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>['a' 'd' 't']</td> <td>['a' 't' 'd' 't']</td>
        </tr>
    </tbody>
        <tr>
            <td>['a' 't' 'd']</td> <td>['a' 'd' 't' 'd']</td>
        </tr>
    </tbody>
        <tr>
            <td>['d' 'a' 't']</td> <td>['d' 't' 'a' 't']</td>
        </tr>
    </tbody>
        <tr>
            <td>['d' 't' 'a']</td> <td>['d' 'a' 't' 'a']</td>
        </tr>
    </tbody>
        <tr>
            <td>['t' 'a' 'd']</td> <td>['t' 'd' 'a' 'd']</td>
        </tr>
    </tbody>
        <tr>
            <td>['t' 'd' 'a']</td> <td>['t' 'a' 'd' 'a']</td>
        </tr>
    </tbody>
</table>



<p>我们应该使用哪一个解码器？为了做出这个决定，我们必须了解英语中单词中，字母串转移的频率。我们的目标是根据解码结果中字母串的转移频率选择解码器。</p>
<p>我们用汇总了英语中，一些<em>双字母</em>或两个字母组合频率的数据。这是一个被称为<code>bigrams</code>的转移矩阵，用于对英语中双字母的可用信息进行粗略简化; 我们使用了Peter Norvig的双字母表，并将其限制在我们的三个字母的字母表中。对应于字母’a’的行假定以’a’开头的大约2％的双字母是’aa’，大约22％是’ad’，剩下的76％是’at’。</p>
<p>“aa”组合是罕见的，这是有道理的; 我们不经常使用像aardvark这样的词。甚至2％看起来很大，直到你记得它只是’aa’，’ad’和’at’中’aa’的比例，因为我们限制了字母表。如果你看它在所有 $26\times26$ 中的比例，会低得多。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bigrams</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>a</th>
      <th>d</th>
      <th>t</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>a</th>
      <td>0.018099</td>
      <td>0.219458</td>
      <td>0.762443</td>
    </tr>
    <tr>
      <th>d</th>
      <td>0.570995</td>
      <td>0.159772</td>
      <td>0.269233</td>
    </tr>
    <tr>
      <th>t</th>
      <td>0.653477</td>
      <td>0.049867</td>
      <td>0.296656</td>
    </tr>
  </tbody>
</table>
</div>



<p>现在将真实文本视为具有此转移矩阵的马尔可夫链的路径。一个有趣的历史是，这就是马尔科夫第一次提出马尔科夫过程时所做的事情 - 他分析了亚历山大普希金的韵文小说，<em><a href="https://zh.wikipedia.org/wiki/%E5%8F%B6%E7%94%AB%E7%9B%96%E5%B0%BC%C2%B7%E5%A5%A5%E6%B6%85%E9%87%91">Eugene Onegin</a></em> 中元音和辅音之间的转移。</p>
<p>如果真实的文本是tada，那么我们可以将序列tada视为马尔可夫链的路径。其概率可以由$P(t)P(t, a)P(a, d)P(d, a)$计算。我们将根据这个概率给每个解码器一个分数。较高的分数对应于更好的解码器。</p>
<p>为了分配分数，我们假设所有三个字母都以相同的概率开始路径。对于字母表中的三个字母，这与事实并不相符（每个字母出现的概率并不相同，我们可以忽略这一因素）。这意味着每条路径的概率将以1/3的系数开始，我们所要做的就是对所有概率进行排名。我们将只计算$P(t, a)P(a, d)P(d, a)$，值约为 8%。</p>
<p>根据我们上面<code>decoding</code>的表格，tada是我们通过将解码器[‘t’，’d’，’a’]应用到我们的数据atdt得到的结果。现在，我们可以说<em>这个解码器在给定数据上的得分</em>是8％。稍后我们将介绍更正式的计算和术语。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># score of decoder [&#x27;t&#x27;, &#x27;d&#x27;, &#x27;a&#x27;]</span></span><br><span class="line"><span class="number">0.653477</span> * <span class="number">0.219458</span> * <span class="number">0.570995</span></span><br></pre></td></tr></table></figure>
<pre><code>0.08188682431730866
</code></pre><p>为了自动化这种计算，我们可以使用<code>prob_of_path</code>方法。请记住，它的第一个参数是初始状态，第二个参数是由序列中剩余状态组成的列表或数组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bigrams.prob_of_path(<span class="string">&#x27;t&#x27;</span>, [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>])</span><br></pre></td></tr></table></figure>
<pre><code>0.081886816291942444
</code></pre><p>我们是否应该决定将我们的消息atdt解码为tada？如果我们认为8％的可能性很高，那么答案为是。但，如果其他的解码器具有更高的可能性呢？在那种情况下，当然选择得分高的。</p>
<p>因此，我们需要全部六个“解码器”路径中的概率。</p>
<p>让我们定义一个函数<code>score</code>，它将获取一个列表或一组字符，并使用<code>bigrams</code>转移矩阵返回相应路径的概率。在我们的示例中，这与返回相应解码器的分数相同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> bigrams.prob_of_path(x[<span class="number">0</span>], x[<span class="number">1</span>:])</span><br></pre></td></tr></table></figure>
<p>以下是按分数降序排列的结果。有一个明显的赢家：对应于消息’data’的解码器[‘d’，’t’，’a’]的分数是任何其他解码器的两倍以上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decoding = decoding.with_column(<span class="string">&#x27;Score of Decoder&#x27;</span>, decoding.apply(score, <span class="number">1</span>))</span><br><span class="line">decoding.sort(<span class="string">&#x27;Score of Decoder&#x27;</span>, descending=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Decoder</th> <th>atdt Decoded</th> <th>Score of Decoder</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>['d' 't' 'a']</td> <td>['d' 'a' 't' 'a']</td> <td>0.284492        </td>
        </tr>
    </tbody>
        <tr>
            <td>['d' 'a' 't']</td> <td>['d' 't' 'a' 't']</td> <td>0.134142        </td>
        </tr>
    </tbody>
        <tr>
            <td>['t' 'd' 'a']</td> <td>['t' 'a' 'd' 'a']</td> <td>0.0818868       </td>
        </tr>
    </tbody>
        <tr>
            <td>['a' 'd' 't']</td> <td>['a' 't' 'd' 't']</td> <td>0.0102363       </td>
        </tr>
    </tbody>
        <tr>
            <td>['t' 'a' 'd']</td> <td>['t' 'd' 'a' 'd']</td> <td>0.00624874      </td>
        </tr>
    </tbody>
        <tr>
            <td>['a' 't' 'd']</td> <td>['a' 'd' 't' 'd']</td> <td>0.00294638      </td>
        </tr>
    </tbody>
</table>



<h3 id="问题的规模"><a href="#问题的规模" class="headerlink" title="问题的规模"></a>问题的规模</h3><p>当字母表较大时，我们在三个字符的字母表上做的工作，将会变得非常可怕。52个小写字母和大写字母，以及空格字符和所有标点，形成一个大约70个字符的字母表。这给了我们70！不同的解码器需要考虑。理论上，我们必须找到这70！个中每一个的可能性和并将他们排序。</p>
<p>这是70！个解码器。我们的计算系统无法处理那么多，其他系统也会遇到同样的问题。</p>
<p>下面计算了70！的值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">math.factorial(<span class="number">70</span>)</span><br></pre></td></tr></table></figure>
<pre><code>11978571669969891796072783721689098736458938142546425857555362864628009582789845319680000000000000000
</code></pre><p>一个可能的解决方案是从这70！个可能的解码器中随机采样，然后只从采样的排序中进行挑选。但是我们如何从70！中进行采样？根据字母表，均匀随机采样并不是一个好主意，因为那不太可能让我们快速获得理想解决方案。</p>
<p>我们希望的采样程序，能够选择具有高概率的良好解码器。好的解码器生成的文本几乎比所有其他解码器生成的文本具有更高概率。换句话说，给定数据，良好的解码器比其他解码器具有更高的可能性。</p>
<p>您可以使用贝叶斯规则记下这种可能性。让 $S$代表所有可能排列的空间; 如果字母表有 $N$字符，然后$S$有$N!$个元素。对于任何随机挑选的排列$j$，给出数据的解码器的概率是：</p>
<script type="math/tex; mode=display">
\begin{align*}
\text{Likelihood of } j \text{ given the encoded text}
&= \frac{\frac{1}{N!} P(\text{encoded text} \mid \text{decoder = }j)}
{ {\sum_{i \in S} } \frac{1}{N!} P(\text{encoded text} \mid \text{decoder = }i)} \\ \\
&=\frac{P(\text{encoded text} \mid \text{decoder = }j)}
{ {\sum_{i \in S} } P(\text{encoded text} \mid \text{decoder = }i)}
\end{align*}</script><p>对于给定的编码文本，分母是使所有似然性总和为1的归一化常数项。它出现在每个解码器的可能性中。在我们使用三个字母字母表的示例中，我们忽略了它，因为我们可以找出所有六个解码器的分子并且只是比较它们。分子就是我们称之为解码器的<em>分数</em>。</p>
<p>即使字母表很大，对于任何特定的解码器 $j$我们可以通过转移概率顺序相乘计算得到分子，就像我们在我们的例子中所做的那样。但是对于所有可能的解码器，我们无法对全量解码器执行此操作，因此我们无法列出所有可能的分数，我们无法对他们求和。因此，我们不知道可能性的分母，甚至找不到合适的近似值。</p>
<p>我们现在需要的是一种方法，即使我们不知道归一化常数，也可以从概率分布中得出一个近似解。这就是Markov Chain Monte Carlo帮助我们做的事情。</p>
<h2 id="马尔可夫链蒙特卡罗法"><a href="#马尔可夫链蒙特卡罗法" class="headerlink" title="马尔可夫链蒙特卡罗法"></a>马尔可夫链蒙特卡罗法</h2><p>马尔可夫链蒙特卡罗（MCMC）的目标是从复杂的高维分布中生成随机样本，这种情况下，我们的信息不完整。例如，我们可能不知道分布的归一化常量，正如我们在上一节的示例中看到的那样。</p>
<p>比如我们想根据分布$\pi$生成样本。我们就假设$\pi$是一个非常巨大有限集上的概率分布。MCMC依赖于较少的采样值。</p>
<ul>
<li><p>设$X_0, X_1, \ldots $是一个定义在有限空间上的不可约非周期性马尔科夫链。那么，当$n$变大时，$X_n$的分布趋向于稳态。如果我们可以创建一个稳态分布为$\pi$ 的马尔科夫链${X_n}$ ，那么我们使用对于一个较大值$n$的 $X_n$，来长期运行链条，从而模拟$\pi$（或其近似值）。</p>
</li>
<li><p>构建一个使得最终稳态分布为$\pi$的转移矩阵的最简单的方式是保证详细平衡方程有解。换言之，最简单的方法是尝试创建一个可逆链。</p>
</li>
<li><p>如果链是可逆的，那么详细平衡方程可以改写为：</p>
</li>
</ul>
<script type="math/tex; mode=display">
\frac{\pi(j)}{\pi(i)} = \frac{P(i, j)}{P(j, i)}</script><p>右侧只涉及我们想要创建的链的转移概率。左侧仅涉及$\pi$中的项的比率。因此，即使我们不知道使$\pi$归一化的常数，也可以得到校验。</p>
<h3 id="Metropolis-算法"><a href="#Metropolis-算法" class="headerlink" title="Metropolis 算法"></a>Metropolis 算法</h3><p>究竟是谁第一个提出了相关算法来创建这样的马尔可夫链存在一定争议。黑斯廷斯提出了一般版本。在这里，我们将描述于1953年由Metropolis和共同作者提出的早期版本。</p>
<p>目标是创建一个转移矩阵 $\mathbb{P}$，使得$\pi$和$\mathbb{P}$能一起求解详细平衡方程。</p>
<p>该算法基于任意的对称转移矩阵$Q$，该矩阵会在状态空间上创建一个不可约的非周期性链。例如，如果状态空间是数值，你可以用“无论链条，它选择三个最接近的值（包括自身，每个的概率都是$1/3$）中的一个”开始链。对于一对状态$i$和$j$，转移概率$Q(i, j)$被称为<em>提议概率</em>。</p>
<p>以下是确定新链转移的步骤。</p>
<ul>
<li><p>假设连载时刻$n$时为状态$i$，即$X_n = i$。根据提议概率$Q(i, j)$选择一个状态$j$。这个$j$是链可能的目的状态。</p>
</li>
<li><p>定义<em>接受概率</em>如下</p>
<script type="math/tex; mode=display">
r(i, j) = \frac{\pi(j)}{\pi(i)}</script></li>
<li><p>如果 $r(i, j) \ge 1$, 则 $X_{n+1} = j$.</p>
</li>
<li><p>如果 $r(i, j) &lt; 1$, 通过抛硬币的方式，随机选择$r(i, j)$。 </p>
<ul>
<li>如果硬币正面向上，则 $X_{n+1} = j$. </li>
<li>如果硬币反面向上，则 $X_{n+1} = i$.</li>
</ul>
</li>
<li>以 $X_{n+1}$为起始值，重复所有步骤。</li>
</ul>
<p>因此，新链要么移动到$Q$，要么保持原样。我们说它基于$Q$和$r$<em>接受移动到新状态</em>，否则它不动。</p>
<p>因为提案链是不可约的，新的链条也是不可约的。因为它可以保持原位，所以它是非周期性的。因此它具有稳态分布。算法表示这种稳态分布与$\pi$相同，即我们定义的$r(i, j)$。</p>
<h3 id="算法的相关思考"><a href="#算法的相关思考" class="headerlink" title="算法的相关思考"></a>算法的相关思考</h3><p>在我们证明算法有效之前，让我们先来看看它在解码器环境中的作用。</p>
<p>首先注意$Q$是对称的，也是不可约的。对称性要求是有意义的，因为每个详细的平衡方程涉及转移$i \to j$和$j \to i$。</p>
<p>修正启动的解码器并将其命名为$i$。现在你必须决定链接下一步的位置，即下一个解码器是什么。由该程序启动的算法，在根据$Q$选择了一个$j$之后会关闭。我们称之为<em>$Q$ 建议移动到$j$</em>。</p>
<p>分布$\pi$包含所有解码器的可能性，决定链是否应移至$j$的根本因素是希望最终得到具有高可能性的解码器，因此需要比较$\pi(i)$和$\pi(j)$。</p>
<p>该算法通过比较<em>接受比率</em> $r(i, j) = \pi(j)/\pi(i)$ 和 1 之间的大小。</p>
<ul>
<li><p>如果$r(i, j) \ge 1$，那么$j$的概率至少和$i$一样大，所以你<em>接受提议</em>并且移动到$j$。 </p>
</li>
<li><p>如果$r(i, j) &lt; 1$,那么建议的解码器$j$的可能性比当前的$i$要<em>小</em>，所以暂时先保持在$i$。但这可能会使链条陷入局部最大值。该算法通过抛硬币（随机选择）提供了避免这种情况的机会。如果硬币为反面，即使$j$比当前具有<em>更低</em>的可能性，链条移动到$j$。我们的想法是，从这个新位置开始，可能存在解码器的路径，这些解码器具有最高的可能性。</p>
</li>
</ul>
<h3 id="算法实践"><a href="#算法实践" class="headerlink" title="算法实践"></a>算法实践</h3><p>我们现在将表明由Metropolis算法创建的链的详细平衡方程，是如何通过期望$\pi$和转移矩阵$\mathbb{P}$求解的。</p>
<p>选择任意两个状态$i$和$j$</p>
<h4 id="案例-1-pi-i-pi-j"><a href="#案例-1-pi-i-pi-j" class="headerlink" title="案例 1: $\pi(i) = \pi(j)$"></a>案例 1: $\pi(i) = \pi(j)$</h4><p>当$r(i, j) = 1$。通过算法和$Q$的对称性，有$P(i, j) = Q(i, j)$和$P(j, i) = Q(j, i) = Q(i, j)$。</p>
<p>因此，$P(i, j) = P(j, i)$，满足详细平衡方程$\pi(i)P(i, j) = \pi(j)P(j, i)$。</p>
<h4 id="案例-2-pi-j-lt-pi-i"><a href="#案例-2-pi-j-lt-pi-i" class="headerlink" title="案例 2: $\pi(j) &lt; \pi(i)$"></a>案例 2: $\pi(j) &lt; \pi(i)$</h4><p>当 $r(i, j) &lt; 1$，有</p>
<script type="math/tex; mode=display">
P(i, j) ~=~ Q(i, j)r(i, j) 
~=~ Q(j, i)\frac{\pi(j)}{\pi(i)} ~~~ \text{(symmetry of } Q \text{ and definition of }r)</script><p>此时 $r(j, i) &gt; 1$，则根据算法有 $P(j, i) = Q(j, i)$。</p>
<p>因此</p>
<script type="math/tex; mode=display">
P(i, j) ~ = ~ P(j, i)\frac{\pi(j)}{\pi(i)}</script><p>这与下面是一样的</p>
<script type="math/tex; mode=display">
\pi(i)P(i, j) ~ = ~ \pi(j)P(j, i)</script><h4 id="案例-3-pi-j-gt-pi-i"><a href="#案例-3-pi-j-gt-pi-i" class="headerlink" title="案例 3: $\pi(j) &gt; \pi(i)$"></a>案例 3: $\pi(j) &gt; \pi(i)$</h4><p>交换案例 2 中$i$和$j$的角色。 </p>
<p>以上就是！一个简单而出色的想法，为困难问题提供解决方案。在实验中，当您实现解码文本的算法时，您将看到它的实际效果。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/29/Markov/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/07/29/Markov/" class="post-title-link" itemprop="url">【翻译活动】面向数据科学的概率论-10.马尔科夫链</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-07-29 17:54:22" itemprop="dateCreated datePublished" datetime="2018-07-29T17:54:22+08:00">2018-07-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-08-05 19:32:39" itemprop="dateModified" datetime="2018-08-05T19:32:39+08:00">2018-08-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BF%BB%E8%AF%91/" itemprop="url" rel="index"><span itemprop="name">翻译</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>原文：<a href="https://nbviewer.jupyter.org/github/prob140/textbook/blob/gh-pages/notebooks/Chapter_10/">prob140/textbook/notebooks/ch_10</a></p>
<p>译者：<a href="https://github.com/Yao544303">喵十八</a></p>
<p>协议：<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p>
<p>自豪地采用<a href="https://translate.google.cn/">谷歌翻译</a></p>
</blockquote>
<h1 id="术语说明"><a href="#术语说明" class="headerlink" title="术语说明"></a>术语说明</h1><p><em>条件概率分布</em>（Conditional Probability Distribution，或者<em>条件分布</em>，Conditional Distribution）是现代概率论中的概念：已知两个相关的随机变量X和Y，随机变量Y在条件{X=x}下的条件概率分布是指当已知X的取值为某个特定值x之时，Y的概率分布。 如果Y在条件{X=x}下的条件概率分布是连续分布，那么其密度函数称作Y在条件{X=x}下的条件概率密度函数（条件分布密度、条件密度函数）。与条件分布有关的概念，常常以“条件”作为前缀，如条件期望、条件方差等等。</p>
<p><em>转移</em> 与<em>转移概率</em>：从状态1变为状态2，称之为状态转移，其对应的概率称之为转移概率。</p>
<p><em>可数无穷</em>：是指集合中的元素可以与自然数一一对应,也就是说可以用自然数来”数”它的数量,从而其数量为可数无穷. </p>
<h1 id="本章所需python包"><a href="#本章所需python包" class="headerlink" title="本章所需python包"></a>本章所需python包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line"><span class="keyword">from</span> datascience <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> prob140 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">&#x27;fivethirtyeight&#x27;</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> misc</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HIDDEN</span></span><br><span class="line">s = np.arange(<span class="number">1</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">refl_walk_probs</span>(<span class="params">i, j</span>):</span><br><span class="line">    <span class="comment"># staying in the same state</span></span><br><span class="line">    <span class="keyword">if</span> i-j == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># moving left or right</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">2</span> &lt;= i &lt;= <span class="number">4</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(i-j) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.25</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># moving right from 1</span></span><br><span class="line">    <span class="keyword">elif</span> i == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.5</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># moving left from 5</span></span><br><span class="line">    <span class="keyword">elif</span> i == <span class="number">5</span>:</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.5</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">reflecting_walk = MarkovChain.from_transition_function(s, refl_walk_probs)</span><br></pre></td></tr></table></figure>
<h1 id="马尔科夫链"><a href="#马尔科夫链" class="headerlink" title="马尔科夫链"></a>马尔科夫链</h1><p>一个 <em>随机过程</em> 是某一概率空间（这里的空间，理解为域更合适，是指一系列随机状态的合集。不是与时间相对的空间，后面的时间也类似）中一系列随机状态的集合。我们将研究一种在<em>离散时间</em>域内演化过程，即有如下随机状态 $X_0, X_1, X_2, \ldots $。想象一下，从时刻0的状态 $X_0$ 开始,不断执行对应时间的操作，状态随之转移。以此类推，在时刻$n$ 时，转移为状态 $n$。</p>
<p>我们已经见过这种过程的例子。例如伯努利实验中，一系列的抛硬币事件构成的独立同分布的序列，就形成这样的过程。每次事件在0和1两个值之间来回传递，每个值都独立于所有其他值。但在许多有趣的过程中，未来的事件的值依赖于当前事件的值，以及过去事件的值。我们可以使用过去和现在来预测未来。</p>
<p>马尔科夫链，是以<a href="https://en.wikipedia.org/wiki/Andrey_Markov">安德烈·马尔科夫</a>的名字命名的一类随机过程。一个非正式的描述如下，对于马尔科夫链而言，将来的状态的值只取决于当前状态的值，而与如何达到当前状态的值无关。这被称为<em>马尔科夫性质</em>。从形式上看</p>
<ul>
<li>对于任一$n \ge 1$， $X_{n+1}$ 的条件分布，只取决于 $X_0, X_1, \ldots , X_n$中的$X_n$</li>
<li>也就是说，对于每一个可能值的序列$i<em>0, i_1, \ldots, i_n, i</em>{n+1}$,</li>
</ul>
<script type="math/tex; mode=display">P(X_{n+1} = i_{n+1} \mid X_0 = i_0, X_1 = i_1 , \ldots, X_{n-1} = i_{n-1}, X_n = i_n) = P(X_{n+1} = i_{n+1} \mid X_n = i_n)</script><p>例如在一个随机漫步试验中，赌徒以a美元的财富开始，然后连续投掷一枚公平的硬币（正反面概率都为50%）。如果硬币为正面，他就获得1美元，如果是反面，他就输掉1美元。<br>设$X<em>{0} = a$，则$n &gt; 0$令$X</em>{n+1} = X_n + I_n$，其中$I_1, I_2, \ldots $是伯努利实验中的独立同分布序列。马尔科夫性质适用于整个过程：给出赌徒在时刻$n$的财富数，那他在时刻$n+1$时的财富数的取值只与其在时刻$n$时的财富数有关，与$n$之前无关。所以该过程$X_0, X_1, X_2, \ldots $是一个马尔科夫链，代表着赌徒的财富随时间的演变。</p>
<p>马尔可夫链的<em>状态空间</em>是链中状态可能值的集合。上述随机漫步的状态空间是所有整数的集合。在本课程中，我们将状态空间限制为离散且有限的。</p>
<h3 id="条件独立"><a href="#条件独立" class="headerlink" title="条件独立"></a>条件独立</h3><p>两个随机变量$X$和$Y$是相互独立是指，$X$处于条件$Y$的情况的条件分布和不处于$Y$的情况下的条件分布是一致的。<br>随机变量$X$和$Y$<em>相对于$Z$条件独立</em> 是指，$X$在条件$Y$和$Z$的情况下的条件分布和在条件$Z$的情况下的条件分布式一致。也就是说，$Z$这一关于$Y$的额外条件，不会影响$X$的值。</p>
<p>在马尔可夫链中，如果定义时刻$n$为现在，定义时刻$n+1$为未来，时刻序列$0$到$n-1$作为过去，马尔科夫性质意味着过去和未来是条件独立的。</p>
<h2 id="转移"><a href="#转移" class="headerlink" title="转移"></a>转移</h2><p>设$X_0, X_1, X_2, \ldots $为状态空间$S$中马尔科夫链。根据马尔科夫性质，有限长度的<em>路径</em>或<em>轨迹</em>的概率如下：</p>
<script type="math/tex; mode=display">
\begin{align*}
& P(X_0 = i_0, X_1 = i_1, X_2 = i_2, \ldots, X_n = i_n) \\
& = ~ 
P(X_0 = i_0)P(X_1 = i_1 \mid X_0 = i_0)P(X_2 = i_2 \mid X_1 = i_1) \cdots
P(X_n = i_n \mid X_{n-1} = i_{n-1})
\end{align*}</script><p>上式中的条件概率，也被称为<em>转移概率</em>。对于状态$i$和$j$，条件概率$P(X_{n+1} = j \mid X_n = i)$被称为<em>时刻$n$时的一阶转移概率</em>。</p>
<p>对于许多链，例如随机漫步，这些一阶转移概率仅仅由状态$i$和$j$决定，而与时刻$n$无关。<br>示例：</p>
<script type="math/tex; mode=display">
\begin{equation}
P(X_{n+1} = j \mid X_n = i) = 
 \begin{cases} 
      \frac{1}{2} & \text{if } j = i-1 \text{ or } j = i+1 \\
      0 & \text{ otherwise}
   \end{cases}
\end{equation}</script><p>对所有的$n$都与时刻无关。 </p>
<h3 id="固定转移概率"><a href="#固定转移概率" class="headerlink" title="固定转移概率"></a>固定转移概率</h3><p>当一阶转移概率与时刻$n$无关时，称之为<em>固定</em>或者<em>时间同质</em>的。我们将在本课程中学习的所有马尔可夫链都具有时间同质的转移概率。<br>对于这样的链，定义<em>一阶转移概率</em>如下：  </p>
<script type="math/tex; mode=display">
P(i, j) ~ = ~ P(X_{n+1} = j \mid X_n = i) ~ = ~ P(X_1 = j \mid X_0 = i)</script><p>Then</p>
<script type="math/tex; mode=display">
P(X_0 = i_0, X_1 = i_1, X_2 = i_2, \ldots, X_n = i_n)
~ = ~ P(X_0 = i_0)P(i_0, i_1)P(i_1, i_2) \cdots P(i_{n-1}, i_n)</script><p>一阶转移概率可以表示为矩阵的元素。这不仅仅是为了符号的紧凑-它导致了一个强大的理论。</p>
<h3 id="一阶转移矩阵"><a href="#一阶转移矩阵" class="headerlink" title="一阶转移矩阵"></a>一阶转移矩阵</h3><p>链的<em>一阶转移矩阵</em>描述如下，矩阵$\mathbb{P}$，其中$(i, j)$位置处的元素是$P(i, j) = P(X_1 = j \mid X_0 = i)$。</p>
<p>通常，$\mathbb{P}$简称为<em>转移矩阵</em>。注意两个重要属性：</p>
<ul>
<li>$\mathbb{P}$是一个正方形矩阵: 它的行和列都由状态空间索引构成。</li>
<li>$\mathbb{P}$的每一行: 对任一状态$i$, 和时刻$n$, 行$i$ 包含了在$X<em>n = i$ 情况下，$X</em>{n+1}$的条件分布。 因为它的每一行的和都为1， $\mathbb{P}$ 也被称为 <em>随机矩阵</em>.</li>
</ul>
<p>让我们看一下示例中转移矩阵的样子。 </p>
<h3 id="粘性反转随机漫步"><a href="#粘性反转随机漫步" class="headerlink" title="粘性反转随机漫步"></a>粘性反转随机漫步</h3><p>通常，马尔可夫链的转移行为更容易在<em>转移图</em>而不是矩阵中描述。下面是状态1,2,3,4和5上的链的转移图。该图显示了一阶转移概率。</p>
<ul>
<li>如果链条处于任何状态，它移动到原有状态的概率为0.5。</li>
<li>如果链处于状态2到4，则它移动到其两个相邻状态中的一个的概率为0.25。</li>
<li>如果链处于状态1或5，则它移动到其相邻状态的概率为0.5。</li>
</ul>
<p><img src="/image/prob140/10-1-trans_refl.png" alt="Reflecting Lazy Walk"></p>
<p>我们称其为<em>反转</em>是在状态1和5可以反转掉头进行转移。整个漫步过程有<em>粘性</em>是指其可能移动到原有状态。</p>
<p>转移图非常适合理解链移动的规则。但是，对于计算，转移矩阵更有帮助。</p>
<p>要开始构造矩阵，我们将数组<code>s</code>设置为状态集，并为转移函数<code>refl_walk_probs</code> 设置成入参为$i$和$j$，返回值为$P(i, j)$的形式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">s = np.arange(<span class="number">1</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">refl_walk_probs</span>(<span class="params">i, j</span>):</span><br><span class="line">    <span class="comment"># staying in the same state</span></span><br><span class="line">    <span class="keyword">if</span> i-j == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># moving left or right</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">2</span> &lt;= i &lt;= <span class="number">4</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(i-j) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.25</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># moving right from 1</span></span><br><span class="line">    <span class="keyword">elif</span> i == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.5</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># moving left from 5</span></span><br><span class="line">    <span class="keyword">elif</span> i == <span class="number">5</span>:</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.5</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>您可以使用<code>prob140</code>库来构造<code>MarkovChain</code>对象。<code>from_transition_function</code>方法有两个参数：</p>
<ul>
<li>状态构成的数组</li>
<li>转移函数</li>
</ul>
<p>并显示<code>MarkovChain</code>对象的一阶转移矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk = MarkovChain.from_transition_function(s, refl_walk_probs)</span><br><span class="line">reflecting_walk</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>0.50</td>
    </tr>
  </tbody>
</table>
</div>



<p>比较转移矩阵$\mathbb{P}$和转移图，并确认它们包含的有关转移概率的信息一致。</p>
<p>为了找到从状态$i$转移到$j$的概率，只需找矩阵$i$行$j$列的值即可。</p>
<p>如果您知道起始状态，则可以使用$\mathbb{P}$找到任何有限路径的概率。例如，假设从1开始，那么它具有路径[2,2,3,4,3]的概率是</p>
<script type="math/tex; mode=display">
P(1, 2)P(2, 2)P(2, 3)P(3, 4)P(4, 3) \approx 0.4\%</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.5</span> * <span class="number">0.5</span> * <span class="number">0.25</span> * <span class="number">0.25</span> * <span class="number">0.25</span></span><br></pre></td></tr></table></figure>
<pre><code>0.00390625
</code></pre><p><code>MarkovChain</code>对象的<code>prob_of_path</code>方法可以省去写乘法的麻烦。它将起始状态和路径的其余部分（在列表或数组中）作为其参数，并返回路径的概率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.prob_of_path(<span class="number">1</span>, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<pre><code>0.00390625
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.prob_of_path(<span class="number">1</span>, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>0.0
</code></pre><p>您可以使用<code>simulate_path</code>方法模拟链的路径。它有两个参数：起始状态和路径的步数。默认情况下，它返回一个由路径中的状态序列组成的数组。可选参数<code>plot_path=True</code>绘制模拟路径。运行几次下面的单元格，看看输出如何变化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.simulate_path(<span class="number">1</span>, <span class="number">7</span>)</span><br></pre></td></tr></table></figure>
<pre><code>array([1, 2, 1, 2, 2, 2, 3, 2])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.simulate_path(<span class="number">1</span>, <span class="number">10</span>, plot_path=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/10-2-output.png" alt="png"></p>
<h3 id="n-阶转移矩阵"><a href="#n-阶转移矩阵" class="headerlink" title="$n$-阶转移矩阵"></a>$n$-阶转移矩阵</h3><p>对于状态$i$和$j$, 耗费$n$步，从状态$i$转移为状态$j$的可能性，称为从$i$到$j$的$n$-阶转移概率。 形式上定义为：</p>
<script type="math/tex; mode=display">
P_n(i, j) ~ = ~ P(X_n = j \mid X_0 = i)</script><p>在这种表示方法中，一阶转移概率$P(i, j)$也可以写作$P_1(i, j)$。</p>
<p>$n$-阶转移概率$P_n(i, j)$可以使用$n$-阶转移矩阵$(i, j)$位置处的元素表示。对于任意状态$i$，$n$-阶转移矩阵的第$i$行包含了从状态$i$开始的链的条件分布$X_n$</p>
<p> <code>MarkovChain</code>的<code>transition_matrix</code>方法，使用$n$作为入参，并返回一个$n$-阶转移矩阵。以下是本节前面定义的粘性反转随机漫步的两阶转移矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.transition_matrix(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.3750</td>
      <td>0.5000</td>
      <td>0.125</td>
      <td>0.0000</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.2500</td>
      <td>0.4375</td>
      <td>0.250</td>
      <td>0.0625</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0625</td>
      <td>0.2500</td>
      <td>0.375</td>
      <td>0.2500</td>
      <td>0.0625</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0000</td>
      <td>0.0625</td>
      <td>0.250</td>
      <td>0.4375</td>
      <td>0.2500</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.125</td>
      <td>0.5000</td>
      <td>0.3750</td>
    </tr>
  </tbody>
</table>
</div>



<p>你可以轻松地手动计算各个条目。例如，$(1, 1)$是分两步从状态1进入状态1的可能性。有两种方法可以实现这一目标：</p>
<ul>
<li>[1, 1, 1]</li>
<li>[1, 2, 1]</li>
</ul>
<p>假设1是起始状态，则两条路径的总概率为$(0.5 \times 0.5) + (0.5 \times 0.25) = 0.375$.</p>
<p>由于马尔科夫性质，基于一阶转移概率，就能得到二阶转移概率。</p>
<p>一般而言，我们可以通过调节链条在时刻1时的位置，来计算$P_2(i, j)$</p>
<script type="math/tex; mode=display">
\begin{align*}
P_2(i, j) ~ &= ~ P(X_2 = j \mid X_0 = i) \\
&= ~ \sum_k P(X_1 = k, X_2 = j \mid X_0 = i) \\
&= ~ \sum_k P(X_1 = k \mid X_0 = i)P(X_2 = j \mid X_1 = k) \\
&= ~ \sum_k P(i, k)P(k, j)
\end{align*}</script><p>如上结果为$\mathbb{P} \times \mathbb{P} = \mathbb{P}^2$矩阵的$(i, j)$位置处元素。因此，二阶转移矩阵为$\mathbb{P}^2$。</p>
<p>通过归纳证明，能总结出，$n$-阶转移矩阵为$\mathbb{P}^n$。</p>
<p>这是粘性反转随机漫步的5步转移矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.transition_matrix(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.246094</td>
      <td>0.410156</td>
      <td>0.234375</td>
      <td>0.089844</td>
      <td>0.019531</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.205078</td>
      <td>0.363281</td>
      <td>0.250000</td>
      <td>0.136719</td>
      <td>0.044922</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.117188</td>
      <td>0.250000</td>
      <td>0.265625</td>
      <td>0.250000</td>
      <td>0.117188</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.044922</td>
      <td>0.136719</td>
      <td>0.250000</td>
      <td>0.363281</td>
      <td>0.205078</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.019531</td>
      <td>0.089844</td>
      <td>0.234375</td>
      <td>0.410156</td>
      <td>0.246094</td>
    </tr>
  </tbody>
</table>
</div>



<p>这是一个表示方法，但要使用矩阵，我们必须以Python识别为矩阵的形式表示它。方法<code>get_transition_matrix</code>为我们做到了这一点。需要步数$n$作为入参，并以numpy矩阵的格式返回$n$-阶转移矩阵。</p>
<p>对于粘性反转随机漫步，我们将从提取$\mathbb{P}$开始P作为矩阵<code>refl_walk_P</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">refl_walk_P = reflecting_walk.get_transition_matrix(<span class="number">1</span>)</span><br><span class="line">refl_walk_P</span><br></pre></td></tr></table></figure>
<pre><code>array([[ 0.5 ,  0.5 ,  0.  ,  0.  ,  0.  ],
       [ 0.25,  0.5 ,  0.25,  0.  ,  0.  ],
       [ 0.  ,  0.25,  0.5 ,  0.25,  0.  ],
       [ 0.  ,  0.  ,  0.25,  0.5 ,  0.25],
       [ 0.  ,  0.  ,  0.  ,  0.5 ,  0.5 ]])
</code></pre><p>让我们检查前面显示的5-阶转移矩阵是否与$\mathbb{P}^5$相同。您可以使用<code>np.linalg.matrix_power</code>将计算矩阵的非负整数次幂。第一个参数是矩阵，第二个参数是幂。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.linalg.matrix_power(refl_walk_P, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<pre><code>array([[ 0.24609375,  0.41015625,  0.234375  ,  0.08984375,  0.01953125],
       [ 0.20507812,  0.36328125,  0.25      ,  0.13671875,  0.04492188],
       [ 0.1171875 ,  0.25      ,  0.265625  ,  0.25      ,  0.1171875 ],
       [ 0.04492188,  0.13671875,  0.25      ,  0.36328125,  0.20507812],
       [ 0.01953125,  0.08984375,  0.234375  ,  0.41015625,  0.24609375]])
</code></pre><p>这确实与<code>transition_matrix</code>显示的矩阵相同，但难以阅读。</p>
<p>当我们想要在计算中使用$\mathbb{P}$，我们将使用此矩阵表示。对于显示和阅读，<code>transition_matrix</code> 则更好。</p>
<h3 id="长期运行"><a href="#长期运行" class="headerlink" title="长期运行"></a>长期运行</h3><p>要理解马尔科夫链的长跑行为，令$n$变大，并检查对于开始状态的每个$X_n$值。这些都包含在$n$-阶转移矩阵$\mathbb{P}^n$中。</p>
<p>如下展示了随机漫步中，$n = 25, 50$, 和 $100$情况下的$\mathbb{P}^n$ 。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.transition_matrix(<span class="number">25</span>)</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.129772</td>
      <td>0.256749</td>
      <td>0.25</td>
      <td>0.243251</td>
      <td>0.120228</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.128374</td>
      <td>0.254772</td>
      <td>0.25</td>
      <td>0.245228</td>
      <td>0.121626</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.125000</td>
      <td>0.250000</td>
      <td>0.25</td>
      <td>0.250000</td>
      <td>0.125000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.121626</td>
      <td>0.245228</td>
      <td>0.25</td>
      <td>0.254772</td>
      <td>0.128374</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.120228</td>
      <td>0.243251</td>
      <td>0.25</td>
      <td>0.256749</td>
      <td>0.129772</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.transition_matrix(<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.125091</td>
      <td>0.250129</td>
      <td>0.25</td>
      <td>0.249871</td>
      <td>0.124909</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.125064</td>
      <td>0.250091</td>
      <td>0.25</td>
      <td>0.249909</td>
      <td>0.124936</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.125000</td>
      <td>0.250000</td>
      <td>0.25</td>
      <td>0.250000</td>
      <td>0.125000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.124936</td>
      <td>0.249909</td>
      <td>0.25</td>
      <td>0.250091</td>
      <td>0.125064</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.124909</td>
      <td>0.249871</td>
      <td>0.25</td>
      <td>0.250129</td>
      <td>0.125091</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.transition_matrix(<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.125</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.125</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.125</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.125</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.125</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.125</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.125</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.125</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.125</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.125</td>
    </tr>
  </tbody>
</table>
</div>



<p>$\mathbb{P}^{100}$中每一行都一样！这意味着，对于随机漫步而言，在时刻100时的条件分布不依赖于其起始状态。<em>链忘了他的起始点</em></p>
<p>你可以增加$n$，并且会看到$n$-阶转移矩阵保持一致。说明链已经<em>达到稳定</em></p>
<p>稳定性是许多马尔可夫链的显着特性，也是本章的主题。</p>
<h2 id="析构链"><a href="#析构链" class="headerlink" title="析构链"></a>析构链</h2><p>设$S$为一个有限状态或者可数无穷状态组成的集合。任一由集合$S$来索引行、列的随机矩阵，都是状态空间$S$下的某一马尔科夫链的转移矩阵。马尔可夫链的转移行为与矩阵变化保持一致。设置术语以讨论其中一些行为很有帮助。</p>
<h3 id="连通"><a href="#连通" class="headerlink" title="连通"></a>连通</h3><p>如果链可以从状态$i$转移到状态$j$，称之为<em>$i$可达$j$</em>，记作$i \rightarrow j$。通常，你能通过检查链的转移图来判定$i$ 是否可达$j$。一个$i \rightarrow j$正式的定义为：</p>
<ul>
<li>存在一条转移路径，从$i$开始，到$j$结束。</li>
<li>等价的, 存在 $n &gt; 0$ 使得 $P_n(i, j) &gt; 0$。</li>
</ul>
<p>当$i \rightarrow j$ 并且 $j \rightarrow i$时，称<em>$i$连通$j$</em> 记作$i \leftrightarrow j$。</p>
<p>如果链的所有状态彼此连通，则该链被称为<em>不可约</em>。</p>
<p>上一节的粘性反转随机漫步是不可约的，因为链条可能从每个状态相互之间都是连通的。</p>
<h3 id="周期"><a href="#周期" class="headerlink" title="周期"></a>周期</h3><p>在离散时间工作存在缺陷。其中一点就是<em>周期性</em>。让我们从随机漫步的例子开始，其中每个步骤是基于公平硬币的投掷。假设从状态0开始。然后定义只能在如下时刻返回状态0：正面和反面出现的数量完全相等，因此投掷的数量必须是偶数。我们说状态0 <em>有周期2</em></p>
<p>当链从状态$i$开始，并且经过$d$的倍数次数后能回到状态$i$，则称状态$i$ 有<em>周期</em> $d$。$d$是所有能使 $P_n(i, i) &gt; 0$的 $n$ 的最大公约数。</p>
<p>在上述描述的随机漫步中，所有的状态有周期2。</p>
<p>周期会导致长期行为的描述出现问题。例如：当状态$i$有周期3,序列$P_n(i, i)$可能看起来像”0, 0, positive, 0, 0, positive, $\ldots$”，因此限制声明可能会变得复杂。</p>
<p>在本课程中，我们将研究链条的长期行为，其中所有状态都是<em>非周期性的</em>，即它们具有周期1.换句话说，链条上无环。</p>
<p>你如何检查所有状态是否具有周期性？如果链是不可约的，那所有状态必须具有相同的周期。这个的证据并不困难，但我们不会这样做。因为这意味着如果一个链是不可约的，你就要找出其中每一个状态的周期，然后保证所有他状态都必须有相同的周期。</p>
<p>有些状态是很容易识别为非周期性的。如果1-阶转移概率$P(i, i)$ 为正，那么状态$i$是非周期性的。因为链可以保持在状态$i$任意长时间，其返回的结果是不成环的。</p>
<h3 id="样例：析构链"><a href="#样例：析构链" class="headerlink" title="样例：析构链"></a>样例：析构链</h3><p>考虑具有转移矩阵的链</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th><strong>a</strong></th>
<th><strong>b</strong></th>
<th><strong>c</strong></th>
<th><strong>d</strong></th>
<th><strong>e</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>a</strong></td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td><strong>b</strong></td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td><strong>c</strong></td>
<td>0</td>
<td>1/3</td>
<td>1/3</td>
<td>1/3</td>
<td>0</td>
</tr>
<tr>
<td><strong>d</strong></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1/3</td>
<td>2/3</td>
</tr>
<tr>
<td><strong>e</strong></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>4/5</td>
<td>1/5</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>状态$a$和$b$相互连通，并且不和其他状态可达。因此称为<em>连通类</em>。小矩阵</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th><strong>a</strong></th>
<th><strong>b</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>a</strong></td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td><strong>b</strong></td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p>本身就是一个转移矩阵。尽管描述的是一个无聊的链，在状态$a$ 和$b$之间循环。$a$和$b$都有周期2。</p>
<ul>
<li>状态$d$和$e$构成连通类，并且是非周期性的。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th><strong>d</strong></th>
<th><strong>e</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>d</strong></td>
<td>1/3</td>
<td>2/3</td>
</tr>
<tr>
<td><strong>e</strong></td>
<td>4/5</td>
<td>1/5</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>状态$c$与自己连通，一旦转移为状态$b$或$d$, 就无法再返回。</li>
</ul>
<p>在本课程中，我们将只使用<em>有限状态空间上的不可约的非周期马尔可夫链</em>。我们所说的大部分内容也适用于周期链，以及具有可数无限状态空间的链。</p>
<h2 id="长期运行行为"><a href="#长期运行行为" class="headerlink" title="长期运行行为"></a>长期运行行为</h2><p>每个具有有限状态空间的不可约和非周期性的马尔可夫链在状态转移一段时间后会表现出惊人的规律性。以下收敛定理的证明超出了本课程的范围，但您已经通过计算看到了结果。对于某些类别无限多个状态的马氏链，所有结果都更为正确。</p>
<h3 id="收敛性"><a href="#收敛性" class="headerlink" title="收敛性"></a>收敛性</h3><p>设$X_0, X_1, \ldots$ 是有限状态空间$S$上的不可约，非周期性的马尔科夫链。那么对于所有的状态$i$和$j$有</p>
<script type="math/tex; mode=display">
P_n(i, j) \to \pi(j) ~~~ \text{as } n \to \infty</script><p>换言之，对于$S$中任意的$i$和$j$，从$i$到$j$的$n$-阶转移概率会逼近一个极限，并且不依赖于$i$。<br>此外</p>
<ul>
<li><p>对所有的状态$j$都有$\pi(j) &gt; 0$ ，和</p>
</li>
<li><p>$\sum_{j \in S} \pi(j) = 1$</p>
</li>
</ul>
<p>也就是说，当$n \to \infty$， $n$-阶转移矩阵$\mathbb{P}^n$的中每一行的值都会等于同一个向量$\pi$，其中每一项都为正值。</p>
<h3 id="限制特性"><a href="#限制特性" class="headerlink" title="限制特性"></a>限制特性</h3><p><strong>(i)</strong> 向量$\pi$是<em>平衡方程</em> $\pi \mathbb{P} = \pi$的唯一解。</p>
<p><strong>(ii)</strong> 如果对某些$n$，$X_n$的分布为$\pi$，那么，对于$m &gt; n$，其分布 $X_m$ 也同样是$\pi$。因此，称$\pi$为链的<em>静态</em>或<em>稳态</em>分布。</p>
<p><strong>(iii)</strong> 对于每一个状态$j$, 向量$\pi$的第$j$th 元素$\pi(j)$是链的长期值在$j$的预期。</p>
<p>我们假设收敛定理是正确的; 然后其他相关的特性推断起来就相对容易了。在本节的其余部分，我们将建立这些特性并查看它们的使用方式。</p>
<h3 id="平衡方程"><a href="#平衡方程" class="headerlink" title="平衡方程"></a>平衡方程</h3><p>另$n \ge 0$，$i$和$j$是两个状态。然后</p>
<script type="math/tex; mode=display">
P_{n+1}(i, j) = \sum_{k \in S} P_n(i, k)P(k, j)</script><p>因此</p>
<script type="math/tex; mode=display">
\begin{align*}
\lim_{n \to \infty} P_{n+1}(i, j) &= \lim_{n \to \infty} \sum_{k \in S} P_n(i, k)P(k, j) \\ \\
&= \sum_{k \in S} \big{(} \lim_{n \to \infty} P_n(i, k) \big{)} P(k, j)
\end{align*}</script><p>因为$S$是有限的，我们可以交换极限与和。现在将收敛定理应用于平稳性：</p>
<script type="math/tex; mode=display">
\pi(j) = \sum_{k \in S} \pi(k)P(k, j)</script><p>这被称为<em>平衡方程</em>。</p>
<p>在矩阵表示方法中，如果你把$\pi$当做行向量，方程可以写为</p>
<script type="math/tex; mode=display">
\pi = \pi \mathbb{P} ~~~~~ \text{或者，等价的} ~~~~~ \pi\mathbb{P} = \pi</script><p>这有助于计算$\pi$时没有限制。</p>
<p><strong>注意:</strong> 稳态不是状态空间$S$的元素。这是链条运行很长一段时间后的状况。让我们进一步研究这个问题。</p>
<h3 id="平衡态和稳态"><a href="#平衡态和稳态" class="headerlink" title="平衡态和稳态"></a>平衡态和稳态</h3><p>要想看看这些方程中的“平衡”是什么，就需要想象一下这个链的大量独立复制。例如，根据粘性反转随机漫步的转移概率，想象大量的粒子在状态1到5之间移动，并假设所有粒子在时刻1,2,3，……… 都彼此独立。</p>
<p>然后在任何时刻和任何状态$j$，有一些比例的粒子离开$j$，和另一些比例的粒子进入$j$。平衡方程表明这两个比例是相等的。</p>
<p>让我们通过再次查看方程来检查：对于任何状态$j$,</p>
<script type="math/tex; mode=display">
\pi(j) = \sum_{k \in S} \pi(k)P(k, j)</script><p>对于每一个$k \in S$ (包括 $k=j$)，以$\pi(k)$ 作为链运行很长一段时间后离开状态$k$的粒子的比例。等式左边是离开状态$j$的粒子的比例。等式右边求和的每一项都是离开状态$k$并转向状态$j$的粒子比例。求和之后，就是所有进入状态$j$的粒子。等式成立时，链是<em>平衡的</em>。</p>
<p>收敛于平稳性的定理表明，当$n$变大时，链趋于平衡。当链确实达到平衡时，对于$n$，其分布$X_n$为$\pi$，然后它保持平衡。原因：</p>
<script type="math/tex; mode=display">
P(X_{n+1} = j) = \sum_{i \in S} P(X_n = i)P(i, j) = \sum_{i \in S} \pi(i)P(i, j) = \pi(j)</script><p>通过平衡方程。现在使用归纳法。</p>
<p>特别是，如果链以其静止分布$\pi$开始，那么之后每一个$n$的分布$X_n$都是$\pi$。</p>
<h3 id="唯一性"><a href="#唯一性" class="headerlink" title="唯一性"></a>唯一性</h3><p>不难表明,如果平衡方程有解，那么它必须是$\pi$，$X_n$的边际分布的极限。我们不会做证明; 它基本上重复了我们用来推导平衡方程的步骤。你应该意识到，一个不可约的，非周期的，有限状态马尔可夫链只有一个稳态分布。</p>
<p>如果您碰巧猜测到平衡方程的解，这将特别有用。如果您猜到了一个概率分布解，那么您已经找到了链的稳态分布。</p>
<h3 id="长期运行时各个状态占比"><a href="#长期运行时各个状态占比" class="headerlink" title="长期运行时各个状态占比"></a>长期运行时各个状态占比</h3><p>有状态$j$ ，令$I_m(j)$代表事件${X_m = j}$。<em>链花费在状态$j$处转移次数比例</em>，当转移次数从1至$n$，表述如下：</p>
<script type="math/tex; mode=display">
\frac{1}{n} \sum_{m=1}^n I_m(j)</script><p>因此，当链从状态$i$开始，<em>链花费在状态$j$处转移次数比例预期</em>为</p>
<script type="math/tex; mode=display">
\frac{1}{n} \sum_{m=1}^n E(I_m(j) \mid X_0 = i) 
= \frac{1}{n} \sum_{m=1}^n P(X_m = j \mid X_0 = i) 
= \frac{1}{n} \sum_{m=1}^n P_m(i, j)</script><p>现在回想一下实数序列的收敛性质：当$n \to \infty$时，$x_n \to x$，那么序列的均值也会收敛于$x$</p>
<script type="math/tex; mode=display">
\frac{1}{n} \sum_{m=1}^n x_m \to x ~~~ \text{as } n \to \infty</script><p>令$x_n = P_n(i, j)$。通过收敛性可得</p>
<script type="math/tex; mode=display">
P_n(i, j) \to \pi(j) ~~~ \text{as } n \to \infty</script><p>因此平均值也会收敛:</p>
<script type="math/tex; mode=display">
\frac{1}{n} \sum_{m=1}^n P_m(i, j) \to \pi(j) ~~~ \text{as } n \to \infty</script><p>因此，长期过程的链花费在状态$j$处转移次数比例预期为$\pi(j)$，其中$\pi$链的固定分布。</p>
<h3 id="粘性反转漫步的稳态分布"><a href="#粘性反转漫步的稳态分布" class="headerlink" title="粘性反转漫步的稳态分布"></a>粘性反转漫步的稳态分布</h3><p>我们在前面的部分对此进行了研究。转移图是</p>
<p><img src="/image/prob140/10-1-trans_refl.png" alt="image.png"></p>
<p>这是转移矩阵$\mathbb{P}$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.50</td>
      <td>0.50</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>0.50</td>
    </tr>
  </tbody>
</table>
</div>



<p> <code>MarkovChain</code>的方法<code>steady_state</code>返回一个稳态分布$\pi$。 之前看到过这是$\mathbb{P}$行的极限。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reflecting_walk.steady_state()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Value</th> <th>Probability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1    </td> <td>0.125      </td>
        </tr>
    </tbody>
        <tr>
            <td>2    </td> <td>0.25       </td>
        </tr>
    </tbody>
        <tr>
            <td>3    </td> <td>0.25       </td>
        </tr>
    </tbody>
        <tr>
            <td>4    </td> <td>0.25       </td>
        </tr>
    </tbody>
        <tr>
            <td>5    </td> <td>0.125      </td>
        </tr>
    </tbody>
</table>



<p>我们也可是使用平衡方程求解$\pi$。当然，这看起来有些多余，因为Python已经给出了$\pi$。当转移矩阵很大，且是分数的情况，使用Python是不错的操作。</p>
<p>根据平衡方程：</p>
<script type="math/tex; mode=display">
\pi(1) = \sum_{k=1}^s \pi(k)P(k, 1)</script><p>也就是说，使用$\pi$乘以$\mathbb{P}$中的<code>1</code>列</p>
<script type="math/tex; mode=display">
\pi(1) = \pi(1)\cdot 0.5 ~ + ~ \pi(2) \cdot 0.25 = 0.5\pi(1) + 0.25\pi(2)</script><p>按照相同的过程获得所有五个平衡方程：</p>
<script type="math/tex; mode=display">
\begin{align*}
\pi(1) &= 0.5\pi(1) + 0.25\pi(2) \\
\pi(2) &= 0.5\pi(1) + 0.5\pi(2) + 0.25\pi(3) \\
\pi(3) &= 0.25\pi(2) + 0.5\pi(3) + 0.25\pi(4) \\
\pi(4) &= 0.25\pi(3) + 0.5\pi(4) + 0.5\pi(5) \\
\pi(5) &= 0.25\pi(4) + 0.5\pi(5)
\end{align*}</script><p>一些观察结果使系统易于解决。</p>
<ul>
<li>通过重新排列第一个等式，我们得到 $\pi(2) = 2\pi(1)$。</li>
<li>通过对称性, $\pi(1) = \pi(5)$ 和 $\pi(2) = \pi (4)$。</li>
<li>因为 $\pi(2) = \pi(4)$,  等式$\pi(3)$ 表明 $\pi(3) = \pi(2) = \pi(4)$。</li>
</ul>
<p>所以$\pi$的分布为</p>
<script type="math/tex; mode=display">
\big{(} \pi(1), 2\pi(1), 2\pi(1), 2\pi(1), \pi(1) \big{)}</script><p>因为$\pi$是一个条件分布概率，其和为1。即 $8\pi(1)$的值为1，可以得到</p>
<script type="math/tex; mode=display">
\pi = \big{(} \frac{1}{8}, \frac{2}{8}, \frac{2}{8}, \frac{2}{8}, \frac{1}{8} \big{)}</script><p>这和我们用<code>distribution</code>计算$n=100$的结果一致。事实上，我们可以使用该方法<code>steady_state</code>来获得$\pi$:</p>
<p>这意味着从长远来看，这一部分的随机漫步预计将花费大约12.5％的时间在状态1，25％的时间用于状态2,3和4，其余12.5%的时间在状态5。</p>
<h3 id="懒惰的随机循环漫步"><a href="#懒惰的随机循环漫步" class="headerlink" title="懒惰的随机循环漫步"></a>懒惰的随机循环漫步</h3><p>现在让状态空间在圆上排列五个点。假设该过程从点1开始，并且在每个步骤中保持在概率为0.5的位置（因此是粘性的），或者移动到两个相邻点中的一个，每个概率为0.25，而不管其他移动。</p>
<p>换言之，除了$1 \rightarrow 5$ 和 $5 \rightarrow 1$这个漫步的转移和上面的随机漫步是相同的。 可以在转移图中总结此转移行为，请注意，所有状态的转移行为都是相同的。</p>
<p><img src="/image/prob140/10-3-trans_circle.png" alt="Lazy Circle Walk"></p>
<p>在每一步中，下一步的动作都是通过从三个选项中随机选择和链的当前位置来确定的，而不是从它到达该位置的方式。所以这个过程就是马尔可夫链。我们称之为 $X_0, X_1, X_2, \ldots $ 并定义其转移矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">s = np.arange(<span class="number">1</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">circle_walk_probs</span>(<span class="params">i, j</span>):</span><br><span class="line">        <span class="keyword">if</span> i-j == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.5</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">abs</span>(i-j) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.25</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">abs</span>(i-j) == <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.25</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>   </span><br><span class="line">        </span><br><span class="line">circle_walk = MarkovChain.from_transition_function(s, circle_walk_probs)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">circle_walk</span><br></pre></td></tr></table></figure>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.25</td>
      <td>0.50</td>
    </tr>
  </tbody>
</table>
</div>



<p>由于转移行为的对称性，任何状态出现的概率，都不应该大于任何其他状态，因此$\pi(j)$的值是相同的。这可以用<code>steady_state</code>验证。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">circle_walk.steady_state()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Value</th> <th>Probability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1    </td> <td>0.2        </td>
        </tr>
    </tbody>
        <tr>
            <td>2    </td> <td>0.2        </td>
        </tr>
    </tbody>
        <tr>
            <td>3    </td> <td>0.2        </td>
        </tr>
    </tbody>
        <tr>
            <td>4    </td> <td>0.2        </td>
        </tr>
    </tbody>
        <tr>
            <td>5    </td> <td>0.2        </td>
        </tr>
    </tbody>
</table>



<h2 id="样例"><a href="#样例" class="headerlink" title="样例"></a>样例</h2><p>这里有两个例子来说明如何找到稳态分布以及如何使用它。</p>
<h3 id="Ehrenfest的扩散模型"><a href="#Ehrenfest的扩散模型" class="headerlink" title="Ehrenfest的扩散模型"></a>Ehrenfest的扩散模型</h3><p><a href="https://en.wikipedia.org/wiki/Paul_Ehrenfest">Paul Ehrenfest</a> 提出了许多气体粒子扩散模型，其中一个我们将在这里研究。</p>
<p>该模型说有两个容器总共含有$N$个粒子。在每个瞬间，随机选择容器，并且独立于容器随机选择颗粒。然后将所选粒子放入所选容器中; 如果它已经在那个容器中，那就留在那里。</p>
<p>令$X_n$表示时刻$n$时容器1中的粒子数。那么$X_0, X_1, \ldots$是一个马尔科夫链，其转移概率描述如下：</p>
<p>\begin{equation}<br>P(i, j) =<br> \begin{cases}<br>      \frac{N-i}{2N} &amp; \text{if } j = i+1 \<br>      \frac{1}{2} &amp; \text{if } j = i \<br>      \frac{i}{2N} &amp; \text{if } j = i-1 \<br>      0 &amp; \text{otherwise}<br>   \end{cases}<br>\end{equation}</p>
<p>这条链显然是不可约的。它是非周期性的，因为 $P(i, i) &gt; 0$.</p>
<p><strong>问题.</strong> 链的稳态分布是什么？ </p>
<p><strong>回答.</strong> 使用电脑， 所以，先找到$N=100$时的稳态分布，然后检查对于一般的$N$是否一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">N = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">states = np.arange(N+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transition_probs</span>(<span class="params">i, j</span>):</span><br><span class="line">    <span class="keyword">if</span> j == i:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>/<span class="number">2</span></span><br><span class="line">    <span class="keyword">elif</span> j == i+<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> (N-i)/(<span class="number">2</span>*N)</span><br><span class="line">    <span class="keyword">elif</span> j == i-<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> i/(<span class="number">2</span>*N)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">ehrenfest = MarkovChain.from_transition_function(states, transition_probs)</span><br><span class="line">Plot(ehrenfest.steady_state(), edges=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/prob140/10-4-output.png" alt="png"></p>
<p>这看起来很像二项式（100,1 / 2）分布。实际上它<em>就是</em>二项式（100,1 / 2）分布。既然你已经猜到了，你所要做的就是将它插入到平衡方程中并检查它们是否有效。</p>
<p>平衡方程是：</p>
<script type="math/tex; mode=display">
\begin{align*}
\pi(0) &= \frac{1}{2}\pi(0) + \frac{1}{2N}\pi(1) \\
\pi(j) &= \frac{N-(j-1)}{2N}\pi(j-1) + \frac{1}{2}\pi(j) + \frac{j+1}{2N}\pi(j+1), ~~~ 1 \le j \le N-1 \\
\pi(N) &= \frac{1}{2N}\pi(N-1) + \frac{1}{2}\pi(N)
\end{align*}</script><p>您已经通过查看$N=100$的结果猜测了答案。但是如果你想从头开始，你必须简化平衡方程并尝试用$\pi(0)$表示$\pi$的所有元素。你会得到：</p>
<script type="math/tex; mode=display">
\begin{align*}
\pi(1) &= N\pi(0) \\ \\
\pi(2) &= \frac{N(N-1)}{2} \pi0 = \binom{N}{2} \pi(0)
\end{align*}</script><p>可以归纳推导如下：</p>
<script type="math/tex; mode=display">
\pi(j) = \binom{N}{j} \pi(0)</script><p>换句话说，稳态分布分布与二项式系数成比例。所以当 $\pi(0) = 1/2^N$可以使所有元素的和为1,分布为二项分布 $(N, 1/2)$。</p>
<h3 id="预期奖励"><a href="#预期奖励" class="headerlink" title="预期奖励"></a>预期奖励</h3><p>假设我长时间运行上一节中的懒惰反转随机漫步。如下，这是它的稳态分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stationary = reflecting_walk.steady_state()</span><br><span class="line">stationary</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Value</th> <th>Probability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1    </td> <td>0.125      </td>
        </tr>
    </tbody>
        <tr>
            <td>2    </td> <td>0.25       </td>
        </tr>
    </tbody>
        <tr>
            <td>3    </td> <td>0.25       </td>
        </tr>
    </tbody>
        <tr>
            <td>4    </td> <td>0.25       </td>
        </tr>
    </tbody>
        <tr>
            <td>5    </td> <td>0.125      </td>
        </tr>
    </tbody>
</table>



<p><strong>问题 1.</strong> 假设每次链条处于状态4时, 我赢得$$4$; 每次进入状态5, 我赢得$$5$; 否则我赢不到钱. 我奖励的期望是多少？</p>
<p><strong>回答 1.</strong> 从长远来看，链条处于稳定状态。所以，有62.5%的概率，我赢不到钱，有25%的概率我赢$$4$，12.5%的概率，我赢$$5$。综上，计算可得奖励的期望为$$1.625$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>*<span class="number">0.625</span> + <span class="number">4</span>*<span class="number">0.25</span> + <span class="number">5</span>*<span class="number">.125</span></span><br></pre></td></tr></table></figure>
<pre><code>1.625
</code></pre><p><strong>问题 2.</strong> 假设每次链条处于状态$i$, 我抛$i$枚硬币，并记录正面次数。从长期来看，我每次得到正面个数的期望是多少？</p>
<p><strong>回答 2.</strong> 每次链条处于状态$i$,期望得到$i/2$个正面。 当链处于稳态, 投掷硬币的期望数是3。所以，从长期来看，正面个数的期望是1.5。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stationary.ev()/<span class="number">2</span></span><br></pre></td></tr></table></figure>
<pre><code>1.5
</code></pre><p>这看上去是人为的，请考虑一下：假设我在上面玩游戏，并且在每一个动作中我告诉你我得到的头数，<em>但我不告诉你链在哪个状态</em>。我<em>隐藏</em>了潜在的马尔可夫链。如果您尝试重新创建马尔可夫链所采用的步骤序列，那么您正在使用隐马尔可夫模型。它们广泛用于模式识别，生物信息学和其他领域。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/11/sklearn-PMML/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/07/11/sklearn-PMML/" class="post-title-link" itemprop="url">Python sklearn中训练的模型导出为PMML</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-07-11 22:34:52 / Modified: 22:36:01" itemprop="dateCreated datePublished" datetime="2018-07-11T22:34:52+08:00">2018-07-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PMML/" itemprop="url" rel="index"><span itemprop="name">PMML</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>自2007年发布以来，scikit-learn已经成为Python重要的机器学习库了。scikit-learn简称sklearn，支持包括分类、回归、降维和聚类四大机器学习算法。还包含了特征提取、数据处理和模型评估三大模块。<br>sklearn拥有着完善的文档，上手容易，具有着丰富的API，在学术界颇受欢迎。sklearn已经封装了大量的机器学习算法，包括LIBSVM和LIBINEAR。同时sklearn内置了大量数据集，节省了获取和整理数据集的时间。<br>本文介绍了如何将sklearn中的模型导出为PMML文件，方便后续的工程上线操作，内容包括涉及环境的搭建和中间遇到的坑。</p>
<h1 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h1><ul>
<li>Python 基本操作，会使用pip 或者Anaconda进行依赖库管理</li>
<li>Maven 基本操作</li>
<li>Java 命令基本操作</li>
</ul>
<h1 id="sklearn2pmml-相关组件安装"><a href="#sklearn2pmml-相关组件安装" class="headerlink" title="sklearn2pmml 相关组件安装"></a>sklearn2pmml 相关组件安装</h1><h2 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h2><ul>
<li>Python 2.7，3.4 或者更新。</li>
<li>scikit-learn 0.16.0 或者更新。</li>
<li>sklearn-pandas 0.0.10 或者更新。</li>
<li>sklearn2pmml 0.14.0 或者更新。</li>
</ul>
<h2 id="安装scikit-learn"><a href="#安装scikit-learn" class="headerlink" title="安装scikit-learn"></a>安装scikit-learn</h2><p>使用pip 安装，命令如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U scikit-learn</span><br></pre></td></tr></table></figure></p>
<p>使用conda 安装，命令如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install scikit-learn</span><br></pre></td></tr></table></figure><br>个人强烈建议，使用<a href="https://anaconda.org/">Anaconda</a> 进行Python 版本管理，使用conda命令进行安装。（貌似因为源的问题，conda中被墙的可能性小）</p>
<p>详细内容，可以参见 <a href="http://scikit-learn.org/stable/install.html">sklearn 安装文档</a></p>
<h2 id="安装skkearn-pandas"><a href="#安装skkearn-pandas" class="headerlink" title="安装skkearn-pandas"></a>安装skkearn-pandas</h2><p>命令如下:<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install sklearn-pandas</span><br></pre></td></tr></table></figure><br>这个地方，如果因为被墙，可以去官网下载<a href="https://pypi.org/project/sklearn-pandas/#files">whl文件</a>到本地，假设路径为”/data/users/miao18/sklearn_pandas-1.6.0-py2.py3-none-any.whl”然后<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install /data/users/miao18/sklearn_pandas-1.6.0-py2.py3-none-any.whl</span><br></pre></td></tr></table></figure><br>通过本地文件的方式安装。</p>
<h2 id="安装sklearn2pmml"><a href="#安装sklearn2pmml" class="headerlink" title="安装sklearn2pmml"></a>安装sklearn2pmml</h2><p>命令如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --user --upgrade git+https://github.com/jpmml/sklearn2pmml.git</span><br></pre></td></tr></table></figure></p>
<h2 id="校验是否安装成功"><a href="#校验是否安装成功" class="headerlink" title="校验是否安装成功"></a>校验是否安装成功</h2><p>进入Python 命令行，输入如下命令<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import sklearn, sklearn.externals.joblib, sklearn_pandas, sklearn2pmml</span><br><span class="line"></span><br><span class="line">print(sklearn.__version__)</span><br><span class="line">print(sklearn.externals.joblib.__version__)</span><br><span class="line">print(sklearn_pandas.__version__)</span><br><span class="line">print(sklearn2pmml.__version__)</span><br></pre></td></tr></table></figure><br>我的环境输出结果如下，符合要求：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0.19.1</span><br><span class="line">0.11</span><br><span class="line">1.6.0</span><br><span class="line">0.26.0</span><br></pre></td></tr></table></figure></p>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn2pmml import PMMLPipeline</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn import tree</span><br><span class="line">iris = load_iris()</span><br><span class="line">clf = tree.DecisionTreeClassifier()</span><br><span class="line">pipeline = PMMLPipeline([(&quot;classifier&quot;, clf)])</span><br><span class="line">pipeline.fit(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line"># 导出为PMML</span><br><span class="line">from sklearn2pmml import sklearn2pmml</span><br><span class="line">sklearn2pmml(pipeline, &quot;DecisionTreeIris.pmml&quot;, with_repr = True)</span><br></pre></td></tr></table></figure>
<p>工作目录下的DecisionTreeIris.pmml 就是导出的pmml文件。</p>
<p>这里需要注意，sklearn中都是以pipeline 的形式进行转化的。原型如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn2pmml(pipeline, pmml, user_classpath, with_repr, debug)</span><br></pre></td></tr></table></figure></p>
<h1 id="jpmml-sklearn"><a href="#jpmml-sklearn" class="headerlink" title="jpmml-sklearn"></a>jpmml-sklearn</h1><h2 id="软件版本-1"><a href="#软件版本-1" class="headerlink" title="软件版本"></a>软件版本</h2><ul>
<li>Python 2.7，3.4 或者更新。</li>
<li>scikit-learn 0.16.0 或者更新。</li>
<li>sklearn-pandas 0.0.10 或者更新。</li>
<li>sklearn2pmml 0.14.0 或者更新。</li>
<li>Java 1.8 或者更新。</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>从github 下载源码，并安装：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:jpmml/jpmml-sklearn.git</span><br><span class="line">mvn clean install</span><br></pre></td></tr></table></figure><br>执行完毕后，在target目录下有 一个 converter-executable-1.4-SNAPSHOT.jar 的jar文件。</p>
<h2 id="使用方法-1"><a href="#使用方法-1" class="headerlink" title="使用方法"></a>使用方法</h2><p>一个典型的workflow如下：</p>
<ol>
<li>使用Python 训练一个模型。</li>
<li>将模型序列化为pickle，并存到本地。</li>
<li>使用Java命令，将pickle文件转为pmml。</li>
</ol>
<h2 id="Python-侧生成一个pickle-文件"><a href="#Python-侧生成一个pickle-文件" class="headerlink" title="Python 侧生成一个pickle 文件"></a>Python 侧生成一个pickle 文件</h2><p>训练部分，和直接导出pmml类似，只是最后的落地文件，不直接导出为pmml，而是存成pickle文件，代码如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn2pmml import PMMLPipeline</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn import tree</span><br><span class="line">iris = load_iris()</span><br><span class="line">clf = tree.DecisionTreeClassifier()</span><br><span class="line">pipeline = PMMLPipeline([(&quot;classifier&quot;, clf)])</span><br><span class="line">pipeline.fit(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line">from sklearn.externals import joblib</span><br><span class="line">joblib.dump(pipeline, &quot;pipeline.pkl.z&quot;, compress = 9)</span><br></pre></td></tr></table></figure></p>
<h2 id="Java侧转换"><a href="#Java侧转换" class="headerlink" title="Java侧转换"></a>Java侧转换</h2><p>使用上文编译好的Jar包，进行转换，命令如下:<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -jar target/jpmml-sklearn-executable-1.5-SNAPSHOT.jar --pkl-input pipeline.pkl.z --pmml-output pipeline.pmml</span><br></pre></td></tr></table></figure></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>分别使用了sklearn2pmml 和 jpmml-sklearn 进行导出pmml文件，操作过程类似。<br>使用sklearn2pmml 的方式更为便捷，直接在python 中就可以导出，这意味着每次训练完模型，就能快速生成一个pmml文件。<br>使用jpmml-sklearn，则可以对现有的pickle 文件进行操作。<br>两者各有优劣，请使用者根据实际情况按需使用。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/11/R-PMML/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/07/11/R-PMML/" class="post-title-link" itemprop="url">R训练的模型导出为PMML</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-07-11 22:30:20 / Modified: 22:33:40" itemprop="dateCreated datePublished" datetime="2018-07-11T22:30:20+08:00">2018-07-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PMML/" itemprop="url" rel="index"><span itemprop="name">PMML</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。<br>许多数据工程师或者数据分析师都习惯使用R进行数据挖掘和建模分析。<br>本文介绍了如何将R中的模型导出为PMML文件，方便后续的工程上线操作，内容包括涉及环境的搭建和中间遇到的坑。<br>本文介绍的三种方式，各自支持的机器学习模型种类不完全一致，文中附有官方文档链接，模型支持程度请查阅官方文档。</p>
<h1 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h1><ul>
<li>R 基本操作</li>
<li>Maven 基本操作</li>
<li>Java 命令基本操作</li>
</ul>
<h1 id="R2PMML"><a href="#R2PMML" class="headerlink" title="R2PMML"></a>R2PMML</h1><p>这是一个R的包，用于将R中训练好的模型导出为PMML。<a href="https://github.com/jpmml/r2pmml">github链接</a></p>
<h2 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h2><ul>
<li>Java 1.7 或者更新</li>
<li>R 3.5.0</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>使用devtools 从github的分支安装。代码如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">install.packages(&quot;devtools&quot;)</span><br><span class="line">library(&quot;devtools&quot;)</span><br><span class="line">install_git(&quot;git://github.com/jpmml/r2pmml.git&quot;)</span><br></pre></td></tr></table></figure></p>
<p><strong>注</strong><br>因为某些不可描述的原因，可能出现网站访问的问题，请灵活使用科学上网手段。<br>博主自己测试的时候，耗时在3min 左右。</p>
<h2 id="基本用法（只有模型部分）"><a href="#基本用法（只有模型部分）" class="headerlink" title="基本用法（只有模型部分）"></a>基本用法（只有模型部分）</h2><p>载入该包，然后调用保存模型即可，代码如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">library(&quot;randomForest&quot;)</span><br><span class="line">library(&quot;r2pmml&quot;)</span><br><span class="line"></span><br><span class="line">data(iris)</span><br><span class="line"></span><br><span class="line"># 训练模型</span><br><span class="line">iris.rf = randomForest(Species ~ ., data = iris, ntree = 7)</span><br><span class="line">print(iris.rf)</span><br><span class="line"></span><br><span class="line"># 导出为 PMML</span><br><span class="line">r2pmml(iris.rf, &quot;iris_rf.pmml&quot;)</span><br></pre></td></tr></table></figure></p>
<h2 id="添加预处理过程"><a href="#添加预处理过程" class="headerlink" title="添加预处理过程"></a>添加预处理过程</h2><p>数据在进入模型前，可以先进行预处理，一线简单的预处理操作也可以定义在PMML中，R代码如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">library(&quot;caret&quot;)</span><br><span class="line">library(&quot;randomForest&quot;)</span><br><span class="line">library(&quot;r2pmml&quot;)</span><br><span class="line"></span><br><span class="line">data(iris)</span><br><span class="line"></span><br><span class="line"># 创建预处理过程，0-1 标准化</span><br><span class="line">iris.preProcess = preProcess(iris, method = c(&quot;range&quot;))</span><br><span class="line"></span><br><span class="line"># 对原始数据进行预处理</span><br><span class="line">iris.transformed = predict(iris.preProcess, newdata = iris)</span><br><span class="line"></span><br><span class="line"># 使用预处理之后的数据训练模型</span><br><span class="line">iris.rf = randomForest(Species ~., data = iris.transformed, ntree = 7)</span><br><span class="line">print(iris.rf)</span><br><span class="line"></span><br><span class="line"># 导出PMML 文件</span><br><span class="line">r2pmml(iris.rf, &quot;iris_rf.pmml&quot;, preProcess = iris.preProcess)</span><br></pre></td></tr></table></figure></p>
<h1 id="PMML包"><a href="#PMML包" class="headerlink" title="PMML包"></a>PMML包</h1><p>R 中也支持了自带的PMML包,在最近的一次更新(2018.07.06)中，增加了支持模型的数量。</p>
<h2 id="软件版本-1"><a href="#软件版本-1" class="headerlink" title="软件版本"></a>软件版本</h2><ul>
<li>R 3.5.0</li>
</ul>
<h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><p>需要用到的包有：XML PMML 需要提前安装，命令如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">install.packages(“XML”) </span><br><span class="line">install.packages(&#x27;pmml&#x27;)</span><br></pre></td></tr></table></figure><br>选择镜像之后，等几分钟就行了。</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>训练模型，和上面一致<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">library(&quot;randomForest&quot;)</span><br><span class="line">data(iris)</span><br><span class="line">iris.rf = randomForest(Species ~ ., data = iris, ntree = 7)</span><br><span class="line">print(iris.rf)</span><br></pre></td></tr></table></figure></p>
<p>将模型转为pmml之后，导出为pmml格式<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">library(&quot;pmml&quot;)</span><br><span class="line">iris.rf.pmml &lt;- pmml(iris.rf,name=&quot;Iris Random Forest&quot;,data=iris.rf)</span><br><span class="line">savePMML(iris.rf.pmml,&quot;iris.rf.pmml&quot;,version=4.3)</span><br></pre></td></tr></table></figure></p>
<h1 id="JPMML-R"><a href="#JPMML-R" class="headerlink" title="JPMML-R"></a>JPMML-R</h1><p>上面两种方式，都是在R中，直接将模型导出为PMML。还可以将R的模型存为rds文件之后，调用Java 的方式安装。</p>
<h2 id="软件版本-2"><a href="#软件版本-2" class="headerlink" title="软件版本"></a>软件版本</h2><ul>
<li>Java 1.8 或者更新</li>
<li>R 3.5.0</li>
</ul>
<h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><p>在github 下载相关源码之后，编译<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:jpmml/jpmml-r.git</span><br><span class="line">mvn clean install</span><br></pre></td></tr></table></figure><br>在 target 目录下会生成converter-executable-1.3-SNAPSHOT.jar 文件。</p>
<h2 id="R中生成rds文件"><a href="#R中生成rds文件" class="headerlink" title="R中生成rds文件"></a>R中生成rds文件</h2><p>将训练好的模型保存为rds，代码如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">library(&quot;randomForest&quot;)</span><br><span class="line">rf = randomForest(Species ~ ., data = iris)</span><br><span class="line">saveRDS(rf, &quot;rf.rds&quot;)</span><br></pre></td></tr></table></figure></p>
<h2 id="将rds文件转为pmml文件"><a href="#将rds文件转为pmml文件" class="headerlink" title="将rds文件转为pmml文件"></a>将rds文件转为pmml文件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -jar target/converter-executable-1.3-SNAPSHOT.jar --rds-input rf.rds --pmml-output rf.pmml</span><br></pre></td></tr></table></figure>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文介绍了三种不同的方式，将R中训练好的模型导出为pmml文件。3种方式支持的模型不完全一致，比如 R2PMML 不支持glmnet，需要存glmnet的模型时，可以使用另外的方式。</p>
<h1 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h1><p><a href="https://github.com/jpmml/r2pmml">R2PMML</a><br><a href="https://cran.r-project.org/web/packages/pmml/">pmml: Generate PMML for Various Models</a><br><a href="https://github.com/jpmml/jpmml-r">JPMML-R</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/08/pmml-GeneralStructure/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/07/08/pmml-GeneralStructure/" class="post-title-link" itemprop="url">PMML文档翻译 基本结构（GeneralStructure）</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-07-08 18:42:42 / Modified: 18:43:45" itemprop="dateCreated datePublished" datetime="2018-07-08T18:42:42+08:00">2018-07-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PMML/" itemprop="url" rel="index"><span itemprop="name">PMML</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><ul>
<li>基于PMML Version4.3</li>
<li>基本可以视为官方文档的一个翻译</li>
<li>如有疏漏，请联系yao544303963@gmail.com</li>
</ul>
<h1 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h1><p>PMML使用XML来表示数据挖掘模型。模型的结构用一个XML Schema来描述。一个PMML文档中可以包含多个数据挖掘模型。一个PMML文档本质就是一个XML文档，其根元素是一个PMML类型的元素。其基本结构如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;PMML version=&quot;4.3&quot;</span><br><span class="line">  xmlns=&quot;http://www.dmg.org/PMML-4_3&quot; </span><br><span class="line">  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;</span><br><span class="line"></span><br><span class="line">  &lt;Header copyright=&quot;Example.com&quot;/&gt;</span><br><span class="line">  &lt;DataDictionary&gt; ... &lt;/DataDictionary&gt;</span><br><span class="line"></span><br><span class="line">  ... a model ...</span><br><span class="line"></span><br><span class="line">&lt;/PMML&gt;</span><br></pre></td></tr></table></figure></p>
<p>命名空间定义如下:<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:schema</span><br><span class="line">  xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot;</span><br><span class="line">  targetNamespace=&quot;http://www.dmg.org/PMML-4_3&quot;</span><br><span class="line">  xmlns=&quot;http://www.dmg.org/PMML-4_3&quot;</span><br><span class="line">  elementFormDefault=&quot;unqualified&quot;&gt;</span><br></pre></td></tr></table></figure><br>这里需要注意，因为命名空间在当前形式中声明，所以PMML中不能使用不同的命名空间。<br>关于命名空间，详见<a href="http://www.w3school.com.cn/xml/xml_namespaces.asp">XML 命名空间</a></p>
<p>尽管一个PMML文件必须严格符合PMML XSD的定义，然而并不需要额外的解析器。为了确保是一个有效的XML文档，PMML 需要遵循一些额外的规则。更多的内容参见<a href="http://dmg.org/pmml/v4-3/Conformance.html">conformance rules </a></p>
<p>PMML文档的根元素，必须是PMML 类型的。如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:element name=&quot;PMML&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:sequence&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Header&quot;/&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;MiningBuildTask&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;DataDictionary&quot;/&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;TransformationDictionary&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">      &lt;xs:sequence minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt;</span><br><span class="line">        &lt;xs:group ref=&quot;MODEL-ELEMENT&quot;/&gt;</span><br><span class="line">      &lt;/xs:sequence&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Extension&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">    &lt;/xs:sequence&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;version&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:group name=&quot;MODEL-ELEMENT&quot;&gt;</span><br><span class="line">  &lt;xs:choice&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;AssociationModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;BayesianNetworkModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;BaselineModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;ClusteringModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;GaussianProcessModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;GeneralRegressionModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;MiningModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;NaiveBayesModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;NearestNeighborModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;NeuralNetwork&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;RegressionModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;RuleSetModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;SequenceModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;Scorecard&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;SupportVectorMachineModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;TextModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;TimeSeriesModel&quot;/&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;TreeModel&quot;/&gt;</span><br><span class="line">  &lt;/xs:choice&gt;</span><br><span class="line">&lt;/xs:group&gt;</span><br></pre></td></tr></table></figure></p>
<p>其中，模型部分由如下定义<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:sequence minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt;</span><br><span class="line">    &lt;xs:group ref=&quot;MODEL-ELEMENT&quot;/&gt;</span><br><span class="line">&lt;/xs:sequence&gt;</span><br></pre></td></tr></table></figure><br>可以看出，一个PMML文档可以包含不止一个模型。如果应用系统提供了模型的命名，并且PMML的消费者指定了该模型的命名。否则会使用第一个模型。<br>minOccurs=”0”,这个参数表示，模型列表可以为空。模型为空时，表示该PMML用来传输原始数据。不包含模型的PMML对于PMML消费者而言，意义不大。  </p>
<p>对于PMML4.3，属性<strong>version</strong>的值，必须为4.3。</p>
<p>元素MiningBuildTask 包含生成该模型时及训练阶段的配置参数的描述。该信息不是必要的，但许多情况下，对于模型的维护和理解很有帮助。MiningBuildTask中特有的结构，不是由PMML定义的。示例如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:element name=&quot;MiningBuildTask&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:sequence&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Extension&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">    &lt;/xs:sequence&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br></pre></td></tr></table></figure></p>
<p>通常来讲，PMML中的字段名是独一无二的。避免字段名重复是一个好习惯，可以使消费者使用起来更为简便，减少异常的发生。</p>
<p>某一类型的PMML模型都有其特定的用途，例如神经网络或者逻辑回归。有的用于回归，有的用于分类。因此PMML定义了5种不同类型的MINING-FUNCTION，如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:simpleType name=&quot;MINING-FUNCTION&quot;&gt;</span><br><span class="line">  &lt;xs:restriction base=&quot;xs:string&quot;&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;associationRules&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;sequences&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;classification&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;regression&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;clustering&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;timeSeries&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;mixed&quot;/&gt;</span><br><span class="line">  &lt;/xs:restriction&gt;</span><br><span class="line">&lt;/xs:simpleType&gt;</span><br></pre></td></tr></table></figure><br>分别为关联规则，序列，分类，聚类，回归。时间序列和混合，是上述5种的组合。</p>
<p>所有的PMML模型的顶层元素，都类似如下结构<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:element name=&quot;ExampleModel&quot;&gt;</span><br><span class="line">   &lt;xs:complexType&gt;</span><br><span class="line">     &lt;xs:sequence&gt;</span><br><span class="line">       &lt;xs:element ref=&quot;Extension&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">       &lt;xs:element ref=&quot;MiningSchema&quot;/&gt;</span><br><span class="line">       &lt;xs:element ref=&quot;Output&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">       &lt;xs:element ref=&quot;ModelStats&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">       &lt;xs:element ref=&quot;Targets&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">       &lt;xs:element ref=&quot;LocalTransformations&quot; minOccurs=&quot;0&quot; /&gt;</span><br><span class="line">       ...</span><br><span class="line">       &lt;xs:element ref=&quot;ModelVerification&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">       &lt;xs:element ref=&quot;Extension&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">     &lt;/xs:sequence&gt;</span><br><span class="line">     &lt;xs:attribute name=&quot;modelName&quot; type=&quot;xs:string&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">     &lt;xs:attribute name=&quot;functionName&quot; type=&quot;MINING-FUNCTION&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">     &lt;xs:attribute name=&quot;algorithmName&quot; type=&quot;xs:string&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">   &lt;/xs:complexType&gt;</span><br><span class="line"> &lt;/xs:element&gt;</span><br></pre></td></tr></table></figure><br>MiningSchema 是一个由模型使用到的字段组成的非空列表。<br>Output 模型的计算结果，比如预测概率或置信度等。<br>ModelStats 是字段的一个统计属性。<br>Targets 包含了目标值，以及相关的信息，如 0 1分类中，属于各个分类的概率。<br>LocalTransformations 包含了在本地转换操作用到的追加字段。<br>…(其他一些元素的定义)<br>ModelVerification 给出了样例数据以及模型结果样例，便于消费者验证有效性。</p>
<p><strong>属性</strong><br><strong>modelName</strong> 属性代表模型名字，用来确保该模型在PMML文件中的唯一性。该字段不是必要的。消费者可以根据需要，自由的管理模型名</p>
<p><strong>functionName</strong> 和 <strong>algorithmName</strong> 描述了数据挖掘模型的类型，例如是聚类模型还是分类模型。<strong>algorithmName</strong> 是自由类型的且只用于说明，可以包含任何用于描述该该算法和模型的内容。</p>
<h1 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h1><p>尽管非常罕见，分类模型可能出现多个解的情况。在这些情况下，PMML没有定义特殊的处理流程，只是按照DataFiled 中对类别的排序，推荐先出现的类别。</p>
<h1 id="命名规范"><a href="#命名规范" class="headerlink" title="命名规范"></a>命名规范</h1><p>PMML的命名规范如下：</p>
<ul>
<li>元素名，首字母大写</li>
<li>属性名，首字母小写</li>
<li>常量，首字母小写</li>
<li>简单类型，全部大写</li>
</ul>
<p>为避免和减号产生歧义，’-‘不建议使用。</p>
<h1 id="扩展机制"><a href="#扩展机制" class="headerlink" title="扩展机制"></a>扩展机制</h1><p>在PMML Schema中可以通过Extension元素扩展模型内容。Extension元素必须出现在第一个子元素，或者组中第一的位置。这为了保证该元素中接下来的内容都受Extension元素的影响。每一个主要的元素都必须包含Extension元素作为第一个和最后一个子元素，来确保其最大的扩展性。</p>
<p>Extension Schema如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:element name=&quot;Extension&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:complexContent mixed=&quot;true&quot;&gt;</span><br><span class="line">      &lt;xs:restriction base=&quot;xs:anyType&quot;&gt;</span><br><span class="line">        &lt;xs:sequence&gt;</span><br><span class="line">          &lt;xs:any processContents=&quot;skip&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">        &lt;/xs:sequence&gt; </span><br><span class="line">        &lt;xs:attribute name=&quot;extender&quot; type=&quot;xs:string&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">        &lt;xs:attribute name=&quot;name&quot; type=&quot;xs:string&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">        &lt;xs:attribute name=&quot;value&quot; type=&quot;xs:string&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">      &lt;/xs:restriction&gt;</span><br><span class="line">    &lt;/xs:complexContent&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br></pre></td></tr></table></figure></p>
<p>这些扩展的元素都含有一个ANY类型的模型来指向扩展的模型。不过这些元素的类型名必须以X开头，来避免和PMML后续增加的内容产生冲突。<br>相应的，Extension元素也有<strong>name</strong> 和 <strong>value</strong> 属性来指定字段名和值。</p>
<h2 id="样例"><a href="#样例" class="headerlink" title="样例"></a>样例</h2><p>扩展属性format可以通过如下方式在DataField内追加：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;DataField name=&quot;foo&quot; dataType=&quot;double&quot; optype=&quot;continuous&quot;&gt;</span><br><span class="line">  &lt;Extension name=&quot;format&quot; value=&quot;%9.2f&quot;/&gt;</span><br><span class="line">&lt;/DataField&gt;</span><br></pre></td></tr></table></figure></p>
<p>扩展元素 DataFieldSource 可以通过如下方式追加到DataField中<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;DataField name=&quot;foo&quot; dataType=&quot;double&quot; optype=&quot;continuous&quot;&gt;</span><br><span class="line">  &lt;Extension&gt;</span><br><span class="line">    &lt;DataFieldSource sourceKnown=&quot;yes&quot;&gt;</span><br><span class="line">      &lt;Source&gt;derivedFromInput&lt;/Source&gt;</span><br><span class="line">    &lt;/DataFieldSource&gt;</span><br><span class="line">  &lt;/Extension&gt;</span><br><span class="line">&lt;/DataField&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="基础数据类型和对象"><a href="#基础数据类型和对象" class="headerlink" title="基础数据类型和对象"></a>基础数据类型和对象</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:simpleType name=&quot;NUMBER&quot;&gt;</span><br><span class="line">  &lt;xs:restriction base=&quot;xs:double&quot;&gt;</span><br><span class="line">  &lt;/xs:restriction&gt;</span><br><span class="line">&lt;/xs:simpleType&gt;</span><br></pre></td></tr></table></figure>
<p>该定义常用来区别数值和其他类型的值。数值通常会包含符号，小数点，指数。XML Schema中float类型支持INF，-INF 和 NaN的表示。这些在NUMBER中是不支持的。除了NUMBER还有一些定义更严格的类型，类似于NUMBER的子类型。</p>
<p><strong>INT-NUMBER</strong><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:simpleType name=&quot;INT-NUMBER&quot;&gt;</span><br><span class="line">  &lt;xs:restriction base=&quot;xs:integer&quot;&gt;</span><br><span class="line">  &lt;/xs:restriction&gt;</span><br><span class="line">&lt;/xs:simpleType&gt;</span><br></pre></td></tr></table></figure><br>必须是整数，不能是小数或指数。</p>
<p><strong>REAL-NUMBER</strong><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:simpleType name=&quot;REAL-NUMBER&quot;&gt;</span><br><span class="line">  &lt;xs:restriction base=&quot;xs:double&quot;&gt;</span><br><span class="line">  &lt;/xs:restriction&gt;</span><br><span class="line">&lt;/xs:simpleType&gt;</span><br></pre></td></tr></table></figure><br>实数型，可以覆盖C/C++中 float、long或者double类型。科学计数法，如 1，23e4 也是支持的。INF,-INF，NaN 是不支持的。</p>
<p><strong>PROB-NUMBER</strong><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:simpleType name=&quot;PROB-NUMBER&quot;&gt;</span><br><span class="line">  &lt;xs:restriction base=&quot;xs:double&quot;&gt;</span><br><span class="line">  &lt;/xs:restriction&gt;</span><br><span class="line">&lt;/xs:simpleType&gt;</span><br></pre></td></tr></table></figure><br>概率型，值在[0.0,1.0]之间，通常用来表示预测概率。</p>
<p><strong>PERCENTAGE-NUMBER</strong><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:simpleType name=&quot;PERCENTAGE-NUMBER&quot;&gt;</span><br><span class="line">  &lt;xs:restriction base=&quot;xs:double&quot;&gt;</span><br><span class="line">  &lt;/xs:restriction&gt;</span><br><span class="line">&lt;/xs:simpleType&gt;</span><br></pre></td></tr></table></figure><br>百分比型，[0.0,100.0]之间的一个实数。</p>
<p>注意到这些对象并不强制XML解析器来检查他们的数据类型。但在PMML文档中定义了其有效性校验的相关操作。<br>许多元素都有输入字段的引用。PMML不使用<a href="https://blog.csdn.net/sweatlove/article/details/1681648">IDERF</a>来表示字段名，就是因为XML 标识的有效性校验不是必须的。而通过如下定义:<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:simpleType name=&quot;FIELD-NAME&quot;&gt;</span><br><span class="line">  &lt;xs:restriction base=&quot;xs:string&quot;&gt;</span><br><span class="line">  &lt;/xs:restriction&gt;</span><br><span class="line">&lt;/xs:simpleType&gt;</span><br></pre></td></tr></table></figure><br>则可以进行相关引用的校验。</p>
<h1 id="简单数组"><a href="#简单数组" class="headerlink" title="简单数组"></a>简单数组</h1><p>模型中通常包含一大堆数值组成的集合。Array 的定义和C or Java中的数组类似，Schema如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:complexType name=&quot;ArrayType&quot; mixed=&quot;true&quot;&gt;</span><br><span class="line">  &lt;xs:attribute name=&quot;n&quot; type=&quot;INT-NUMBER&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">  &lt;xs:attribute name=&quot;type&quot; use=&quot;required&quot;&gt;</span><br><span class="line">    &lt;xs:simpleType&gt;</span><br><span class="line">      &lt;xs:restriction base=&quot;xs:string&quot;&gt;</span><br><span class="line">        &lt;xs:enumeration value=&quot;int&quot;/&gt;</span><br><span class="line">        &lt;xs:enumeration value=&quot;real&quot;/&gt;</span><br><span class="line">        &lt;xs:enumeration value=&quot;string&quot;/&gt;</span><br><span class="line">      &lt;/xs:restriction&gt;</span><br><span class="line">    &lt;/xs:simpleType&gt;</span><br><span class="line">  &lt;/xs:attribute&gt;</span><br><span class="line">&lt;/xs:complexType&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:element name=&quot;Array&quot; type=&quot;ArrayType&quot;/&gt;</span><br></pre></td></tr></table></figure></p>
<p>Array 的内容是一组以空格分割的值，多个空格和单个空格效果一致。<br><strong>n</strong>：该属性定义了该序列的值数量。如果<strong>n</strong>的值给出了，那和值的数量必须保持一致，否则该pmml文档视为无效。<br><strong>type</strong>：该属性是必须的，指定类型便于后续解析。<br>特殊的，在String中存在空格 和 “ ,需要使用转义符，例子如下：<br><strong>例子</strong><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;Array n=&quot;3&quot; type=&quot;int&quot;&gt;1 22 3&lt;/Array&gt;</span><br><span class="line">&lt;Array n=&quot;3&quot; type=&quot;string&quot;&gt;ab  &quot;a b&quot;   &quot;with \&quot;quotes\&quot; &quot;&lt;/Array&gt;</span><br></pre></td></tr></table></figure></p>
<p>类似上面NUMBER有很多子类型，Array 也有，如下：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:group name=&quot;NUM-ARRAY&quot;&gt;</span><br><span class="line">  &lt;xs:choice&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;Array&quot;/&gt;</span><br><span class="line">  &lt;/xs:choice&gt;</span><br><span class="line">&lt;/xs:group&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:group name=&quot;INT-ARRAY&quot;&gt;</span><br><span class="line">  &lt;xs:choice&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;Array&quot;/&gt;</span><br><span class="line">  &lt;/xs:choice&gt;</span><br><span class="line">&lt;/xs:group&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:group name=&quot;REAL-ARRAY&quot;&gt;</span><br><span class="line">  &lt;xs:choice&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;Array&quot;/&gt;</span><br><span class="line">  &lt;/xs:choice&gt;</span><br><span class="line">&lt;/xs:group&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:group name=&quot;STRING-ARRAY&quot;&gt;</span><br><span class="line">  &lt;xs:choice&gt;</span><br><span class="line">    &lt;xs:element ref=&quot;Array&quot;/&gt;</span><br><span class="line">  &lt;/xs:choice&gt;</span><br><span class="line">&lt;/xs:group&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="稀疏数组"><a href="#稀疏数组" class="headerlink" title="稀疏数组"></a>稀疏数组</h1><p>只记录非0值的数组，类似系数矩阵<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:element name=&quot;INT-SparseArray&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:sequence&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Indices&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;INT-Entries&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">    &lt;/xs:sequence&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;n&quot; type=&quot;INT-NUMBER&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;defaultValue&quot; type=&quot;INT-NUMBER&quot; use=&quot;optional&quot; default=&quot;0&quot;/&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:element name=&quot;REAL-SparseArray&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:sequence&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Indices&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;REAL-Entries&quot; minOccurs=&quot;0&quot;/&gt;</span><br><span class="line">    &lt;/xs:sequence&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;n&quot; type=&quot;INT-NUMBER&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;defaultValue&quot; type=&quot;REAL-NUMBER&quot; use=&quot;optional&quot; default=&quot;0&quot;/&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:element name=&quot;Indices&quot;&gt;</span><br><span class="line">  &lt;xs:simpleType&gt;</span><br><span class="line">    &lt;xs:list itemType=&quot;xs:int&quot;/&gt;</span><br><span class="line">  &lt;/xs:simpleType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:element name=&quot;INT-Entries&quot;&gt;</span><br><span class="line">  &lt;xs:simpleType&gt;</span><br><span class="line">    &lt;xs:list itemType=&quot;xs:int&quot;/&gt;</span><br><span class="line">  &lt;/xs:simpleType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:element name=&quot;REAL-Entries&quot;&gt;</span><br><span class="line">  &lt;xs:simpleType&gt;</span><br><span class="line">    &lt;xs:list itemType=&quot;xs:double&quot;/&gt;</span><br><span class="line">  &lt;/xs:simpleType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>n</strong> 该属性指定了稀疏数组的长度，这在没有指定数组最后一个对象的情况下，会非常有用。<br><strong>defaultValue</strong> 该属性指定了整个数组中，没有指定值情况下的默认值。<br>稀疏数组其实是由两个数组组成，索引数组Indices和值数组INT-Entries 或者 REAL-Entries。<br>索引数组从1开始，包含了值不为默认值的索引。<br>值数组是索引数组对应编号位的值。因此索引数组和值数组的长度必须保持一致。<br>形成稀疏数组的结构  如 1:3 2:6 8:9的索引数组为[1,2,8] 值数组为[3,6,9]。<br>综上，索引数组和值数组是成对出现的，否则PMML会视为无效。</p>
<h2 id="样例-1"><a href="#样例-1" class="headerlink" title="样例"></a>样例</h2><p>数组 0 3 0 0 42 0 0 可以用如下形式表示<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;INT-SparseArray n=&quot;7&quot;&gt;</span><br><span class="line">  &lt;Indices&gt;2 5&lt;/Indices&gt;</span><br><span class="line">  &lt;INT-Entries&gt;3 42&lt;/INT-Entries&gt;</span><br><span class="line">&lt;/INT-SparseArray&gt;</span><br></pre></td></tr></table></figure></p>
<p>数组 0 0 0 0 0 0 0 可以用如下形式表示<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;INT-SparseArray n=&quot;7&quot;/&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h1><p>为了节省空间，一个矩阵会以对角矩阵或者稀疏矩阵的形式存储。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:element name=&quot;Matrix&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:choice minOccurs=&quot;0&quot;&gt;</span><br><span class="line">      &lt;xs:group ref=&quot;NUM-ARRAY&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;MatCell&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">    &lt;/xs:choice&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;kind&quot; use=&quot;optional&quot; default=&quot;any&quot;&gt;</span><br><span class="line">      &lt;xs:simpleType&gt;</span><br><span class="line">        &lt;xs:restriction base=&quot;xs:string&quot;&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;diagonal&quot;/&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;symmetric&quot;/&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;any&quot;/&gt;</span><br><span class="line">        &lt;/xs:restriction&gt;</span><br><span class="line">      &lt;/xs:simpleType&gt;</span><br><span class="line">    &lt;/xs:attribute&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;nbRows&quot; type=&quot;INT-NUMBER&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;nbCols&quot; type=&quot;INT-NUMBER&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;diagDefault&quot; type=&quot;REAL-NUMBER&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;offDiagDefault&quot; type=&quot;REAL-NUMBER&quot; use=&quot;optional&quot;/&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:element name=&quot;MatCell&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:simpleContent&gt;</span><br><span class="line">      &lt;xs:extension base=&quot;xs:string&quot;&gt;</span><br><span class="line">        &lt;xs:attribute name=&quot;row&quot; type=&quot;INT-NUMBER&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">        &lt;xs:attribute name=&quot;col&quot; type=&quot;INT-NUMBER&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">      &lt;/xs:extension&gt;</span><br><span class="line">    &lt;/xs:simpleContent&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br></pre></td></tr></table></figure></p>
<p>矩阵通常用一个数组的序列（二维数组）或者矩阵元素的序列来表示。如果用数组表示，每个数组表示矩阵的一行。<br><strong>MatCells</strong> 矩阵元素通过行、列索引来指定对应位置的值。行、列索引从1开始。<br><strong>diagDefault</strong> 和 <strong>offDiagDefault</strong> 属性在使用稀疏矩阵时，必须设定。<br><strong>nbRows</strong> 和 <strong>nbCols</strong> 属性指定了矩阵的维度。如果其中一个属性没有指定，那便有矩阵表示（数组或者矩阵元素）的定义隐式定义。如使用了矩阵元素，那么矩阵的维度就是能容纳该元素得的维度值。</p>
<p><strong>kind</strong> 属性触发了矩阵的实际表示：</p>
<ul>
<li>diagonal: 只有一个数组，用来表示矩阵对角线元素</li>
<li>symmetric: 对称矩阵，用二维数组表示，第一个数组表示坐标(0,0)处元素, 第二个数组表示坐标(1，0)和(1，1)处元素，以此类推。描述整个左下半三角区。右上半三角区由对称求得。</li>
<li>any: 通过二维数组或者矩阵元素指定矩阵。</li>
</ul>
<h2 id="样例-2"><a href="#样例-2" class="headerlink" title="样例"></a>样例</h2><p>矩阵<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">0  0  0 42  0</span><br><span class="line">0  1  0  0  0</span><br><span class="line">5  0  0  0  0</span><br><span class="line">0  0  0  0  7</span><br><span class="line">0  0  9  0  0</span><br></pre></td></tr></table></figure><br>可以用如下定义来表述：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;Matrix nbRows=&quot;5&quot; nbCols=&quot;5&quot;&gt;</span><br><span class="line">  &lt;Array type=&quot;real&quot;&gt;0 0 0 42 0&lt;/Array&gt;</span><br><span class="line">  &lt;Array type=&quot;real&quot;&gt;0 1 0 0 0&lt;/Array&gt;</span><br><span class="line">  &lt;Array type=&quot;real&quot;&gt;5 0 0 0 0&lt;/Array&gt;</span><br><span class="line">  &lt;Array type=&quot;real&quot;&gt;0 0 0 0 7&lt;/Array&gt;</span><br><span class="line">  &lt;Array type=&quot;real&quot;&gt;0 0 9 0 0&lt;/Array&gt;</span><br><span class="line">&lt;/Matrix&gt;</span><br><span class="line">&lt;Matrix diagDefault=&quot;0&quot; offDiagDefault=&quot;0&quot;&gt;</span><br><span class="line">  &lt;MatCell row=&quot;1&quot; col=&quot;4&quot;&gt;42&lt;/MatCell&gt;</span><br><span class="line">  &lt;MatCell row=&quot;2&quot; col=&quot;2&quot;&gt;1&lt;/MatCell&gt;</span><br><span class="line">  &lt;MatCell row=&quot;3&quot; col=&quot;1&quot;&gt;5&lt;/MatCell&gt;</span><br><span class="line">  &lt;MatCell row=&quot;4&quot; col=&quot;5&quot;&gt;7&lt;/MatCell&gt;</span><br><span class="line">  &lt;MatCell row=&quot;5&quot; col=&quot;3&quot;&gt;9&lt;/MatCell&gt;</span><br><span class="line">&lt;/Matrix&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="无评分模型"><a href="#无评分模型" class="headerlink" title="无评分模型"></a>无评分模型</h1><p>找寻一个有效模型的道路通常是曲折和充满荆棘的。生成可部署的模型的尝试中出现失败是很正常的。在早期的试验阶段，会进行非常多的测试来寻找有用的特征。或者，从基础的角度说，训练模型使用的数据有问题的话，最后也无法生成正确的模型。相对，许多数据挖掘工具都会自动排除那些不符合要求的特征，或者制定一个最低限度的标准来确保模型可以被部署。</p>
<p>PMML包含许多帮助使用者了解模型质量的特征性，比如Statics 和 Model Explanation。这些描述性的元素对于验证模型的有效性，以及理解模型运行失败的原因很有包住。</p>
<p>反过来看，PMML既能产生好的结果，也能产生坏的结果，尤其是在整个系统中，PMML只是承担了接口人的角色，联接了模型生成者和模型消费者。这也就要求模型的消费者能够辨别PMML中是否包含一个有效的模型，或者PMML不能用于判断得分。<br>举个例子，如回归模型中，所有的独立变量都不能满足最小的重要性验证。在追加的描述信息中，应该有所体现，并且说明为何这些变量会被排除。或者，如果模型不能满足某些验证，模型的生成者需要将这些说明增加在Model Explanation中。<br>综上，存在这样一些模型，最后的产生的结果都是一样的，无法用于评分。模型消费者可以选择不去部署这些模型，或者部署他们只为加深理解，而不用于评分。</p>
<h1 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h1><p><a href="http://dmg.org/pmml/v4-3/GeneralStructure.html">PMML 4.3 - General Structure</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/08/pmml-DataDictionary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="喵十八">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="喵十八の小窝">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/07/08/pmml-DataDictionary/" class="post-title-link" itemprop="url">PMML文档翻译 数据字典（DataDictionary）</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-07-08 18:41:12 / Modified: 18:42:02" itemprop="dateCreated datePublished" datetime="2018-07-08T18:41:12+08:00">2018-07-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PMML/" itemprop="url" rel="index"><span itemprop="name">PMML</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><ul>
<li>基于PMML Version4.3</li>
<li>基本可以视为官方文档的一个翻译</li>
<li>如有疏漏，请联系yao544303963@gmail.com</li>
</ul>
<h1 id="数据字典"><a href="#数据字典" class="headerlink" title="数据字典"></a>数据字典</h1><p>数据字典包含了数据挖掘模型中使用的字段定义。指定了字段类型和字段值的取值范围。<br>这些定义是独立的，无关于使用了何种数据集训练了何种模型。<br>一个数据字典，可以被多个模型、统计值以及其他相关的操作共享。</p>
<h1 id="Schema"><a href="#Schema" class="headerlink" title="Schema"></a>Schema</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:element name=&quot;DataDictionary&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:sequence&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Extension&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;DataField&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Taxonomy&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">    &lt;/xs:sequence&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;numberOfFields&quot; type=&quot;xs:nonNegativeInteger&quot;/&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:element name=&quot;DataField&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:sequence&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Extension&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">      &lt;xs:sequence&gt;</span><br><span class="line">        &lt;xs:element ref=&quot;Interval&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">        &lt;xs:element ref=&quot;Value&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">      &lt;/xs:sequence&gt;</span><br><span class="line">    &lt;/xs:sequence&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;name&quot; type=&quot;FIELD-NAME&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;displayName&quot; type=&quot;xs:string&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;optype&quot; type=&quot;OPTYPE&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;dataType&quot; type=&quot;DATATYPE&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;taxonomy&quot; type=&quot;xs:string&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;isCyclic&quot; default=&quot;0&quot;&gt;</span><br><span class="line">      &lt;xs:simpleType&gt;</span><br><span class="line">        &lt;xs:restriction base=&quot;xs:string&quot;&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;0&quot;/&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;1&quot;/&gt;</span><br><span class="line">        &lt;/xs:restriction&gt;</span><br><span class="line">      &lt;/xs:simpleType&gt;</span><br><span class="line">    &lt;/xs:attribute&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:simpleType name=&quot;OPTYPE&quot;&gt;      </span><br><span class="line">  &lt;xs:restriction base=&quot;xs:string&quot;&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;categorical&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;ordinal&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;continuous&quot;/&gt;</span><br><span class="line">  &lt;/xs:restriction&gt;</span><br><span class="line">&lt;/xs:simpleType&gt;</span><br><span class="line"></span><br><span class="line">&lt;xs:simpleType name=&quot;DATATYPE&quot;&gt;      </span><br><span class="line">  &lt;xs:restriction base=&quot;xs:string&quot;&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;string&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;integer&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;float&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;double&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;boolean&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;date&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;time&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;dateTime&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;dateDaysSince[0]&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;dateDaysSince[1960]&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;dateDaysSince[1970]&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;dateDaysSince[1980]&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;timeSeconds&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;dateTimeSecondsSince[0]&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;dateTimeSecondsSince[1960]&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;dateTimeSecondsSince[1970]&quot;/&gt;</span><br><span class="line">    &lt;xs:enumeration value=&quot;dateTimeSecondsSince[1980]&quot;/&gt;</span><br><span class="line">  &lt;/xs:restriction&gt;</span><br><span class="line">&lt;/xs:simpleType&gt;</span><br></pre></td></tr></table></figure>
<h1 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h1><h2 id="DataDictionary"><a href="#DataDictionary" class="headerlink" title="DataDictionary"></a>DataDictionary</h2><p>该元素定义了数据字典的顶层。可以包含三种类型的子元素： Extension、DataField、Taxonomy  </p>
<p><strong>包含属性：</strong></p>
<p><strong>numberOfFields</strong><br>该属性值是数据字典中定义的字段的数量，可以用来进行前后一致性的校验（字段数量的校验）</p>
<h2 id="DataField"><a href="#DataField" class="headerlink" title="DataField"></a>DataField</h2><p>该元素定义了字段。<br>在整个数据字典中，字段名称必须唯一。也有一些特殊情况，在整个PMML文档中，名称以必须唯一。</p>
<p><strong>包含属性：</strong><br><strong>displayName</strong>：<br>应用程序使用该名称来关联该字段。在XML文档内部，只有<strong>name</strong>的值是必须的，如果没有给出<strong>displayName</strong>，那其默认值就是<strong>name</strong>的值。<br>举个例子：<br>某个字段的<strong>name=”SCTAGE” displayName=”Customer age”</strong>。应用程序在调用PMML 消费者时，会在接口处使用Customer age来请求输入数据。一旦消费者接受了参数，并且和miningFields匹配上了，那么<strong>displayName</strong>就没有什么实际意义了，在内部处理中，都是使用<strong>name</strong>。</p>
<p><strong>optype</strong>：<br>字段的类型，即定义在这些字段值上的操作类型，主要有三类。</p>
<ul>
<li>categorical 类别型 只能进行相等或不相等的运算。（即，是这个分类，或者不是这个分类）</li>
<li>ordinal 定序型 有内在排序，可以比较，但是不适合加减运算。如年级编号。</li>
<li>continuous 连续型  数值</li>
</ul>
<p><strong>dataType</strong>：<br>字段值的类型（这个更类似于Java 或 C中的数据类型），比如类别型，就是所有的string<br>可选值如下：</p>
<ul>
<li>string</li>
<li>integer</li>
<li>float</li>
<li>double</li>
<li>boolean</li>
<li>date</li>
<li>time</li>
<li>dateTime</li>
<li>dateDaysSince[0]</li>
<li>dateDaysSince[1960]</li>
<li>dateDaysSince[1970]</li>
<li>dateDaysSince[1980]</li>
<li>timeSeconds</li>
<li>dateTimeSecondsSince[0]</li>
<li>dateTimeSecondsSince[1960]</li>
<li>dateTimeSecondsSince[1970]</li>
<li>dateTimeSecondsSince[1980]</li>
</ul>
<p>类型的定义，详见<a href="https://www.w3.org/TR/xmlschema-2/">XML Schema Part 2: Datatypes</a><br>其中有三个类型是PMML 相较于 XML Schema 新增的，分别是timeSeconds,dateDaysSince[a Year],dateTimesSecondsSince[a Year],其中a Year 可以是0、1960、1970、1980中的一个值。注意到，a Year不是一个任意值，必须在允许的值中进行选取。如果可变的a Year 是必须的，那就需要考虑使用<a href="http://dmg.org/pmml/v4-3/BuiltinFunctions.html#datedayssinceyear">內建函数</a><br>PMML支持这些额外的类型，原因在于在数据挖掘中，经常需要将时间转化为可以比较和计算的数值。例如 2003-04-01 就可以通过 dateDaysSince[1960] 转为15796。</p>
<p><strong>taxonomy</strong>：<br>可选属性 <strong>taxonomy</strong> 关联了一个<a href="https://en.wikipedia.org/wiki/Taxonomy">taxonomy</a> 值。用来描述一个分层的值的情况。<br><em>Tips</em>：<br>这个值体现了一个继承性和分层性。</p>
<p><strong>isCyclic</strong>:<br>表示定序型的值是否可循环，如周日至周六</p>
<h1 id="有效性"><a href="#有效性" class="headerlink" title="有效性"></a>有效性</h1><p>DataFiled 定义了一组规则来验证值的有效性。<br>数据挖掘模型区分了如下三种值的情况：  </p>
<ul>
<li>Missing Data： 缺失值。  </li>
<li>Invalid Value： 无效值，即输入不为空，但是取值范围超出了给该值的取值区间。</li>
<li>Valid Value： 有效值，即不为以上两种情况的值。</li>
</ul>
<h1 id="值和区间"><a href="#值和区间" class="headerlink" title="值和区间"></a>值和区间</h1><p>Value 和 Interval 元素用来描述数据字典中值的情况和取值区间。</p>
<h2 id="Value-Schema"><a href="#Value-Schema" class="headerlink" title="Value Schema"></a>Value Schema</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:element name=&quot;Value&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:sequence&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Extension&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">    &lt;/xs:sequence&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;value&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;displayValue&quot; type=&quot;xs:string&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;property&quot; default=&quot;valid&quot;&gt;</span><br><span class="line">      &lt;xs:simpleType&gt;</span><br><span class="line">        &lt;xs:restriction base=&quot;xs:string&quot;&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;valid&quot;/&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;invalid&quot;/&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;missing&quot;/&gt;</span><br><span class="line">        &lt;/xs:restriction&gt;</span><br><span class="line">      &lt;/xs:simpleType&gt;</span><br><span class="line">    &lt;/xs:attribute&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br></pre></td></tr></table></figure>
<h2 id="Interval-Schema"><a href="#Interval-Schema" class="headerlink" title="Interval Schema"></a>Interval Schema</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:element name=&quot;Interval&quot;&gt;</span><br><span class="line">  &lt;xs:complexType&gt;</span><br><span class="line">    &lt;xs:sequence&gt;</span><br><span class="line">      &lt;xs:element ref=&quot;Extension&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;</span><br><span class="line">    &lt;/xs:sequence&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;closure&quot; use=&quot;required&quot;&gt;</span><br><span class="line">      &lt;xs:simpleType&gt;</span><br><span class="line">        &lt;xs:restriction base=&quot;xs:string&quot;&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;openClosed&quot;/&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;openOpen&quot;/&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;closedOpen&quot;/&gt;</span><br><span class="line">          &lt;xs:enumeration value=&quot;closedClosed&quot;/&gt;</span><br><span class="line">        &lt;/xs:restriction&gt;</span><br><span class="line">      &lt;/xs:simpleType&gt;</span><br><span class="line">    &lt;/xs:attribute&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;leftMargin&quot; type=&quot;NUMBER&quot;/&gt;</span><br><span class="line">    &lt;xs:attribute name=&quot;rightMargin&quot; type=&quot;NUMBER&quot;/&gt;</span><br><span class="line">  &lt;/xs:complexType&gt;</span><br><span class="line">&lt;/xs:element&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="连续型demo"><a href="#连续型demo" class="headerlink" title="连续型demo"></a>连续型demo</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;DataField name=&quot;SomeVariable&quot; dataType=&quot;double&quot; optype=&quot;continuous&quot;&gt;</span><br><span class="line">  &lt;Interval closure=&quot;closedClosed&quot; leftMargin=&quot;0&quot; rightMargin=&quot;100&quot;/&gt;</span><br><span class="line">  &lt;Value property=&quot;missing&quot; value=&quot;-999&quot;/&gt;</span><br><span class="line">&lt;/DataField&gt;</span><br></pre></td></tr></table></figure>
<p>表示取值区间[0, 100]，若为空，则取-999<br>Interval 只支持连续型（continuous)</p>
<h2 id="类别型demo"><a href="#类别型demo" class="headerlink" title="类别型demo"></a>类别型demo</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;DataField name=&quot;_target&quot; optype=&quot;categorical&quot; dataType=&quot;string&quot;&gt;</span><br><span class="line">	&lt;Value value=&quot;0&quot;/&gt;</span><br><span class="line">	&lt;Value value=&quot;1&quot;/&gt;</span><br><span class="line">&lt;/DataField&gt;</span><br></pre></td></tr></table></figure>
<p>不存在二分类的数据类型，所以二分类的定义如上。</p>
<h2 id="定序型demo"><a href="#定序型demo" class="headerlink" title="定序型demo"></a>定序型demo</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;DataField name=&quot;Volume&quot; optype=&quot;ordinal&quot; dataType=&quot;string&quot;&gt;</span><br><span class="line">  &lt;Value value=&quot;loud&quot;/&gt;</span><br><span class="line">  &lt;Value value=&quot;louder&quot;/&gt;</span><br><span class="line">  &lt;Value value=&quot;insane&quot;/&gt;</span><br><span class="line">&lt;/DataField&gt;</span><br></pre></td></tr></table></figure>
<p>如上，定序为出现顺序的逆序，及loud &lt; louder &lt; insane<br>加上 cyclic 参数，即可形成循环，如周日至周六</p>
<h1 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h1><p><a href="http://dmg.org/pmml/v4-3/DataDictionary.html">PMML 4.3 - Data Dictionary</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">喵十八</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">58</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">78</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Yao544303" title="GitHub → https://github.com/Yao544303" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yao544303963@gmail.com" title="E-Mail → mailto:yao544303963@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">喵十八</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


</body>
</html>
